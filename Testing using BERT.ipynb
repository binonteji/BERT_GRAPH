{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41c731b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 15:27:46.327181: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-02 15:27:46.449154: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-02 15:27:46.937297: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-12-02 15:27:46.937344: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-12-02 15:27:46.937349: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "import os.path as osp\n",
    "from torch_geometric.datasets import Planetoid,PPI\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from modeling.models import TransformerModel\n",
    "from modeling.data import bert_walk_collate, BertWalkDataset\n",
    "from modeling.tokenizer import bert_walk_tokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils.commons import *\n",
    "import random\n",
    "import argparse\n",
    "# from train_bert_walk import *\n",
    "# bert_walk_tokenizer, bert_walk_collate\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(flush_secs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac8f4b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"cpu\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2c32a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "checkpoint = torch.load(\"/home/netra-mobile/Desktop/GRAPH_BERT_VAE/artifacts/Dec02_11-42-04_netramobile-precision-7560_model.pt\", map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82bb69b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model_params', 'model_state_dict', 'networks', 'tokenizer'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db62e857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 64,\n",
       " 'emsize': 128,\n",
       " 'nhid': 200,\n",
       " 'nlayers': 6,\n",
       " 'nhead': 4,\n",
       " 'dropout': 0.0,\n",
       " 'learning_rate': 0.0005,\n",
       " 'epochs': 40,\n",
       " 'K': 1,\n",
       " 'alpha': 0.1,\n",
       " 'mask_rate': 0.2,\n",
       " 'q': 1,\n",
       " 'p': 1,\n",
       " 'walk_length': 10,\n",
       " 'num_walks': 10,\n",
       " 'weighted': 1,\n",
       " 'directed': 0,\n",
       " 'organism': 'FIRSTMM_DB',\n",
       " 'ntokens': 3533}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint['model_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e49c8ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = ['/home/netra-mobile/Desktop/GRAPH_BERT_VAE/inputs/FIRSTMM_DB/FIRSTMM_DB_11.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7f87968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['/home/netra-mobile/Desktop/GRAPH_BERT_VAE/inputs/FIRSTMM_DB/FIRSTMM_DB_11.txt']\n",
      "\n",
      "Reading Corpus from Disk\n"
     ]
    }
   ],
   "source": [
    "data, pyg_graphs = read_data(graphs, checkpoint['model_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b896b48b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Data(edge_index=[2, 6014], num_nodes=1304, edge_weight=[6014], node_index=[1304], node_sequence=[1])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyg_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc52645b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1304"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyg_graphs[0].num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3da021d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_params': {'batch_size': 64,\n",
       "  'emsize': 128,\n",
       "  'nhid': 200,\n",
       "  'nlayers': 6,\n",
       "  'nhead': 4,\n",
       "  'dropout': 0.0,\n",
       "  'learning_rate': 0.0005,\n",
       "  'epochs': 20,\n",
       "  'K': 1,\n",
       "  'alpha': 0.1,\n",
       "  'mask_rate': 0.2,\n",
       "  'q': 1,\n",
       "  'p': 1,\n",
       "  'walk_length': 10,\n",
       "  'num_walks': 10,\n",
       "  'weighted': 1,\n",
       "  'directed': 0,\n",
       "  'organism': 'FIRSTMM_DB',\n",
       "  'ntokens': 1304},\n",
       " 'model_state_dict': OrderedDict([('pos_encoder.pe',\n",
       "               tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
       "                          0.0000e+00,  1.0000e+00]],\n",
       "               \n",
       "                       [[ 8.4147e-01,  5.4030e-01,  7.6172e-01,  ...,  1.0000e+00,\n",
       "                          1.1548e-04,  1.0000e+00]],\n",
       "               \n",
       "                       [[ 9.0930e-01, -4.1615e-01,  9.8705e-01,  ...,  1.0000e+00,\n",
       "                          2.3096e-04,  1.0000e+00]],\n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "                       [[ 6.1950e-02,  9.9808e-01,  8.1507e-01,  ...,  9.9770e-01,\n",
       "                          5.8745e-02,  9.9827e-01]],\n",
       "               \n",
       "                       [[ 8.7333e-01,  4.8714e-01,  9.6940e-01,  ...,  9.9769e-01,\n",
       "                          5.8860e-02,  9.9827e-01]],\n",
       "               \n",
       "                       [[ 8.8177e-01, -4.7168e-01,  4.4109e-01,  ...,  9.9768e-01,\n",
       "                          5.8975e-02,  9.9826e-01]]])),\n",
       "              ('transformer_encoder.layers.0.self_attn.in_proj_weight',\n",
       "               tensor([[ 0.1510, -0.1310,  0.0489,  ...,  0.0956, -0.0572, -0.0317],\n",
       "                       [ 0.1913,  0.0290,  0.1326,  ...,  0.0464,  0.1594, -0.0631],\n",
       "                       [-0.0181, -0.1350, -0.1101,  ..., -0.0591, -0.0409,  0.0396],\n",
       "                       ...,\n",
       "                       [ 0.0088, -0.0035, -0.0020,  ..., -0.0165,  0.0079, -0.0611],\n",
       "                       [-0.0044, -0.0012, -0.0120,  ..., -0.0126,  0.1079,  0.0802],\n",
       "                       [-0.0117,  0.0041, -0.0011,  ..., -0.0262, -0.0769,  0.0777]])),\n",
       "              ('transformer_encoder.layers.0.self_attn.in_proj_bias',\n",
       "               tensor([ 1.1797e-01,  2.2760e-02, -9.2881e-02, -6.8548e-02, -1.1970e-01,\n",
       "                       -7.4573e-02,  2.8580e-02, -8.7884e-02,  1.4552e-01,  1.5656e-02,\n",
       "                       -2.8807e-02, -8.9454e-02, -7.7336e-02, -2.0122e-02,  4.5474e-02,\n",
       "                       -8.9767e-02,  3.9151e-02,  3.6870e-02, -1.0908e-01,  1.3590e-01,\n",
       "                        1.0726e-01, -3.4840e-03,  1.0390e-01,  2.6279e-02,  3.5983e-02,\n",
       "                        7.9379e-02, -4.7254e-02,  7.4392e-03, -9.9459e-02, -5.6907e-02,\n",
       "                       -3.8263e-03,  1.1075e-01,  4.5211e-02,  2.6638e-02,  7.5298e-02,\n",
       "                       -7.6018e-02, -1.5447e-01,  4.9845e-02, -2.0667e-01,  3.7062e-02,\n",
       "                       -1.3579e-01, -2.2767e-01, -5.9572e-02, -8.9703e-02,  2.9127e-01,\n",
       "                       -1.5606e-01,  5.9673e-02, -3.9930e-01,  2.5187e-01,  2.7632e-01,\n",
       "                       -1.1043e-01, -2.5914e-01,  9.3393e-02,  1.6979e-02, -6.8169e-02,\n",
       "                       -1.3520e-01, -4.1932e-02, -1.2234e-01, -1.1043e-02,  2.2063e-01,\n",
       "                        1.2524e-01,  3.2428e-01,  2.0877e-01, -1.7982e-01,  3.1791e-02,\n",
       "                       -1.7014e-01, -1.3462e-01,  7.4036e-03, -1.7328e-03,  4.0585e-04,\n",
       "                        9.6232e-02, -3.4497e-01, -1.0196e-01, -3.6102e-01,  1.6614e-01,\n",
       "                        3.5633e-01, -6.3569e-02,  1.9725e-02,  2.8324e-01, -3.7955e-01,\n",
       "                        2.5411e-01, -8.2659e-04,  3.3526e-02, -2.1560e-01, -2.3878e-01,\n",
       "                        3.4709e-01,  2.1489e-01,  2.1547e-01, -2.7174e-01,  5.8695e-02,\n",
       "                        1.2789e-01, -2.7167e-01, -2.0589e-01, -4.0150e-01, -9.1499e-02,\n",
       "                        3.1004e-01,  2.0047e-01,  7.2566e-02, -6.4617e-02,  1.6834e-01,\n",
       "                        1.8653e-01,  1.3724e-01, -1.0676e-02,  4.3872e-02,  1.0339e-01,\n",
       "                        2.5608e-01, -2.0895e-01,  2.8220e-02,  1.7830e-01,  3.5820e-02,\n",
       "                       -2.4272e-01, -2.2044e-01, -6.9115e-02, -1.5548e-01,  1.7147e-01,\n",
       "                        1.9187e-01, -2.4665e-01, -1.6692e-01,  9.3219e-02, -1.7923e-01,\n",
       "                        5.9227e-02, -9.6346e-03,  4.7113e-02,  9.7025e-02, -9.2414e-02,\n",
       "                       -5.2930e-02,  1.9536e-01, -2.3447e-01, -2.8074e-04,  5.7403e-05,\n",
       "                       -2.0795e-04, -2.9185e-04,  6.4060e-04, -2.9331e-04, -5.0435e-05,\n",
       "                        2.4008e-04, -5.4730e-04,  1.4709e-04, -1.5703e-04,  2.5496e-04,\n",
       "                        7.0027e-05,  6.2625e-05,  1.2793e-04,  4.3199e-04,  1.8415e-04,\n",
       "                       -1.9044e-04, -5.4308e-05, -9.8301e-05,  1.0698e-04,  1.1875e-04,\n",
       "                        5.1223e-05,  5.8395e-05,  2.3700e-04,  9.7962e-05, -2.6533e-04,\n",
       "                       -1.9960e-04,  3.3450e-05, -4.5785e-04, -1.3559e-05, -2.8918e-07,\n",
       "                        2.4975e-05,  6.1724e-05,  6.8333e-04,  1.2814e-04, -1.2095e-04,\n",
       "                        8.5680e-05,  2.3767e-04,  1.3549e-04, -1.6162e-04, -6.0846e-04,\n",
       "                       -8.7127e-05, -3.5569e-04,  9.0392e-04,  1.1174e-04, -2.5011e-05,\n",
       "                       -1.5844e-03,  5.0692e-04, -3.5185e-05, -3.5584e-04, -2.7991e-04,\n",
       "                        2.1901e-04,  1.8269e-04, -9.3040e-05, -2.2572e-04, -2.0056e-04,\n",
       "                        4.4686e-05,  1.7038e-04,  1.8844e-05,  3.8481e-04,  1.9963e-04,\n",
       "                        5.2485e-04, -1.4117e-04, -1.7181e-04,  6.1293e-04, -3.2361e-04,\n",
       "                       -1.2875e-04, -3.9519e-04,  9.0998e-05,  1.1965e-04, -1.7619e-05,\n",
       "                        1.6739e-04, -1.1585e-05,  2.6490e-04, -1.2403e-04,  1.3854e-04,\n",
       "                        2.9561e-04, -1.7217e-04, -1.5472e-04, -4.5291e-05,  2.0503e-04,\n",
       "                       -4.6726e-04,  5.6748e-04, -5.5339e-04,  7.3465e-04,  1.0125e-03,\n",
       "                       -2.2746e-04,  8.2228e-06,  1.1904e-04,  4.4624e-04,  2.1126e-05,\n",
       "                        3.6153e-04, -1.6881e-05,  1.1882e-04, -1.6293e-05, -2.3290e-04,\n",
       "                        1.1150e-04,  1.6535e-04,  1.9070e-04,  1.3522e-03, -3.6145e-05,\n",
       "                        1.7812e-04, -2.7375e-04, -9.7730e-05, -7.7611e-04, -1.6982e-04,\n",
       "                        1.6304e-04,  5.5149e-04, -2.8653e-04,  2.1456e-04,  1.5530e-04,\n",
       "                       -5.8645e-04,  5.3430e-04,  2.8696e-06,  9.3506e-05, -3.5497e-04,\n",
       "                        2.8261e-04,  1.1925e-05, -2.2844e-05, -3.8152e-04, -3.9374e-04,\n",
       "                        8.8401e-05,  4.8214e-04, -1.0925e-04, -4.8424e-04,  4.8195e-05,\n",
       "                       -8.1891e-05,  6.5260e-03, -2.4472e-03, -1.0722e-02,  9.5395e-03,\n",
       "                       -2.5430e-03, -1.2622e-02,  4.0634e-03, -2.5620e-03, -1.9354e-02,\n",
       "                       -6.1015e-03,  5.4029e-03,  1.6690e-02,  3.1333e-04, -7.0391e-03,\n",
       "                       -2.4688e-03, -5.0766e-03,  2.1895e-02, -4.3304e-03,  1.6191e-02,\n",
       "                       -1.6072e-02,  7.4490e-03,  3.3636e-03, -5.6141e-03, -2.5807e-02,\n",
       "                       -1.4536e-02, -7.1602e-03, -8.9866e-03, -1.6615e-02,  3.3650e-03,\n",
       "                       -8.5311e-04, -1.2313e-02, -8.5268e-03, -3.6675e-03, -3.0157e-03,\n",
       "                       -9.6001e-03,  2.1338e-03, -1.2941e-02,  9.7724e-03,  1.0440e-02,\n",
       "                        7.4099e-03, -7.4363e-03, -1.0802e-02, -1.1349e-02,  2.6377e-03,\n",
       "                        1.6209e-03, -8.4827e-03, -4.4851e-04,  1.4755e-03,  3.9827e-03,\n",
       "                        1.6414e-02, -3.8152e-03, -1.7803e-03, -1.1801e-02, -4.1676e-03,\n",
       "                        5.6594e-03, -3.8347e-03,  4.0147e-03,  2.0451e-02,  2.5822e-03,\n",
       "                        1.0629e-02, -6.8702e-03,  4.7866e-03,  2.3193e-05, -1.1589e-02,\n",
       "                       -3.6963e-03,  2.2366e-03,  1.1168e-03,  5.0765e-03, -4.5062e-03,\n",
       "                       -8.6277e-03,  1.3649e-02, -1.0868e-02, -7.9745e-03,  5.5946e-04,\n",
       "                        3.6226e-03, -3.4004e-03, -6.2448e-03, -3.9870e-03, -1.9745e-03,\n",
       "                        4.7631e-03, -4.8698e-03,  9.7117e-03, -8.5790e-04,  2.9509e-03,\n",
       "                        5.2375e-03,  7.4280e-03,  6.5816e-03, -7.9594e-03,  1.4499e-02,\n",
       "                       -7.3904e-03,  4.7300e-03,  1.5098e-02, -2.1305e-04,  8.4937e-03,\n",
       "                        4.3520e-03,  4.7313e-02,  1.4701e-02,  1.6803e-03,  5.6116e-03,\n",
       "                       -6.6563e-03, -3.8207e-03, -8.7138e-03, -5.8049e-03, -3.6487e-02,\n",
       "                        9.4866e-03,  2.6716e-03, -4.4665e-03, -8.0319e-03, -6.7593e-03,\n",
       "                        1.2114e-02, -5.0179e-03, -4.8291e-03, -2.9664e-02, -4.4510e-03,\n",
       "                        5.9017e-03,  1.0164e-02, -8.0259e-03, -3.4137e-03, -8.4477e-03,\n",
       "                       -8.4083e-03,  8.1842e-03,  4.9921e-03,  5.5423e-03, -1.9935e-04,\n",
       "                        1.0668e-03, -7.1364e-03, -2.6183e-02,  8.9364e-03])),\n",
       "              ('transformer_encoder.layers.0.self_attn.out_proj.weight',\n",
       "               tensor([[-0.0175,  0.0126, -0.1076,  ...,  0.0517,  0.1326,  0.1248],\n",
       "                       [ 0.0561, -0.3140, -0.1696,  ..., -0.0383,  0.1970, -0.2492],\n",
       "                       [-0.0028,  0.2051, -0.2295,  ...,  0.1147, -0.1038,  0.0722],\n",
       "                       ...,\n",
       "                       [-0.0044, -0.0401,  0.0063,  ..., -0.0301,  0.0864,  0.0097],\n",
       "                       [-0.0084,  0.0123, -0.0204,  ...,  0.0095, -0.0592,  0.0347],\n",
       "                       [-0.0151, -0.0587,  0.0145,  ...,  0.0076,  0.0739,  0.0103]])),\n",
       "              ('transformer_encoder.layers.0.self_attn.out_proj.bias',\n",
       "               tensor([ 0.2010,  0.1091,  0.2853,  0.2087,  0.2177,  0.2647,  0.2233,  0.2774,\n",
       "                        0.0787,  0.2289,  0.1818,  0.1805,  0.1839,  0.0962,  0.0429,  0.1289,\n",
       "                        0.0801,  0.2154,  0.0590,  0.1340,  0.0051,  0.1139,  0.1354,  0.0725,\n",
       "                        0.0868,  0.1185,  0.0393,  0.1304,  0.0267,  0.0952,  0.0575,  0.1193,\n",
       "                        0.1518,  0.0620,  0.1037,  0.1178,  0.0377,  0.1506,  0.0342,  0.1089,\n",
       "                       -0.0290,  0.1470,  0.0099,  0.1072, -0.0260,  0.0604, -0.0506,  0.0710,\n",
       "                       -0.0471, -0.0073, -0.0304, -0.0155, -0.0671, -0.0281, -0.0479, -0.0253,\n",
       "                       -0.0337, -0.0933,  0.0211, -0.1256,  0.0482, -0.1146,  0.0896, -0.1393,\n",
       "                        0.0797, -0.1318,  0.0568, -0.1466,  0.0819, -0.1368,  0.1026, -0.1599,\n",
       "                        0.1267, -0.1287,  0.0932, -0.1198,  0.1265, -0.1474,  0.1071, -0.1575,\n",
       "                        0.1229, -0.1281,  0.1074, -0.1252,  0.0996, -0.1556,  0.1208, -0.1420,\n",
       "                        0.1040, -0.1660,  0.0891, -0.1281,  0.1543, -0.1557,  0.1193, -0.1141,\n",
       "                        0.1128, -0.1357,  0.1385, -0.1451,  0.0854, -0.1641,  0.1281,  0.3021,\n",
       "                        0.1501, -0.1356,  0.1641, -0.1379,  0.1492, -0.1559,  0.1232, -0.1859,\n",
       "                        0.1310, -0.1406,  0.1516, -0.1568,  0.1263, -0.1311,  0.0990, -0.1638,\n",
       "                        0.1348, -0.1598,  0.0882, -0.1652,  0.1312, -0.1375,  0.1171, -0.1322])),\n",
       "              ('transformer_encoder.layers.0.linear1.weight',\n",
       "               tensor([[-0.0448, -0.0237, -0.0261,  ..., -0.0439, -0.0472,  0.0701],\n",
       "                       [ 0.0363,  0.1726,  0.1033,  ..., -0.0458,  0.1055,  0.0128],\n",
       "                       [ 0.0550,  0.0352, -0.0057,  ..., -0.0892,  0.2273, -0.0446],\n",
       "                       ...,\n",
       "                       [ 0.0966,  0.0968,  0.0085,  ..., -0.0399,  0.0620, -0.1203],\n",
       "                       [-0.0047, -0.0252,  0.1145,  ..., -0.1016,  0.0710, -0.0384],\n",
       "                       [-0.0551,  0.0180, -0.0513,  ..., -0.0995,  0.0900, -0.0755]])),\n",
       "              ('transformer_encoder.layers.0.linear1.bias',\n",
       "               tensor([-0.1256, -0.1693, -0.0700, -0.1601, -0.1032, -0.0758, -0.1043, -0.0412,\n",
       "                       -0.0560, -0.0852, -0.0883, -0.1354, -0.1252, -0.1180, -0.1740, -0.0746,\n",
       "                       -0.0993, -0.1078, -0.1479, -0.0761, -0.1278, -0.1046, -0.0680, -0.1196,\n",
       "                       -0.1041, -0.1677, -0.1184, -0.1217, -0.1700, -0.1135, -0.1075, -0.0942,\n",
       "                       -0.1269, -0.0780, -0.0651, -0.0449, -0.0740, -0.1031, -0.1933, -0.0770,\n",
       "                       -0.0565, -0.0941, -0.0828, -0.2089, -0.0195, -0.0203, -0.4689, -0.0361,\n",
       "                       -0.0513, -0.0569, -0.1049, -0.0246, -0.1693, -0.1569, -0.5556, -0.1088,\n",
       "                       -0.0185, -0.1311, -0.0744, -0.0693, -0.1285, -0.0977, -0.1917, -0.0830,\n",
       "                       -0.1619, -0.0896, -0.0434, -0.0892, -0.0137, -0.0318, -0.2303, -0.1325,\n",
       "                       -0.1546, -0.0280, -0.1186, -0.0713, -0.1494, -0.0972, -0.0674, -0.1350,\n",
       "                       -0.0198, -0.0058, -0.0616, -0.1586, -0.1751, -0.0797, -0.0655, -0.0778,\n",
       "                       -0.1356,  0.0047, -0.0932, -0.1466, -0.2044, -0.1429, -0.1858, -0.0800,\n",
       "                       -0.0890, -0.1074, -0.0968, -0.0289, -0.1542, -0.1046, -0.0235, -0.1496,\n",
       "                       -0.1615, -0.0323, -0.0735, -0.0298, -0.0367, -0.0539, -0.0897, -0.1047,\n",
       "                       -0.0726, -0.1013, -0.1136, -0.0437, -0.1420, -0.1204, -0.1246, -0.1375,\n",
       "                       -0.0182, -0.1083, -0.0875, -0.0480, -0.0077, -0.1086, -0.0334, -0.0159,\n",
       "                       -0.0502, -0.0810, -0.1392, -0.1347, -0.1099, -0.1623, -0.0620, -0.1324,\n",
       "                       -0.1363, -0.0507, -0.1849, -0.1659, -0.2110, -0.0654, -0.6088, -0.0672,\n",
       "                       -0.0929, -0.1830, -0.0483, -0.0541, -0.2039, -0.1357, -0.1682, -0.1190,\n",
       "                       -0.1287, -0.0212, -0.0962, -0.1836, -0.1805, -0.1270, -0.0994, -0.0402,\n",
       "                       -0.1491, -0.0673, -0.0748, -0.0944, -0.1747, -0.1541, -0.0565, -0.0716,\n",
       "                       -0.1257, -0.1436, -0.0881, -0.1499, -0.1290, -0.1865, -0.0810, -0.0560,\n",
       "                       -0.1437, -0.1287, -0.1177, -0.0987, -0.0699, -0.1314, -0.0923, -0.0444,\n",
       "                       -0.1171, -0.1729, -0.1452, -0.1130, -0.1599, -0.1908, -0.0984, -0.0729,\n",
       "                       -0.1270, -0.0226, -0.1882, -0.1144, -0.0939, -0.0916, -0.0445, -0.1705])),\n",
       "              ('transformer_encoder.layers.0.linear2.weight',\n",
       "               tensor([[-0.1343,  0.0156, -0.0823,  ..., -0.0136,  0.1661,  0.0489],\n",
       "                       [ 0.0578, -0.1012, -0.1221,  ..., -0.0834,  0.1333, -0.0065],\n",
       "                       [ 0.1296,  0.0051, -0.1353,  ...,  0.1194,  0.1655, -0.0444],\n",
       "                       ...,\n",
       "                       [ 0.0696,  0.0563, -0.1035,  ..., -0.0220,  0.1672,  0.0247],\n",
       "                       [-0.0706,  0.0676,  0.0194,  ...,  0.0344, -0.0403,  0.0064],\n",
       "                       [ 0.0795,  0.2071,  0.0348,  ...,  0.0056, -0.1003,  0.0252]])),\n",
       "              ('transformer_encoder.layers.0.linear2.bias',\n",
       "               tensor([ 5.1788e-02,  2.0741e-01,  5.2886e-01,  5.9835e-01, -5.5017e-01,\n",
       "                        6.8459e-01,  3.2326e-01,  1.6147e-02, -8.8489e-01,  2.3861e-01,\n",
       "                        3.6430e-01,  1.5806e-01,  2.8554e-01,  3.0252e-01, -3.7055e-01,\n",
       "                        4.2304e-02,  8.3549e-02,  2.2108e-01,  1.0752e-01,  4.4872e-02,\n",
       "                       -2.4724e-02,  7.4984e-02,  1.0794e-01,  8.2480e-02,  1.0231e-01,\n",
       "                        6.0256e-02,  3.4653e-02,  9.7974e-02, -2.3106e-02,  3.5191e-02,\n",
       "                       -4.6921e-03,  6.9275e-02,  6.3327e-02,  6.9898e-02,  9.3280e-02,\n",
       "                        6.8308e-02, -6.9448e-02,  8.3974e-02, -3.9547e-02,  1.0877e-01,\n",
       "                       -4.8343e-02,  1.0486e-01, -9.5590e-03,  9.1590e-02, -3.0378e-02,\n",
       "                        3.2244e-02, -1.7003e-02,  1.0482e-02, -6.8485e-02, -5.0399e-02,\n",
       "                        9.5619e-03, -2.6148e-02,  3.2964e-02,  8.4409e-05, -9.0015e-03,\n",
       "                       -8.9180e-02,  8.6227e-03, -6.9851e-02, -7.1314e-02, -6.7752e-02,\n",
       "                        1.0631e-01, -1.3217e-01, -3.1696e-03, -1.0583e-01,  8.0853e-02,\n",
       "                       -1.1951e-01,  1.6544e-03, -1.0284e-01,  7.8609e-02, -2.9596e-02,\n",
       "                        9.1706e-02, -1.3121e-01,  5.9299e-02, -1.0104e-01,  8.4073e-02,\n",
       "                       -1.0026e-01,  9.7655e-02, -1.1857e-01,  1.3593e-01, -1.7083e-01,\n",
       "                        6.5601e-02, -1.2423e-01,  7.8808e-02, -1.6637e-01,  8.5148e-03,\n",
       "                       -1.0211e-01,  2.4970e-02, -1.3245e-01,  1.4734e-01, -1.6263e-01,\n",
       "                        1.1047e-01, -1.4440e-01,  9.4543e-02, -6.2479e-02,  1.5053e-01,\n",
       "                       -1.4675e-01,  6.4459e-02, -9.2229e-02,  1.5373e-01, -1.5860e-01,\n",
       "                        1.3014e-01, -9.1931e-02,  1.1784e-01,  2.2254e-01,  8.6415e-02,\n",
       "                       -1.4113e-01,  1.3347e-01, -1.9067e-01,  1.7186e-01, -1.8448e-01,\n",
       "                        1.1106e-01, -1.3194e-01,  1.3271e-01, -7.7557e-02,  8.3062e-02,\n",
       "                       -1.3773e-01,  1.6922e-01, -1.2109e-01,  1.4911e-01, -1.2933e-01,\n",
       "                        6.5315e-02, -1.0356e-01,  1.1397e-01, -1.0531e-01,  1.2559e-01,\n",
       "                       -1.5469e-01,  5.0813e-02, -1.5965e-01])),\n",
       "              ('transformer_encoder.layers.0.norm1.weight',\n",
       "               tensor([-5.5756e-03, -1.1387e-02, -4.2571e-02, -1.3714e-03,  2.4862e-02,\n",
       "                        6.2355e-03,  2.1935e-02,  3.9417e-02,  1.4072e+00, -6.9213e-03,\n",
       "                        3.7524e-02,  7.9548e-02,  9.2413e-02,  1.7090e-01,  6.8756e-01,\n",
       "                        1.0685e-01,  1.1147e-01,  1.8885e-01,  1.9570e-01,  1.2985e-01,\n",
       "                        2.6447e-01,  2.3936e-01,  3.1620e-01,  4.3074e-01,  4.5171e-01,\n",
       "                        4.9051e-01,  5.7821e-01,  5.7437e-01,  6.9171e-01,  5.3819e-01,\n",
       "                        6.4612e-01,  7.4035e-01,  6.9512e-01,  7.7863e-01,  6.3090e-01,\n",
       "                        7.7727e-01,  9.6077e-01,  8.5803e-01,  1.0752e+00,  8.8938e-01,\n",
       "                        1.1231e+00,  9.7295e-01,  1.2043e+00,  8.5694e-01,  1.1826e+00,\n",
       "                        9.3512e-01,  1.1458e+00,  9.7132e-01,  1.0854e+00,  1.1503e+00,\n",
       "                        1.1381e+00,  1.1312e+00,  9.6016e-01,  1.1949e+00,  1.1920e+00,\n",
       "                        1.2277e+00,  1.2608e+00,  1.0746e+00,  1.2330e+00,  1.1272e+00,\n",
       "                        1.1509e+00,  1.1645e+00,  1.2626e+00,  1.1291e+00,  1.2690e+00,\n",
       "                        1.2129e+00,  1.1125e+00,  1.2135e+00,  1.1410e+00,  9.7686e-01,\n",
       "                        1.2848e+00,  1.1839e+00,  1.2684e+00,  1.0500e+00,  1.1819e+00,\n",
       "                        1.0744e+00,  1.1717e+00,  1.1348e+00,  1.2043e+00,  1.1012e+00,\n",
       "                        1.2955e+00,  1.0953e+00,  1.1948e+00,  1.0815e+00,  1.2016e+00,\n",
       "                        1.0897e+00,  1.0975e+00,  1.1051e+00,  1.1907e+00,  1.1083e+00,\n",
       "                        1.1415e+00,  1.0458e+00,  1.0666e+00,  1.0841e+00,  1.1289e+00,\n",
       "                        1.0935e+00,  1.1897e+00,  1.1684e+00,  1.0235e+00,  1.0329e+00,\n",
       "                        1.1482e+00,  1.0330e+00,  1.1078e+00,  7.7996e-01,  1.1911e+00,\n",
       "                        1.1354e+00,  1.2294e+00,  1.1574e+00,  1.1217e+00,  1.1572e+00,\n",
       "                        1.1767e+00,  1.0490e+00,  9.9773e-01,  1.0502e+00,  1.2004e+00,\n",
       "                        1.0914e+00,  1.1616e+00,  1.0701e+00,  1.2186e+00,  1.1228e+00,\n",
       "                        1.1417e+00,  1.1188e+00,  1.2279e+00,  1.0706e+00,  1.1275e+00,\n",
       "                        1.0716e+00,  1.2332e+00,  1.1153e+00])),\n",
       "              ('transformer_encoder.layers.0.norm1.bias',\n",
       "               tensor([-3.5570e-01, -2.6650e-01, -9.1292e-02,  4.2974e-01, -4.6397e-01,\n",
       "                        3.9016e-01,  3.9668e-01,  9.8330e-03, -8.4973e-01,  2.7836e-01,\n",
       "                        3.7272e-01,  3.2147e-01,  3.2097e-01,  3.2229e-01, -4.8581e-01,\n",
       "                        6.8066e-02,  1.2239e-02,  3.3635e-01,  1.9210e-01,  1.2184e-01,\n",
       "                        8.1892e-02,  1.6239e-01,  1.6904e-01,  1.2203e-01,  7.7334e-02,\n",
       "                        1.0540e-01,  5.5359e-02,  1.0530e-01,  1.5783e-01,  8.4335e-02,\n",
       "                        5.6226e-02,  8.8227e-02,  1.0097e-01,  6.4607e-02,  9.6136e-02,\n",
       "                        1.4413e-01,  8.3758e-02,  1.5278e-01,  4.5222e-03,  1.3336e-01,\n",
       "                       -3.9748e-02,  1.0110e-01, -2.9038e-02,  7.9563e-02, -3.3466e-02,\n",
       "                        1.2466e-01, -9.0657e-02,  8.5047e-02, -2.6396e-02, -5.3506e-04,\n",
       "                       -9.1571e-02, -8.8852e-03, -5.5888e-02, -4.8374e-02, -5.1256e-02,\n",
       "                       -4.7937e-02, -4.4539e-02, -1.0239e-01,  1.5370e-02, -1.2481e-01,\n",
       "                        3.9375e-02, -9.6372e-02,  6.3393e-02, -1.2370e-01,  6.4542e-02,\n",
       "                       -1.2226e-01,  6.2847e-02, -1.5509e-01,  7.9162e-02, -1.6649e-01,\n",
       "                        8.0575e-02, -1.3008e-01,  8.8196e-02, -1.5537e-01,  8.8134e-02,\n",
       "                       -1.2100e-01,  1.0674e-01, -1.5624e-01,  9.5976e-02, -1.5326e-01,\n",
       "                        1.0173e-01, -1.1853e-01,  1.1923e-01, -1.0545e-01,  1.0310e-01,\n",
       "                       -1.2069e-01,  1.3455e-01, -1.4646e-01,  9.9532e-02, -1.3515e-01,\n",
       "                        8.5172e-02, -1.0583e-01,  1.2835e-01, -1.6549e-01,  1.1533e-01,\n",
       "                       -1.1601e-01,  1.0163e-01, -1.5492e-01,  7.5129e-02, -1.1566e-01,\n",
       "                        1.2389e-01, -1.6150e-01,  9.4020e-02,  1.4093e-01,  1.5884e-01,\n",
       "                       -1.4722e-01,  1.4608e-01, -1.1522e-01,  9.5326e-02, -1.2855e-01,\n",
       "                        1.2255e-01, -1.7962e-01,  1.2254e-01, -1.5662e-01,  1.2706e-01,\n",
       "                       -1.4824e-01,  1.1169e-01, -1.0926e-01,  5.4060e-02, -1.4235e-01,\n",
       "                        1.6539e-01, -1.6039e-01,  6.3081e-02, -1.5503e-01,  1.0038e-01,\n",
       "                       -1.1769e-01,  1.4005e-01, -1.3930e-01])),\n",
       "              ('transformer_encoder.layers.0.norm2.weight',\n",
       "               tensor([-9.5713e-03,  1.2197e-02, -1.4157e-03,  8.5107e-02,  1.3159e-02,\n",
       "                        1.1875e-01,  2.0245e-01, -4.7570e-03, -1.1229e-03,  5.7840e-02,\n",
       "                        9.1386e-02,  1.0637e-01,  1.3874e-01,  4.7009e-02,  4.4217e-02,\n",
       "                        1.2295e-01,  3.8620e-02,  1.5450e-01,  1.2516e-01,  1.4040e-01,\n",
       "                        2.8670e-01,  2.8275e-01,  2.7705e-01,  4.6936e-01,  4.5292e-01,\n",
       "                        4.6909e-01,  5.6557e-01,  5.3414e-01,  4.3972e-01,  4.6741e-01,\n",
       "                        5.7356e-01,  6.4105e-01,  6.5527e-01,  6.7090e-01,  5.4615e-01,\n",
       "                        7.2739e-01,  7.7757e-01,  8.1574e-01,  9.0082e-01,  8.7443e-01,\n",
       "                        9.9168e-01,  9.3854e-01,  1.1028e+00,  7.6581e-01,  1.1054e+00,\n",
       "                        7.5781e-01,  1.1213e+00,  8.2648e-01,  9.3625e-01,  1.0250e+00,\n",
       "                        1.0335e+00,  1.0207e+00,  8.3442e-01,  1.0517e+00,  1.0832e+00,\n",
       "                        1.1543e+00,  1.1318e+00,  1.0216e+00,  1.0584e+00,  1.1409e+00,\n",
       "                        1.0388e+00,  1.1786e+00,  1.1214e+00,  1.1891e+00,  1.1072e+00,\n",
       "                        1.2402e+00,  9.5084e-01,  1.2817e+00,  1.0453e+00,  8.8504e-01,\n",
       "                        1.1912e+00,  1.2099e+00,  1.0647e+00,  1.0681e+00,  1.0414e+00,\n",
       "                        1.0846e+00,  1.0460e+00,  1.1576e+00,  1.0447e+00,  1.1595e+00,\n",
       "                        1.1697e+00,  1.0059e+00,  1.1541e+00,  1.0519e+00,  1.0331e+00,\n",
       "                        1.0844e+00,  9.8979e-01,  1.0603e+00,  1.0932e+00,  1.1532e+00,\n",
       "                        1.0170e+00,  9.7781e-01,  9.2409e-01,  1.0936e+00,  1.0409e+00,\n",
       "                        1.0914e+00,  1.1093e+00,  1.2209e+00,  8.1571e-01,  9.9288e-01,\n",
       "                        1.0695e+00,  1.0119e+00,  1.0283e+00,  9.0067e-01,  1.0689e+00,\n",
       "                        1.1499e+00,  1.2396e+00,  1.2211e+00,  1.0264e+00,  1.1421e+00,\n",
       "                        1.0291e+00,  1.1169e+00,  8.5502e-01,  1.0411e+00,  1.1431e+00,\n",
       "                        1.0804e+00,  1.0553e+00,  1.0936e+00,  1.1274e+00,  1.1295e+00,\n",
       "                        9.9074e-01,  1.1477e+00,  1.1023e+00,  1.0978e+00,  1.0285e+00,\n",
       "                        1.0106e+00,  1.1945e+00,  1.1922e+00])),\n",
       "              ('transformer_encoder.layers.0.norm2.bias',\n",
       "               tensor([ 2.7258e-03, -3.5419e-03, -3.2129e-03, -6.8565e-02,  8.6787e-03,\n",
       "                       -1.0738e-01, -9.9552e-02, -4.2410e-03, -1.4086e-02, -2.9972e-02,\n",
       "                       -5.2831e-02, -4.7741e-02, -7.6100e-02, -4.6112e-02,  1.1194e-01,\n",
       "                       -1.9511e-02, -7.5888e-03, -6.4137e-02, -6.4866e-02, -2.7549e-02,\n",
       "                       -2.3963e-02, -4.8821e-02, -3.9082e-02, -4.4698e-02, -2.0469e-02,\n",
       "                        1.0167e-01, -7.4399e-02,  9.8220e-02, -1.1673e-01,  6.1244e-02,\n",
       "                       -2.7102e-03, -1.3442e-02, -9.4468e-02,  5.2521e-02, -9.3778e-03,\n",
       "                       -3.6731e-02, -9.1631e-02, -3.3930e-02, -7.8925e-02, -3.4677e-04,\n",
       "                       -1.7040e-02,  5.6812e-02, -1.0707e-02, -3.5333e-03,  1.0268e-02,\n",
       "                       -1.0679e-01, -4.4242e-02, -9.7000e-03, -9.0473e-02, -9.0425e-02,\n",
       "                        6.2496e-02, -1.5392e-02,  6.1961e-02,  2.2861e-02, -2.6188e-02,\n",
       "                       -7.0575e-02, -6.3765e-02, -8.9146e-02, -8.2600e-02, -1.0383e-01,\n",
       "                        3.7598e-02, -3.8303e-02,  5.1432e-03, -1.9798e-02, -3.6244e-03,\n",
       "                       -9.6165e-02,  3.2006e-02, -9.5273e-02, -1.4434e-02,  7.9903e-03,\n",
       "                       -2.2108e-02, -5.5996e-02,  5.0369e-02, -7.1930e-02, -3.9262e-03,\n",
       "                       -1.0515e-01,  1.4295e-02, -1.1908e-01,  4.9635e-02, -1.0298e-01,\n",
       "                        8.7569e-02, -1.3402e-01, -5.2273e-02, -1.3099e-01,  1.7209e-02,\n",
       "                       -3.8361e-02, -3.2895e-02,  2.8482e-02, -8.8692e-03, -8.0707e-02,\n",
       "                        7.7176e-02, -9.6015e-02, -4.2514e-02, -1.2546e-01,  6.0139e-03,\n",
       "                       -4.1539e-02,  5.1220e-02, -5.9103e-02,  5.2868e-02, -1.4170e-01,\n",
       "                        5.5227e-02, -1.4537e-01, -4.1920e-03,  4.5596e-01,  1.0250e-02,\n",
       "                       -1.1320e-01, -9.1047e-03, -1.4952e-01,  2.9587e-02, -1.3790e-01,\n",
       "                        4.4752e-02, -6.1019e-02,  2.6693e-02, -2.9195e-02,  1.4061e-02,\n",
       "                       -4.5027e-02,  2.1866e-02, -8.4010e-02,  4.6875e-02, -9.4524e-02,\n",
       "                       -7.6180e-02, -1.0342e-01,  5.5879e-02, -8.4108e-02,  1.1079e-02,\n",
       "                       -1.3387e-01,  4.8171e-02, -5.2270e-02])),\n",
       "              ('transformer_encoder.layers.1.self_attn.in_proj_weight',\n",
       "               tensor([[ 0.0787,  0.0239, -0.0085,  ...,  0.1206, -0.0901, -0.1967],\n",
       "                       [ 0.0116,  0.0224, -0.1501,  ..., -0.1098, -0.0410,  0.1096],\n",
       "                       [-0.1749, -0.0879,  0.1495,  ..., -0.1981, -0.2030, -0.0507],\n",
       "                       ...,\n",
       "                       [-0.0301,  0.0100,  0.0037,  ...,  0.0339,  0.2575, -0.0486],\n",
       "                       [ 0.0249, -0.0396, -0.0393,  ..., -0.0660,  0.0421, -0.0652],\n",
       "                       [ 0.0089,  0.0161,  0.0691,  ...,  0.0223, -0.3025,  0.2531]])),\n",
       "              ('transformer_encoder.layers.1.self_attn.in_proj_bias',\n",
       "               tensor([ 1.2322e-01, -9.3024e-02,  1.2877e-01, -5.0651e-02,  2.7514e-01,\n",
       "                       -8.4013e-02, -9.8691e-02, -3.4756e-02, -1.7157e-01, -2.6195e-01,\n",
       "                       -1.0323e-01,  3.7068e-02,  9.7974e-02,  3.0192e-03,  8.6860e-02,\n",
       "                        3.2952e-03,  2.1028e-01,  4.1237e-03,  1.7985e-01,  5.2923e-03,\n",
       "                       -1.9090e-01,  3.9451e-02,  1.5243e-01,  8.5806e-02,  6.0769e-02,\n",
       "                       -1.1355e-01, -1.2611e-01,  1.1845e-01, -8.0000e-02, -6.5969e-02,\n",
       "                        4.8245e-02,  3.0871e-01, -8.0396e-03, -6.8211e-02,  1.8365e-02,\n",
       "                       -2.6586e-01, -1.5253e-01,  1.2637e-01,  5.9435e-02,  2.2293e-02,\n",
       "                        8.4878e-02, -2.1843e-02, -1.3615e-01,  1.3931e-01, -9.0882e-02,\n",
       "                        1.1147e-01,  1.5906e-01, -1.9820e-01,  8.3491e-02,  2.4459e-01,\n",
       "                       -2.0472e-02,  5.5643e-02, -3.4819e-01, -2.9288e-01, -1.0153e-01,\n",
       "                       -5.1961e-02,  1.2184e-01,  6.3774e-02,  9.3773e-02,  1.1849e-01,\n",
       "                       -8.3740e-02, -1.6825e-01, -2.0888e-01,  8.7833e-02,  7.5272e-02,\n",
       "                       -2.1982e-01,  7.3034e-02, -4.3374e-02, -1.1839e-01,  7.9040e-02,\n",
       "                        1.7237e-01,  1.0243e-01,  1.3028e-01, -3.9232e-02, -2.7683e-03,\n",
       "                       -2.1486e-01,  3.2996e-02, -3.8968e-02, -5.9800e-02,  5.3239e-02,\n",
       "                        6.8983e-02,  2.2473e-02,  6.7764e-02, -1.6524e-02,  3.9166e-02,\n",
       "                       -6.6097e-02,  1.9997e-01, -1.9050e-01,  2.9348e-01,  6.2948e-02,\n",
       "                        8.8846e-02,  9.5584e-02,  1.6297e-01, -1.1606e-01, -9.4840e-02,\n",
       "                       -2.4778e-02,  3.4788e-01, -1.1181e-01, -6.6238e-02,  7.9702e-02,\n",
       "                        9.7346e-02,  7.0472e-02, -1.5657e-01,  1.0952e-01,  3.4489e-02,\n",
       "                       -3.9539e-02, -2.0569e-02, -3.6754e-02,  1.5671e-01, -1.8326e-01,\n",
       "                        3.2147e-02,  8.7587e-02,  2.3745e-02, -6.2591e-02, -2.7868e-02,\n",
       "                        3.5529e-02, -1.2475e-01, -1.1492e-01,  6.6128e-02, -2.3368e-01,\n",
       "                        5.3713e-02, -9.4433e-02, -6.7704e-02,  1.1823e-01,  1.8698e-01,\n",
       "                       -7.5955e-02, -4.9451e-02, -3.6370e-02,  1.0583e-03,  2.5929e-04,\n",
       "                       -2.7759e-04,  6.0940e-04, -7.5120e-04,  6.0584e-04,  7.4446e-04,\n",
       "                       -3.3220e-04,  6.0207e-04, -2.9001e-04,  5.9608e-04, -1.3624e-04,\n",
       "                       -8.6048e-04, -1.1841e-04, -5.1640e-05, -2.3785e-04, -2.3440e-04,\n",
       "                       -1.0673e-03, -1.2349e-04,  4.6712e-04,  8.0845e-04, -2.0118e-05,\n",
       "                        2.0747e-04, -3.4865e-04, -1.5877e-05,  1.9934e-04,  1.4761e-04,\n",
       "                       -5.6811e-04, -5.6743e-04, -1.6821e-04,  1.6274e-04, -3.6464e-04,\n",
       "                       -3.4343e-04, -2.7393e-04,  1.5407e-04, -2.9533e-04, -3.7310e-04,\n",
       "                        2.0492e-04, -4.0299e-05, -3.3461e-04,  3.3805e-04, -7.2363e-06,\n",
       "                       -5.9757e-04,  4.0136e-04,  4.1217e-04, -8.6825e-06,  5.6950e-05,\n",
       "                        3.4087e-04,  3.4723e-04, -2.1536e-04, -5.9510e-05, -1.8291e-04,\n",
       "                        6.1779e-04, -6.1602e-05, -1.0943e-04,  4.2306e-05, -1.6899e-04,\n",
       "                       -7.1318e-05, -1.8354e-04,  5.9224e-05,  3.2792e-04,  8.9744e-04,\n",
       "                        8.0216e-05,  3.1193e-04,  2.1322e-04, -2.6275e-04,  2.6427e-04,\n",
       "                       -1.1536e-04, -2.8197e-04,  1.6123e-04,  3.5830e-04,  2.2387e-04,\n",
       "                       -6.5275e-05, -2.4917e-04, -2.7307e-04, -3.4807e-04,  2.9461e-04,\n",
       "                       -1.4646e-04, -3.2580e-04,  8.2075e-05,  3.4027e-04, -1.1177e-04,\n",
       "                        3.3340e-04, -2.9908e-04, -4.4165e-04,  4.4219e-04,  3.0081e-04,\n",
       "                       -4.9925e-04,  2.8090e-04,  3.6181e-04,  3.8176e-05,  3.3212e-05,\n",
       "                       -1.6828e-04, -2.4075e-05, -1.9755e-05,  3.4711e-04,  3.8225e-04,\n",
       "                        1.2242e-06, -4.2597e-04, -4.1959e-04, -3.2291e-04,  1.1109e-04,\n",
       "                       -1.7937e-04,  7.8418e-05,  3.4797e-04,  9.3143e-05, -4.0725e-04,\n",
       "                       -3.1426e-04, -1.0128e-04,  2.3799e-04,  3.4308e-04,  4.1480e-04,\n",
       "                        9.2020e-05, -1.8218e-04,  2.0407e-04,  5.1124e-05,  5.3916e-04,\n",
       "                        2.7399e-06, -3.4089e-05, -2.5038e-05,  2.7251e-04, -4.0364e-04,\n",
       "                        1.5692e-04,  6.4494e-05, -8.3356e-05, -5.5063e-05, -1.6583e-05,\n",
       "                        1.3463e-04, -8.5417e-02,  1.1325e-02, -3.6146e-02,  6.3904e-02,\n",
       "                        5.4970e-02, -5.0138e-02,  5.0044e-02,  1.9362e-02,  5.4251e-02,\n",
       "                       -2.7442e-02, -1.1029e-01, -4.9482e-02,  2.4373e-02,  6.4916e-02,\n",
       "                        2.5366e-02, -1.8785e-03, -3.5730e-02,  2.5104e-03, -1.7675e-02,\n",
       "                        9.7055e-03, -3.4669e-02, -2.1026e-02, -1.2401e-02,  3.3755e-02,\n",
       "                       -6.5564e-02,  8.0467e-02, -1.2088e-02, -2.2614e-02,  3.9947e-02,\n",
       "                        4.7036e-02,  3.3354e-02, -1.5703e-03,  2.5390e-02, -9.0343e-03,\n",
       "                       -2.6768e-02, -3.1987e-02,  2.8501e-02, -1.7811e-02,  8.8159e-02,\n",
       "                       -3.5484e-02,  4.6686e-02, -5.4388e-02, -2.5955e-02,  9.8130e-03,\n",
       "                       -3.9941e-02,  9.5563e-02, -4.9419e-02, -2.7449e-02, -3.9137e-03,\n",
       "                        3.2798e-02,  6.5422e-02,  1.3277e-02,  7.6503e-03,  2.4262e-02,\n",
       "                        9.9086e-03,  1.9493e-02, -4.3260e-02, -4.4553e-03,  6.4483e-03,\n",
       "                        1.2487e-02, -3.1486e-02,  3.2984e-03, -7.7113e-02,  1.0340e-02,\n",
       "                        1.4639e-02,  5.2681e-02,  1.1822e-02,  6.3201e-02,  3.3222e-03,\n",
       "                       -2.5567e-02, -5.4581e-02,  4.8873e-02,  2.4269e-02,  3.5808e-02,\n",
       "                       -5.8448e-02, -6.5877e-02,  2.6685e-02, -1.2205e-02, -2.7850e-02,\n",
       "                       -9.2702e-03,  3.1715e-02, -3.5926e-02,  5.0392e-02, -9.8095e-02,\n",
       "                        1.8848e-02, -3.9107e-02,  2.6524e-02, -1.3322e-02,  3.4969e-03,\n",
       "                       -3.5888e-02, -9.8543e-02,  7.4226e-04,  4.5809e-02, -6.0855e-02,\n",
       "                        2.4881e-02,  1.0327e-01,  3.0374e-02, -3.5879e-02,  2.8943e-02,\n",
       "                       -6.0422e-02,  2.5620e-02, -7.4278e-02,  3.5860e-02, -5.1575e-03,\n",
       "                       -7.8506e-02, -3.3155e-02,  8.7269e-03, -1.9540e-02,  4.6943e-02,\n",
       "                        3.2154e-02, -2.5399e-02,  4.5840e-02,  5.9976e-04, -2.4832e-05,\n",
       "                       -3.8635e-03,  4.6292e-02,  1.5678e-02,  1.7910e-02, -6.6084e-02,\n",
       "                        2.3003e-02,  5.0860e-02,  2.8670e-02,  3.4532e-02,  1.1363e-03,\n",
       "                        7.4023e-02,  1.7671e-02, -4.9246e-02, -5.0772e-02])),\n",
       "              ('transformer_encoder.layers.1.self_attn.out_proj.weight',\n",
       "               tensor([[ 0.0275, -0.1379,  0.1238,  ...,  0.1701,  0.0368,  0.1352],\n",
       "                       [ 0.0326, -0.0417, -0.0785,  ..., -0.2448,  0.1982, -0.2592],\n",
       "                       [-0.1091,  0.1606,  0.0299,  ..., -0.1903, -0.0210, -0.0694],\n",
       "                       ...,\n",
       "                       [ 0.1583,  0.0044, -0.1294,  ..., -0.1287,  0.0126, -0.0183],\n",
       "                       [ 0.0764, -0.0071,  0.0496,  ..., -0.1850, -0.0077,  0.2484],\n",
       "                       [ 0.1701, -0.1405, -0.1045,  ..., -0.1449,  0.0905, -0.2168]])),\n",
       "              ('transformer_encoder.layers.1.self_attn.out_proj.bias',\n",
       "               tensor([-6.5551e-02, -2.2422e-01, -3.9916e-01, -2.2370e-02, -4.3167e-01,\n",
       "                       -9.7348e-01,  3.1850e-01,  1.6317e-01, -6.0329e-01, -7.8767e-02,\n",
       "                        9.9127e-03,  1.1461e-01,  2.9799e-02, -7.3271e-02, -5.5278e-01,\n",
       "                        1.0229e-02, -1.5212e-01,  2.1556e-01,  1.4093e-02, -1.0184e-01,\n",
       "                        1.4003e-01,  3.0869e-02, -1.6726e-02, -1.7324e-01, -2.1212e-01,\n",
       "                       -5.0813e-02,  1.5697e-02, -1.4899e-02,  1.2402e-01,  3.0326e-02,\n",
       "                       -3.7705e-02, -8.4937e-02, -7.6898e-02, -5.7646e-02, -9.1415e-02,\n",
       "                       -6.0886e-03,  6.3975e-02, -1.3083e-01,  1.4667e-02, -1.6152e-02,\n",
       "                        3.9482e-02, -8.9139e-02,  6.6077e-03, -1.8031e-01, -2.5200e-02,\n",
       "                        3.5513e-02, -8.3844e-02,  7.8795e-02,  6.8948e-02,  2.8630e-02,\n",
       "                       -7.7685e-04, -4.3505e-02,  6.2109e-03, -7.8463e-03,  2.2956e-02,\n",
       "                        3.2400e-02,  7.8262e-02,  5.9042e-02, -7.7965e-02, -2.6145e-02,\n",
       "                       -5.9992e-02,  9.1470e-02,  2.1797e-02,  4.3477e-02, -6.8818e-02,\n",
       "                        3.8897e-02,  3.9133e-02,  8.1982e-02, -2.2282e-02,  7.6121e-02,\n",
       "                        6.6119e-04, -1.4036e-02, -8.1106e-02, -1.2714e-02, -2.0617e-01,\n",
       "                        2.8552e-02, -2.2323e-02,  1.6178e-02, -7.6475e-02,  9.8561e-03,\n",
       "                        3.7671e-04,  1.6605e-01, -1.0177e-01,  6.8795e-02,  1.5835e-02,\n",
       "                        1.4484e-01, -3.8473e-02,  9.5303e-02, -9.2672e-02,  8.2358e-02,\n",
       "                        5.5975e-02,  3.6344e-02, -1.3098e-01, -5.4630e-02, -8.3687e-02,\n",
       "                        1.3688e-01,  2.6788e-02,  2.4224e-02, -8.9856e-02, -2.1531e-02,\n",
       "                       -1.1448e-01,  8.5444e-02, -2.6034e-01,  7.9185e-01, -1.5687e-01,\n",
       "                        1.7296e-02, -6.5254e-02,  1.2553e-01, -1.5472e-01,  1.2336e-01,\n",
       "                       -5.8035e-02,  8.8673e-02, -9.7332e-02, -3.1605e-02, -1.2657e-01,\n",
       "                        1.4567e-01, -2.8487e-02,  6.6956e-02,  7.6152e-04,  1.2186e-01,\n",
       "                       -1.8458e-01, -4.2982e-03, -2.3946e-02,  9.9888e-03, -2.9633e-02,\n",
       "                        3.7821e-02,  5.9537e-02,  1.1967e-01])),\n",
       "              ('transformer_encoder.layers.1.linear1.weight',\n",
       "               tensor([[ 1.0243e-01,  5.0836e-02,  1.3312e-01,  ..., -9.6557e-02,\n",
       "                        -1.4508e-04,  3.9798e-02],\n",
       "                       [-5.3359e-02,  1.7852e-01,  1.0986e-02,  ...,  8.4736e-02,\n",
       "                         2.4312e-01, -1.5764e-01],\n",
       "                       [ 1.3277e-01,  1.5467e-01,  2.1325e-01,  ..., -1.8094e-01,\n",
       "                         4.0096e-02, -3.3304e-01],\n",
       "                       ...,\n",
       "                       [ 9.3809e-02,  2.0886e-01, -8.2726e-02,  ...,  1.8896e-02,\n",
       "                        -1.9253e-02,  1.4311e-01],\n",
       "                       [ 6.1735e-03, -7.9294e-02,  4.9792e-02,  ...,  9.7251e-02,\n",
       "                        -5.5725e-02, -1.6849e-01],\n",
       "                       [-1.2432e-01,  1.6996e-01,  1.8245e-01,  ..., -2.5352e-01,\n",
       "                         8.0641e-02, -2.3836e-01]])),\n",
       "              ('transformer_encoder.layers.1.linear1.bias',\n",
       "               tensor([-0.3029, -0.4009, -0.3491, -0.3374, -0.2484, -0.2748, -0.1386, -0.2849,\n",
       "                       -0.2349, -0.3355, -0.1447, -0.3622, -0.3349, -0.2262, -0.2630, -0.2480,\n",
       "                       -0.2531, -0.2267, -0.2874, -0.3011, -0.1834, -0.2683, -0.2324, -0.3121,\n",
       "                       -0.3252, -0.3338, -0.2270, -0.3184, -0.4195, -0.2231, -0.2711, -0.2471,\n",
       "                       -0.2357, -0.2932, -0.3053, -0.2230, -0.2787, -0.2712, -0.2925, -0.2808,\n",
       "                       -0.1878, -0.2937, -0.2633, -0.3457, -0.1759, -0.2187, -0.2781, -0.1721,\n",
       "                       -0.2422, -0.3161, -0.2734, -0.2694, -0.4395, -0.3617, -0.3267, -0.3057,\n",
       "                       -0.2402, -0.3072, -0.2830, -0.3140, -0.2804, -0.1617, -0.2674, -0.2173,\n",
       "                       -0.3916, -0.2341, -0.2624, -0.2791, -0.2218, -0.0665, -0.3936, -0.3480,\n",
       "                       -0.3427, -0.3646, -0.2831, -0.2784, -0.3023, -0.2322, -0.1642, -0.2534,\n",
       "                       -0.2272, -0.1520, -0.2088, -0.3030, -0.3532, -0.2229, -0.2323, -0.2078,\n",
       "                       -0.3229, -0.2154, -0.2207, -0.3378, -0.3803, -0.2788, -0.3616, -0.2762,\n",
       "                       -0.2843, -0.3111, -0.2811, -0.2111, -0.2996, -0.2437, -0.1686, -0.3378,\n",
       "                       -0.2618, -0.1357, -0.2468, -0.3184, -0.1880, -0.3012, -0.1531, -0.2235,\n",
       "                       -0.1876, -0.2846, -0.3107, -0.2840, -0.3061, -0.1642, -0.1999, -0.2607,\n",
       "                       -0.2315, -0.3383, -0.2426, -0.2041, -0.2070, -0.2494, -0.3645, -0.2335,\n",
       "                       -0.2384, -0.2633, -0.2466, -0.3131, -0.2972, -0.3042, -0.2100, -0.1397,\n",
       "                       -0.2819, -0.2526, -0.2701, -0.4057, -0.3276, -0.2580, -0.3538, -0.3566,\n",
       "                       -0.2590, -0.3177, -0.1852, -0.2360, -0.4007, -0.3290, -0.3815,  0.0135,\n",
       "                       -0.3743, -0.2802, -0.2736, -0.4061, -0.3556, -0.2726, -0.2475, -0.2034,\n",
       "                       -0.3203, -0.2635, -0.2871, -0.3216, -0.3652, -0.3911, -0.1719, -0.2170,\n",
       "                       -0.3003, -0.2714, -0.2746, -0.3821, -0.2891, -0.3023, -0.2403, -0.2369,\n",
       "                       -0.2997, -0.2749, -0.1845, -0.2875, -0.2410, -0.3406, -0.2548, -0.1340,\n",
       "                       -0.3114, -0.3564, -0.3245, -0.3136, -0.2272, -0.3489, -0.2398, -0.2320,\n",
       "                       -0.2736, -0.1542, -0.3903, -0.3822, -0.2960, -0.3059, -0.1707, -0.3171])),\n",
       "              ('transformer_encoder.layers.1.linear2.weight',\n",
       "               tensor([[-0.2158,  0.4361, -0.0085,  ..., -0.3172,  0.1980,  0.2277],\n",
       "                       [ 0.0725, -0.0699, -0.0699,  ..., -0.2880, -0.1111, -0.0678],\n",
       "                       [ 0.1243,  0.2210,  0.0195,  ..., -0.0527,  0.0578,  0.0222],\n",
       "                       ...,\n",
       "                       [ 0.0635,  0.0185,  0.0308,  ...,  0.3388,  0.0226, -0.0272],\n",
       "                       [-0.0239,  0.0307,  0.0528,  ...,  0.0050, -0.1663, -0.0765],\n",
       "                       [ 0.0913,  0.0352, -0.0363,  ..., -0.0219,  0.0234, -0.1808]])),\n",
       "              ('transformer_encoder.layers.1.linear2.bias',\n",
       "               tensor([-0.0162,  0.0459,  0.0832,  0.0290, -0.0041, -0.4583,  0.0057, -0.1306,\n",
       "                        0.0557,  0.1169,  0.0584, -0.0730,  0.1153,  0.0359, -0.1849,  0.0180,\n",
       "                       -0.0019,  0.0795,  0.0449, -0.0054, -0.0559,  0.0199,  0.0495,  0.0876,\n",
       "                        0.0359, -0.0183,  0.0295,  0.0443,  0.0365, -0.0382, -0.0009,  0.0510,\n",
       "                        0.0593, -0.0042,  0.0721,  0.0251,  0.0021,  0.0677, -0.0328,  0.0707,\n",
       "                       -0.0409, -0.0140,  0.0392,  0.0813, -0.0177, -0.0112,  0.0699, -0.0483,\n",
       "                       -0.0646, -0.0366, -0.0955, -0.0361,  0.0173, -0.0528,  0.0040, -0.0446,\n",
       "                        0.1219, -0.0416, -0.0216, -0.0466,  0.0307, -0.0856, -0.0464, -0.0639,\n",
       "                        0.0886, -0.0865, -0.0070, -0.0172,  0.0707, -0.0794,  0.1001, -0.0843,\n",
       "                       -0.0207, -0.0645,  0.1032, -0.0710,  0.0627, -0.0772,  0.0845, -0.0727,\n",
       "                       -0.0670, -0.0831,  0.0990, -0.1102, -0.0018, -0.0571,  0.0378, -0.1877,\n",
       "                        0.1136, -0.0655,  0.0395, -0.1171,  0.1209,  0.0221,  0.0921, -0.1682,\n",
       "                       -0.0051, -0.0626,  0.0329, -0.0494,  0.0936, -0.0298,  0.1372,  0.3422,\n",
       "                       -0.0065, -0.0433,  0.0665, -0.1527,  0.0885, -0.0539,  0.0232, -0.0800,\n",
       "                        0.0950, -0.0460, -0.0035, -0.0826,  0.0956, -0.0675,  0.0104, -0.0586,\n",
       "                        0.0985, -0.0294,  0.0771, -0.0314,  0.0214, -0.0831,  0.0256, -0.1904])),\n",
       "              ('transformer_encoder.layers.1.norm1.weight',\n",
       "               tensor([0.5508, 0.7249, 0.6250, 0.7367, 0.8640, 1.1584, 0.8938, 0.7266, 0.9501,\n",
       "                       0.8361, 0.7876, 0.7769, 0.7977, 0.7866, 1.2474, 0.6567, 0.7281, 0.7274,\n",
       "                       0.7245, 0.7638, 0.8188, 0.7919, 0.5809, 0.8474, 0.9322, 0.6962, 0.7719,\n",
       "                       0.8730, 0.9913, 0.6827, 0.8537, 0.8957, 0.9116, 0.8946, 0.8481, 0.9150,\n",
       "                       0.9876, 0.8810, 0.9579, 0.9495, 0.9434, 1.0365, 1.0191, 0.9722, 1.0033,\n",
       "                       0.9413, 1.0106, 0.9240, 0.9877, 1.0268, 0.9956, 0.9855, 0.8994, 1.0338,\n",
       "                       1.0244, 1.0707, 1.0221, 0.9957, 1.0500, 1.0439, 1.0379, 1.1136, 1.0079,\n",
       "                       1.1047, 1.0405, 1.0671, 0.9442, 1.1604, 0.9306, 0.9681, 1.0944, 1.0751,\n",
       "                       1.0157, 0.9975, 1.0539, 1.0128, 0.9775, 1.0579, 1.0127, 1.0274, 1.0383,\n",
       "                       1.0409, 1.0051, 0.9700, 0.9970, 1.0448, 0.9543, 1.0729, 1.0197, 1.0619,\n",
       "                       1.0104, 0.9581, 0.9835, 1.0627, 0.9669, 1.0784, 1.0745, 1.0778, 0.9858,\n",
       "                       0.9940, 1.0190, 1.0370, 1.0572, 1.4085, 1.0769, 1.0593, 1.0270, 1.0995,\n",
       "                       1.0396, 1.0730, 1.0019, 1.1000, 0.9247, 1.0403, 1.0788, 1.1190, 1.0210,\n",
       "                       1.0243, 0.9848, 1.1094, 1.0256, 1.0727, 1.0083, 1.0108, 0.9588, 0.9812,\n",
       "                       1.0252, 1.0538])),\n",
       "              ('transformer_encoder.layers.1.norm1.bias',\n",
       "               tensor([-1.6982e-01, -3.9852e-01, -4.6029e-01,  1.6952e-01, -6.6958e-01,\n",
       "                       -1.2471e+00,  7.8623e-01,  2.3396e-01, -9.3533e-01,  3.9036e-02,\n",
       "                        8.6826e-02,  2.3165e-01,  8.5941e-02,  1.1749e-01, -1.0043e+00,\n",
       "                        1.6489e-01, -1.3496e-01,  4.1330e-01,  3.9663e-02,  3.2484e-02,\n",
       "                        4.3713e-01,  1.7704e-01,  7.8019e-02, -2.2934e-01, -4.7594e-01,\n",
       "                       -8.0892e-02,  1.6628e-01, -4.6886e-02,  4.7901e-01,  8.8181e-02,\n",
       "                       -8.9156e-02, -1.3756e-01, -9.1764e-02, -2.8056e-01, -2.0167e-01,\n",
       "                        3.8259e-02,  2.9140e-01, -2.4647e-01,  1.2415e-01,  2.0913e-02,\n",
       "                        3.0620e-02, -2.2615e-01,  3.7186e-02, -3.5232e-01, -8.3960e-02,\n",
       "                        1.8737e-01, -2.3766e-01,  1.3452e-01,  2.1710e-01,  3.6103e-02,\n",
       "                       -1.0486e-01, -8.9279e-02,  1.6970e-02, -3.3210e-02,  1.0141e-01,\n",
       "                        5.2769e-02,  3.7005e-01,  1.2067e-01, -1.0496e-01,  8.5033e-02,\n",
       "                       -2.0066e-01,  1.2881e-01, -2.8760e-02,  1.2075e-03, -2.6083e-01,\n",
       "                        8.4807e-02, -7.0266e-03,  1.4829e-01,  6.2038e-02,  2.1408e-01,\n",
       "                        9.4035e-02, -5.7088e-02, -2.5081e-01, -1.7426e-02, -3.8086e-01,\n",
       "                        2.6791e-02,  3.2243e-02,  1.8646e-02, -2.7957e-01,  5.0029e-02,\n",
       "                       -8.5254e-02,  4.0993e-01, -2.0281e-01,  1.8486e-01,  2.0787e-01,\n",
       "                        3.6697e-01, -1.2808e-01,  7.4581e-02, -1.8491e-01,  1.3314e-01,\n",
       "                        1.1474e-01,  6.4964e-02, -2.9484e-01, -6.0741e-02, -1.0555e-01,\n",
       "                        2.1461e-01,  4.4630e-02, -2.8186e-02, -2.4648e-01,  6.6524e-02,\n",
       "                       -1.9826e-01,  1.7366e-01, -4.9092e-01,  8.0508e-01, -3.8988e-01,\n",
       "                       -4.5314e-02, -4.8004e-02,  1.5635e-01, -3.6290e-01,  3.4734e-01,\n",
       "                       -1.0143e-01,  2.0709e-01, -1.6959e-01, -4.7209e-02, -3.4658e-01,\n",
       "                        3.9523e-01, -3.5848e-02,  9.7071e-02,  3.6591e-02,  3.3923e-01,\n",
       "                       -3.1717e-01, -2.5229e-02, -3.5865e-02, -1.6658e-02, -3.2993e-02,\n",
       "                        1.3815e-01,  1.3060e-01,  5.5046e-02])),\n",
       "              ('transformer_encoder.layers.1.norm2.weight',\n",
       "               tensor([0.5794, 0.7060, 0.5065, 0.8032, 0.5926, 0.2454, 0.6750, 0.7483, 0.5142,\n",
       "                       0.8580, 0.7568, 0.7355, 0.7067, 0.7691, 0.5003, 0.7264, 0.7750, 0.3780,\n",
       "                       0.7374, 0.7676, 0.7138, 0.7432, 0.5587, 0.6701, 0.6868, 0.6432, 0.6754,\n",
       "                       0.7028, 0.6583, 0.5805, 0.6195, 0.7319, 0.7626, 0.7662, 0.7354, 0.7795,\n",
       "                       0.7031, 0.6807, 0.7653, 0.8182, 0.7491, 0.8047, 0.8132, 0.6589, 0.8029,\n",
       "                       0.7340, 0.8063, 0.7630, 0.7344, 0.7876, 0.7863, 0.7652, 0.7526, 0.7455,\n",
       "                       0.7863, 0.8385, 0.8016, 0.7607, 0.7870, 0.7983, 0.7408, 0.7800, 0.7942,\n",
       "                       0.8389, 0.7989, 0.7964, 0.7867, 0.7945, 0.7845, 0.7643, 0.7700, 0.8189,\n",
       "                       0.7456, 0.8240, 0.7432, 0.7399, 0.7648, 0.7767, 0.7954, 0.8344, 0.7719,\n",
       "                       0.7272, 0.7812, 0.8114, 0.7832, 0.7890, 0.7550, 0.7616, 0.7434, 0.8317,\n",
       "                       0.7444, 0.7487, 0.7518, 0.7776, 0.7722, 0.7389, 0.7540, 0.8368, 0.6841,\n",
       "                       0.8000, 0.7454, 0.7555, 0.6620, 0.8674, 0.7827, 0.7282, 0.7656, 0.8041,\n",
       "                       0.7601, 0.7800, 0.7701, 0.8262, 0.7919, 0.7737, 0.7551, 0.7806, 0.7777,\n",
       "                       0.7769, 0.7545, 0.7601, 0.6931, 0.7963, 0.7715, 0.7968, 0.7851, 0.7598,\n",
       "                       0.7777, 0.7950])),\n",
       "              ('transformer_encoder.layers.1.norm2.bias',\n",
       "               tensor([ 1.0916e-01,  2.1970e-01,  2.4085e-01, -7.3089e-02,  4.1845e-01,\n",
       "                        5.5473e-01, -3.7195e-01, -1.4316e-01,  5.4088e-01, -2.1995e-03,\n",
       "                       -5.9431e-02, -1.2720e-01, -3.7480e-02, -8.7062e-02,  4.8498e-01,\n",
       "                       -1.9776e-02,  6.4254e-02, -1.5700e-01, -9.5750e-04,  9.5217e-04,\n",
       "                       -2.0088e-01, -8.9670e-02,  3.6574e-04,  1.6703e-01,  2.1074e-01,\n",
       "                        6.0500e-02, -3.1078e-02,  7.0124e-02, -1.4967e-01,  3.3853e-02,\n",
       "                        6.8922e-02,  1.0303e-01,  1.2029e-01,  1.4423e-01,  5.6018e-02,\n",
       "                       -1.2057e-03, -1.2587e-01,  1.6919e-01,  1.5800e-02,  9.6307e-02,\n",
       "                       -4.4991e-02,  1.2405e-01,  2.8195e-02,  1.7816e-01, -2.0480e-02,\n",
       "                       -4.5044e-02,  8.3240e-02, -3.7891e-02, -4.2225e-02, -2.5642e-02,\n",
       "                        1.4206e-02,  5.4188e-02, -2.5829e-02, -6.8735e-03, -3.8861e-02,\n",
       "                       -7.6468e-02, -8.3413e-02, -7.5046e-02,  1.0409e-01, -1.1042e-01,\n",
       "                        1.1493e-01, -1.8616e-01, -1.5036e-02, -1.2652e-01,  9.8724e-02,\n",
       "                       -1.1108e-01, -1.6364e-02, -1.5572e-01, -5.6849e-03, -1.5194e-01,\n",
       "                        8.8429e-02, -7.5574e-02,  1.4407e-01, -4.1365e-02,  1.7528e-01,\n",
       "                       -4.2892e-02,  7.1876e-02, -1.0438e-01,  1.3625e-01, -5.3015e-02,\n",
       "                        8.0960e-02, -1.5828e-01,  1.2494e-01, -7.6578e-02, -2.1750e-04,\n",
       "                       -2.1250e-01,  8.1427e-02, -1.4105e-01,  9.0488e-02, -9.7205e-02,\n",
       "                        2.1188e-02, -3.8054e-03,  1.9933e-01, -6.3035e-02,  9.4116e-02,\n",
       "                       -1.6058e-01,  2.3354e-02, -8.3319e-02,  1.8501e-01, -4.2648e-02,\n",
       "                        1.1672e-01, -1.0819e-01,  2.8217e-01,  1.6064e-01,  1.7898e-01,\n",
       "                       -7.8149e-02,  1.1716e-01, -1.8163e-01,  1.8298e-01, -1.6488e-01,\n",
       "                        9.4858e-02, -1.5139e-01,  1.1639e-01, -2.1339e-02,  1.5575e-01,\n",
       "                       -2.4878e-01,  1.1043e-01, -6.3446e-02,  4.9237e-03, -2.1741e-01,\n",
       "                        2.2799e-01, -8.4123e-02,  3.4196e-02, -1.0441e-01,  7.3740e-03,\n",
       "                       -1.0361e-01,  2.3319e-02, -1.4006e-01])),\n",
       "              ('transformer_encoder.layers.2.self_attn.in_proj_weight',\n",
       "               tensor([[ 0.1543,  0.1289, -0.0600,  ...,  0.0903, -0.1595,  0.0439],\n",
       "                       [-0.0838, -0.0683, -0.0141,  ...,  0.1882,  0.1310,  0.1747],\n",
       "                       [-0.0143,  0.1771,  0.0184,  ...,  0.0294, -0.1334, -0.0400],\n",
       "                       ...,\n",
       "                       [-0.1227,  0.0845, -0.0670,  ...,  0.0426,  0.1089, -0.1164],\n",
       "                       [ 0.0077, -0.0172, -0.1556,  ..., -0.0448,  0.0255,  0.0206],\n",
       "                       [ 0.0825,  0.0787,  0.0501,  ...,  0.0185, -0.0833, -0.0543]])),\n",
       "              ('transformer_encoder.layers.2.self_attn.in_proj_bias',\n",
       "               tensor([ 1.4434e-02, -1.7455e-02,  8.7398e-02,  8.5590e-02,  3.3436e-02,\n",
       "                       -1.2589e-01, -1.6357e-02, -8.0148e-02, -3.1854e-02,  5.5528e-02,\n",
       "                        5.9220e-02,  4.1416e-03,  1.8131e-01, -4.9476e-02,  8.0553e-03,\n",
       "                       -3.0014e-02,  4.5491e-02, -8.6964e-02, -5.4711e-02, -6.3228e-04,\n",
       "                       -1.4357e-01, -3.2360e-02,  5.4862e-02,  1.8742e-01, -5.4868e-03,\n",
       "                        1.1928e-01, -2.8561e-02,  3.9653e-02, -9.0155e-02,  9.4600e-02,\n",
       "                        4.5196e-02,  2.9763e-02,  9.1076e-02, -1.2140e-01, -7.2193e-02,\n",
       "                        1.3024e-02,  4.0265e-02, -3.1539e-02,  2.7462e-03,  7.3897e-02,\n",
       "                       -1.8120e-02,  2.0059e-02,  2.3638e-01, -8.4410e-02, -1.2292e-01,\n",
       "                       -7.7011e-02,  5.7160e-02, -3.5524e-02,  1.3121e-01,  1.9503e-01,\n",
       "                        1.4307e-01, -1.0435e-01,  4.0123e-03,  1.6726e-02,  2.4772e-02,\n",
       "                        1.2259e-01, -5.5704e-02, -1.8174e-02, -1.6801e-01, -5.5169e-03,\n",
       "                        7.9741e-02, -6.3163e-02,  9.1048e-02,  2.5306e-01, -6.8953e-02,\n",
       "                       -4.4699e-02,  4.0866e-02,  6.2301e-02, -2.3889e-02,  2.5337e-02,\n",
       "                        6.0574e-02,  3.5865e-02, -5.7645e-02, -4.6946e-02,  1.2844e-01,\n",
       "                       -8.3428e-03,  9.5023e-02, -1.6532e-01, -2.1387e-02, -6.6000e-02,\n",
       "                        1.8714e-01, -1.3075e-01,  7.7629e-02, -1.4122e-01,  1.4800e-01,\n",
       "                        3.4451e-02,  1.8424e-01, -3.9768e-02,  1.5017e-01, -4.6714e-02,\n",
       "                        4.6847e-03,  1.4409e-01,  3.6629e-03, -1.0490e-02, -3.3290e-03,\n",
       "                        4.4285e-02,  8.8074e-02,  2.1085e-02,  1.0742e-01, -4.6347e-02,\n",
       "                        1.7619e-01,  6.1316e-02,  4.3795e-02, -1.7801e-02,  1.0315e-01,\n",
       "                       -6.3746e-02, -6.9224e-02,  3.5574e-03,  9.4122e-02, -3.4080e-02,\n",
       "                       -5.2382e-02,  1.4887e-02, -1.0285e-01, -3.2714e-02,  5.0001e-03,\n",
       "                       -8.8501e-02,  3.6264e-02, -5.4978e-02,  6.2436e-02, -8.2315e-02,\n",
       "                       -3.6520e-02,  4.7237e-02,  1.1716e-01,  5.5676e-02, -9.3237e-02,\n",
       "                        2.0898e-02, -4.1774e-02,  9.3006e-02, -1.7065e-04,  2.9989e-04,\n",
       "                        1.3344e-04,  5.0793e-04,  1.7715e-04, -1.6793e-04, -8.3506e-04,\n",
       "                       -6.6349e-04, -3.3819e-04,  2.1261e-04, -6.9792e-04, -4.3412e-04,\n",
       "                        3.4184e-04, -4.2805e-04,  2.8711e-04,  5.4230e-04,  6.0063e-04,\n",
       "                        4.1934e-04,  4.5658e-05,  3.9025e-04, -2.1901e-04, -3.1657e-04,\n",
       "                       -7.6382e-04,  2.8687e-04,  3.5589e-04,  1.9033e-04,  3.5826e-04,\n",
       "                       -7.2699e-04,  4.9909e-04, -5.9049e-04,  1.4637e-04,  9.6432e-04,\n",
       "                        7.8243e-04, -6.8838e-04, -1.1172e-03, -1.7773e-04, -1.1206e-03,\n",
       "                       -9.2469e-04, -6.4645e-05,  3.4102e-05, -5.1926e-05, -4.6085e-05,\n",
       "                        1.1339e-04,  4.3432e-04, -4.0561e-04, -6.8970e-04,  5.9894e-04,\n",
       "                       -1.1565e-04,  5.8879e-04,  2.0869e-03,  1.1024e-03, -1.1179e-03,\n",
       "                        2.9773e-04, -2.9928e-04,  4.1119e-04,  4.6883e-04, -5.2635e-04,\n",
       "                       -7.8406e-04,  1.7308e-04,  2.2481e-05, -4.1532e-04,  5.5682e-04,\n",
       "                        6.2318e-04,  1.1220e-03,  5.1115e-05, -1.1354e-03, -4.7473e-04,\n",
       "                       -2.1652e-04,  2.4005e-05, -1.2602e-04,  4.5475e-04, -3.1949e-04,\n",
       "                        3.8647e-04, -8.0836e-04,  1.9185e-04,  7.6631e-04, -3.8052e-04,\n",
       "                       -3.4367e-04,  2.2686e-04, -1.0953e-03,  1.4187e-03, -2.8432e-04,\n",
       "                       -6.6563e-04, -1.8743e-03,  3.2677e-05,  1.0953e-03,  8.2910e-04,\n",
       "                        4.3171e-04,  3.0363e-04, -3.0461e-05,  2.0934e-03, -1.7256e-04,\n",
       "                        4.3256e-04, -1.4887e-04, -7.9195e-05,  9.0437e-04,  7.2379e-04,\n",
       "                        4.5432e-04,  6.5096e-04, -2.7686e-04,  1.7925e-03,  1.3126e-03,\n",
       "                       -3.4820e-04, -5.7640e-04,  7.8840e-04, -8.2441e-04, -1.0420e-04,\n",
       "                        2.8205e-05,  5.4281e-04,  9.8056e-05, -8.9087e-04,  3.8097e-04,\n",
       "                       -1.0606e-03,  1.0336e-03,  6.2860e-04, -3.3079e-04, -8.0967e-04,\n",
       "                       -1.0464e-03, -8.4154e-04, -1.0084e-03,  1.7804e-04, -1.1252e-04,\n",
       "                        2.6955e-04,  3.0182e-04,  6.0266e-04,  6.8769e-05, -9.8892e-05,\n",
       "                        1.1377e-03, -2.2917e-02, -5.5420e-02, -1.6369e-02,  1.2214e-02,\n",
       "                       -4.1728e-02, -7.8635e-02,  9.3596e-02,  8.3717e-03,  1.8073e-02,\n",
       "                       -1.3007e-01, -1.0387e-01,  1.5546e-02,  5.8686e-02,  9.6053e-02,\n",
       "                       -2.4857e-03,  9.0906e-02,  3.5045e-02,  5.7066e-02, -5.5952e-02,\n",
       "                       -2.2026e-03, -8.4191e-02,  2.5368e-02,  6.6564e-02,  6.4381e-02,\n",
       "                       -1.5714e-02,  4.8982e-02, -3.5259e-02,  5.6373e-02,  2.6099e-02,\n",
       "                        2.3566e-02,  2.6014e-03, -5.5569e-02,  5.5438e-02, -6.4918e-02,\n",
       "                       -4.7963e-02, -5.4312e-02,  1.2040e-02, -3.0621e-02, -8.7649e-04,\n",
       "                        1.3265e-02,  3.2858e-02, -8.8533e-02,  2.1659e-02,  4.7554e-02,\n",
       "                       -5.6083e-02,  6.8201e-02, -2.8106e-02,  2.6800e-02,  8.3715e-02,\n",
       "                       -1.1269e-02,  5.7837e-02,  1.2219e-02,  1.4123e-02,  2.6937e-02,\n",
       "                       -3.0558e-02, -1.8758e-02, -6.2253e-03,  5.5676e-02,  5.0652e-02,\n",
       "                       -7.4200e-02, -4.1433e-02,  3.6171e-02, -1.5710e-02, -1.1595e-02,\n",
       "                       -4.7264e-03, -1.4677e-02, -2.8374e-02,  4.6424e-02, -3.3318e-02,\n",
       "                        9.5275e-03, -5.9357e-02, -7.3033e-02,  2.0265e-02,  6.7675e-02,\n",
       "                       -4.0760e-02, -1.4095e-01,  1.5544e-02,  3.0503e-03, -9.9991e-03,\n",
       "                        3.2601e-02, -4.3839e-02, -4.7637e-02,  2.2863e-02, -8.2662e-03,\n",
       "                       -3.5424e-02,  7.7101e-03, -6.6983e-02,  8.7504e-03,  2.9779e-02,\n",
       "                        2.2082e-02, -4.5808e-02,  4.6905e-02,  3.7080e-02, -2.9706e-02,\n",
       "                        1.4952e-02,  6.4681e-02,  4.9726e-03, -2.2671e-02,  6.1814e-02,\n",
       "                       -5.3144e-02, -1.5290e-03, -2.4879e-02,  7.5208e-02,  8.7885e-02,\n",
       "                       -4.1238e-02, -2.1208e-02,  1.0598e-01,  7.4607e-03,  5.6578e-02,\n",
       "                        4.4195e-02,  2.3400e-02, -7.2898e-02,  8.9285e-02,  4.8356e-02,\n",
       "                       -1.2520e-03,  3.7628e-02,  6.5064e-02,  7.4979e-02, -2.6913e-02,\n",
       "                        3.7321e-02, -3.8942e-02,  6.8023e-02,  5.5209e-02, -8.9608e-02,\n",
       "                        3.9724e-02,  1.0248e-01,  1.9873e-02, -3.0608e-02])),\n",
       "              ('transformer_encoder.layers.2.self_attn.out_proj.weight',\n",
       "               tensor([[-0.1299, -0.1083, -0.1614,  ..., -0.0005,  0.0529, -0.0177],\n",
       "                       [-0.1731, -0.1545, -0.0116,  ..., -0.1285,  0.1392, -0.0125],\n",
       "                       [-0.0908,  0.0236,  0.1473,  ...,  0.0018, -0.0105, -0.0066],\n",
       "                       ...,\n",
       "                       [ 0.0164,  0.0146, -0.0882,  ..., -0.0617,  0.0463, -0.1629],\n",
       "                       [ 0.0373,  0.0704, -0.0270,  ..., -0.0538,  0.0569,  0.1090],\n",
       "                       [ 0.1287, -0.1042,  0.0441,  ...,  0.0957,  0.1361,  0.0808]])),\n",
       "              ('transformer_encoder.layers.2.self_attn.out_proj.bias',\n",
       "               tensor([-0.0631, -0.2077,  0.0520,  0.0561, -0.1596, -0.4273,  0.3105,  0.1163,\n",
       "                       -0.2166,  0.0864,  0.0800,  0.1139, -0.0575, -0.0265, -0.2637,  0.1139,\n",
       "                       -0.0068,  0.0709,  0.0074,  0.0345,  0.2133,  0.0669,  0.0323, -0.1217,\n",
       "                       -0.2904, -0.0947,  0.0277, -0.0622,  0.2006,  0.0979, -0.0598, -0.0647,\n",
       "                       -0.0568, -0.0981, -0.0954, -0.0472,  0.0451, -0.2115,  0.0951,  0.0459,\n",
       "                        0.0010, -0.1314,  0.0366, -0.2185, -0.0409,  0.0555, -0.0991,  0.0061,\n",
       "                        0.0969, -0.0609, -0.0267, -0.0139,  0.0850,  0.0461, -0.0062, -0.0485,\n",
       "                        0.2030,  0.1341, -0.0503,  0.0370, -0.1239,  0.0207, -0.1500, -0.0503,\n",
       "                       -0.1538,  0.0331, -0.0612,  0.0527,  0.0621,  0.1816,  0.0327, -0.0413,\n",
       "                       -0.1328,  0.0399, -0.2115, -0.0455,  0.0732, -0.0483, -0.1320,  0.0342,\n",
       "                       -0.0174,  0.2251, -0.1601,  0.0093,  0.0884,  0.1828, -0.1828, -0.0194,\n",
       "                       -0.1261,  0.0075,  0.0806,  0.0542, -0.2018, -0.0326, -0.0309,  0.0456,\n",
       "                        0.0819, -0.0115, -0.1197,  0.0406, -0.1049,  0.0538, -0.1976,  0.8957,\n",
       "                       -0.3015, -0.0207,  0.0213, -0.0626, -0.1725,  0.1390, -0.0022,  0.1487,\n",
       "                       -0.0311,  0.0176, -0.1592,  0.1117,  0.0367,  0.0288,  0.0749,  0.1284,\n",
       "                       -0.2308, -0.0242,  0.0014, -0.0262, -0.0338,  0.0872,  0.1000, -0.0046])),\n",
       "              ('transformer_encoder.layers.2.linear1.weight',\n",
       "               tensor([[ 0.0643,  0.0226,  0.1675,  ...,  0.0401, -0.2457, -0.0758],\n",
       "                       [-0.0542,  0.0529, -0.1268,  ...,  0.0476, -0.1104,  0.1685],\n",
       "                       [ 0.1010, -0.0014,  0.2030,  ..., -0.0485, -0.0658,  0.0085],\n",
       "                       ...,\n",
       "                       [ 0.0309,  0.0296,  0.0403,  ..., -0.0394, -0.0007, -0.0532],\n",
       "                       [ 0.1358, -0.0198, -0.1227,  ..., -0.0881,  0.0807, -0.0313],\n",
       "                       [ 0.2939,  0.0871, -0.1029,  ..., -0.1483,  0.0140, -0.1559]])),\n",
       "              ('transformer_encoder.layers.2.linear1.bias',\n",
       "               tensor([-0.2232, -0.2360, -0.2762, -0.2303, -0.2279, -0.3467, -0.3377, -0.2322,\n",
       "                       -0.1329, -0.2661, -0.1867, -0.2350, -0.2702, -0.1927, -0.2635, -0.2272,\n",
       "                       -0.2834, -0.2094, -0.3041, -0.2234, -0.2086, -0.3178, -0.1547, -0.2803,\n",
       "                       -0.2180, -0.2733, -0.2744, -0.2049, -0.3782, -0.1662, -0.2435, -0.2141,\n",
       "                       -0.2405, -0.2593, -0.2385, -0.2355, -0.2538, -0.2673, -0.2724, -0.2287,\n",
       "                       -0.0917, -0.2822, -0.2433, -0.3214, -0.2421, -0.1575, -0.3352, -0.2145,\n",
       "                       -0.2895, -0.2007, -0.1993, -0.1283, -0.3789, -0.3045, -0.2844, -0.3059,\n",
       "                       -0.1571, -0.2056, -0.2073, -0.2631, -0.2602, -0.1213, -0.1743, -0.2644,\n",
       "                       -0.2683, -0.2285, -0.1381, -0.2050, -0.1903, -0.1022, -0.2979, -0.2699,\n",
       "                       -0.2620, -0.2509, -0.3595, -0.1660, -0.2615, -0.3924, -0.2571, -0.3171,\n",
       "                       -0.1990, -0.1643, -0.1587, -0.2320, -0.3798, -0.1313, -0.1654, -0.1951,\n",
       "                       -0.2423, -0.1089, -0.1782, -0.3092, -0.3445, -0.2172, -0.2434, -0.1887,\n",
       "                       -0.2263, -0.2799, -0.2331, -0.1792, -0.2950, -0.2077, -0.1631, -0.2769,\n",
       "                       -0.2310, -0.0927, -0.2360, -0.1633, -0.1066, -0.1978, -0.1458, -0.1352,\n",
       "                       -0.1821, -0.2967, -0.2259, -0.3068, -0.2090, -0.2504, -0.1870, -0.1025,\n",
       "                       -0.2721, -0.2015, -0.2238, -0.1645, -0.1518, -0.2165, -0.2689, -0.1793,\n",
       "                       -0.2126, -0.2275, -0.2332, -0.2636, -0.3245, -0.2684, -0.2244, -0.0967,\n",
       "                       -0.2592, -0.1540, -0.2926, -0.2579, -0.3136, -0.1442, -0.2482, -0.2415,\n",
       "                       -0.1740, -0.3285, -0.1513, -0.2405, -0.3086, -0.1705, -0.2861, -0.2357,\n",
       "                       -0.2300, -0.0848, -0.1726, -0.2456, -0.2504, -0.1721, -0.2123, -0.1757,\n",
       "                       -0.3243, -0.2570, -0.2943, -0.2460, -0.2776, -0.3882, -0.2905, -0.1634,\n",
       "                       -0.2449, -0.2052, -0.2956, -0.3150, -0.2052, -0.2203, -0.1648, -0.0859,\n",
       "                       -0.2496, -0.2737, -0.1916, -0.2333, -0.1772, -0.3711, -0.2033, -0.0966,\n",
       "                       -0.2552, -0.2967, -0.2519, -0.2244, -0.1740, -0.2971, -0.2020, -0.1838,\n",
       "                       -0.2319, -0.2006, -0.3495, -0.3207, -0.2608, -0.1876, -0.2569, -0.2860])),\n",
       "              ('transformer_encoder.layers.2.linear2.weight',\n",
       "               tensor([[-0.0381,  0.0987, -0.0351,  ...,  0.1654,  0.3406, -0.1512],\n",
       "                       [ 0.2757, -0.0333, -0.0037,  ..., -0.1631, -0.0394, -0.0355],\n",
       "                       [ 0.0839,  0.1402, -0.1154,  ...,  0.0539, -0.0246, -0.1075],\n",
       "                       ...,\n",
       "                       [ 0.0064,  0.2411,  0.1114,  ..., -0.0664,  0.0662,  0.0794],\n",
       "                       [-0.1147, -0.1580,  0.0069,  ...,  0.0545, -0.0541, -0.2197],\n",
       "                       [ 0.0543,  0.0344, -0.2349,  ..., -0.0944, -0.2494,  0.0309]])),\n",
       "              ('transformer_encoder.layers.2.linear2.bias',\n",
       "               tensor([-0.0452,  0.0979, -0.0781, -0.0558,  0.0249,  0.1279, -0.2383, -0.1124,\n",
       "                        0.1450,  0.0126, -0.0548, -0.1984,  0.0037, -0.0379,  0.3496, -0.1442,\n",
       "                       -0.0007, -0.0998, -0.0089, -0.0226, -0.2091, -0.0568, -0.0847,  0.0590,\n",
       "                        0.1864,  0.0415, -0.0593,  0.0720, -0.2642, -0.1098, -0.0053,  0.0864,\n",
       "                        0.0224,  0.0924,  0.1233, -0.0213, -0.1620,  0.1090, -0.1063, -0.0309,\n",
       "                        0.0014,  0.0806, -0.0190,  0.1923,  0.0312, -0.1384,  0.1429, -0.0895,\n",
       "                       -0.1257, -0.0119,  0.0543,  0.0136,  0.0279,  0.0031,  0.0230, -0.0437,\n",
       "                       -0.0347, -0.0597, -0.0283,  0.0078,  0.1176, -0.0593,  0.0191,  0.0263,\n",
       "                        0.1044, -0.0514, -0.0235, -0.0260, -0.0480, -0.0311, -0.0126, -0.0021,\n",
       "                        0.0388, -0.0481,  0.1735,  0.0039, -0.0573, -0.0154,  0.1519, -0.0487,\n",
       "                        0.0170, -0.2390,  0.0918, -0.0742, -0.1374, -0.1125,  0.0225, -0.0030,\n",
       "                        0.1361, -0.0697, -0.0734, -0.1188,  0.1057,  0.0764,  0.0412, -0.0840,\n",
       "                       -0.0440,  0.0287,  0.1524, -0.0492,  0.1301, -0.0693,  0.1358,  0.3928,\n",
       "                        0.0415,  0.0373,  0.0021, -0.0545,  0.1473, -0.1751,  0.0228, -0.0684,\n",
       "                        0.0748,  0.0436,  0.0683, -0.1035,  0.0277, -0.0583,  0.0079, -0.1312,\n",
       "                        0.0539,  0.0098,  0.0637,  0.0397,  0.0556, -0.1417, -0.0867, -0.0246])),\n",
       "              ('transformer_encoder.layers.2.norm1.weight',\n",
       "               tensor([0.6902, 0.8731, 0.6095, 0.8315, 0.8291, 0.8336, 1.0020, 0.8085, 0.8163,\n",
       "                       0.9143, 0.8285, 0.8232, 0.8156, 0.8340, 1.0224, 0.7980, 0.8547, 0.5483,\n",
       "                       0.8543, 0.8743, 0.9341, 0.8613, 0.7289, 0.9138, 1.0500, 0.7887, 0.8187,\n",
       "                       0.9292, 0.9955, 0.8036, 0.8335, 0.8958, 0.9008, 0.9272, 0.8522, 0.9219,\n",
       "                       0.9305, 0.8989, 0.9490, 0.9724, 0.9121, 0.9944, 1.0184, 0.9499, 1.0047,\n",
       "                       0.9297, 1.0015, 0.9390, 0.9819, 0.9805, 0.9360, 0.9932, 0.9229, 0.9405,\n",
       "                       1.0086, 1.0551, 1.1073, 1.0028, 0.9967, 1.0229, 0.9860, 0.9681, 1.0343,\n",
       "                       1.0364, 1.0624, 0.9472, 0.9797, 1.0671, 0.9334, 1.0327, 1.0365, 1.0421,\n",
       "                       1.0080, 0.9552, 1.0359, 0.9365, 0.9900, 0.9872, 0.9955, 1.0176, 0.9995,\n",
       "                       1.0249, 0.9706, 0.9627, 0.9638, 1.0171, 0.9924, 0.9548, 0.9774, 0.9913,\n",
       "                       0.9413, 0.9855, 1.0181, 0.9816, 0.9435, 0.9691, 0.9746, 1.0240, 0.9181,\n",
       "                       0.9836, 0.9655, 0.9774, 0.9607, 2.0317, 1.1590, 0.9220, 0.9830, 1.0029,\n",
       "                       1.0069, 1.0552, 0.9790, 1.0801, 0.9311, 0.9854, 1.0520, 1.0349, 0.9701,\n",
       "                       0.9869, 0.9883, 1.0577, 1.0288, 1.0045, 0.9529, 0.9762, 1.0123, 0.9258,\n",
       "                       0.9382, 0.9665])),\n",
       "              ('transformer_encoder.layers.2.norm1.bias',\n",
       "               tensor([-0.0715, -0.3035,  0.1054,  0.1600, -0.2117, -0.5216,  0.5236,  0.1317,\n",
       "                       -0.2925,  0.1561,  0.1742,  0.1778, -0.0726,  0.0248, -0.4015,  0.2283,\n",
       "                        0.0226,  0.1546,  0.0330,  0.0708,  0.3302,  0.1283,  0.0708, -0.1361,\n",
       "                       -0.4329, -0.0985,  0.0817, -0.0742,  0.3527,  0.1014, -0.0879, -0.0753,\n",
       "                       -0.0949, -0.1997, -0.1544, -0.0570,  0.1145, -0.2991,  0.1633,  0.0695,\n",
       "                        0.0026, -0.2051,  0.0755, -0.3325, -0.0556,  0.1400, -0.1965,  0.0383,\n",
       "                        0.1814, -0.0917, -0.0460, -0.0141,  0.1491,  0.0611,  0.0367, -0.0599,\n",
       "                        0.3496,  0.2038, -0.0465,  0.0977, -0.1753,  0.0248, -0.1917, -0.0716,\n",
       "                       -0.2612,  0.0277, -0.0699,  0.0913,  0.1391,  0.2805,  0.0880, -0.0573,\n",
       "                       -0.2101,  0.0740, -0.3148, -0.0434,  0.1520, -0.0484, -0.2169,  0.0628,\n",
       "                       -0.0606,  0.3775, -0.2135,  0.0330,  0.1702,  0.2933, -0.2491, -0.0144,\n",
       "                       -0.1601,  0.0101,  0.1333,  0.0729, -0.2706, -0.0126, -0.0229,  0.0974,\n",
       "                        0.1312, -0.0320, -0.1846,  0.0952, -0.1403,  0.1178, -0.3043,  0.9756,\n",
       "                       -0.4342, -0.0530,  0.0723, -0.0628, -0.2477,  0.2498, -0.0036,  0.2208,\n",
       "                       -0.0378,  0.0280, -0.2635,  0.2419,  0.0341,  0.0523,  0.1267,  0.2370,\n",
       "                       -0.3089, -0.0272, -0.0084, -0.0252, -0.0280,  0.1360,  0.1252, -0.0586])),\n",
       "              ('transformer_encoder.layers.2.norm2.weight',\n",
       "               tensor([0.7434, 0.8087, 0.7516, 0.9525, 0.8791, 0.5975, 0.8180, 0.9565, 0.9016,\n",
       "                       0.9713, 0.8760, 0.8926, 0.8913, 0.9690, 0.8148, 0.9059, 1.0119, 0.7614,\n",
       "                       0.9441, 1.0024, 0.9350, 0.9799, 0.7304, 0.8731, 0.8332, 0.9351, 0.8988,\n",
       "                       0.9432, 0.8209, 0.8262, 0.9111, 0.9319, 0.9233, 0.9244, 0.9067, 0.9110,\n",
       "                       0.9489, 0.8358, 0.9292, 0.9629, 0.9194, 0.8504, 0.9493, 0.8641, 0.9103,\n",
       "                       0.9519, 0.9452, 0.9454, 0.9126, 0.9372, 0.9422, 0.9255, 0.8875, 0.9212,\n",
       "                       0.9434, 0.9085, 0.8839, 0.8969, 0.9459, 0.8979, 0.9269, 0.9176, 0.8543,\n",
       "                       0.9121, 0.9386, 0.9366, 0.9105, 0.8791, 0.9819, 0.8871, 0.9015, 0.9215,\n",
       "                       0.8828, 0.9739, 0.8950, 0.8567, 0.8937, 0.8826, 0.9222, 0.9582, 0.9048,\n",
       "                       0.8698, 0.9166, 1.0157, 0.9239, 0.9353, 0.8202, 0.8899, 0.9082, 0.9855,\n",
       "                       0.9038, 0.8911, 0.8265, 0.9298, 0.9811, 0.9095, 0.9375, 0.9599, 0.8550,\n",
       "                       0.9595, 0.8686, 0.9181, 0.7989, 0.7663, 0.7752, 0.9150, 0.8991, 0.9543,\n",
       "                       0.9130, 0.8992, 0.9590, 0.9047, 0.9715, 0.9187, 0.8692, 0.9267, 0.9328,\n",
       "                       0.9508, 0.8927, 0.9255, 0.8365, 0.9366, 0.9237, 0.9433, 0.8911, 0.9105,\n",
       "                       0.9207, 0.9173])),\n",
       "              ('transformer_encoder.layers.2.norm2.bias',\n",
       "               tensor([ 0.1098,  0.2354,  0.0206, -0.0430,  0.2266,  0.2849, -0.2052, -0.0494,\n",
       "                        0.1725, -0.0462, -0.0689,  0.0088,  0.1155,  0.0382,  0.2027, -0.0270,\n",
       "                        0.0303, -0.0035,  0.0697,  0.0051, -0.1404, -0.0334,  0.0692,  0.1449,\n",
       "                        0.2226,  0.0934,  0.0373,  0.0444, -0.1072, -0.0139,  0.0758,  0.1167,\n",
       "                        0.1185,  0.1002,  0.1231,  0.0632,  0.0402,  0.2056, -0.0213,  0.0515,\n",
       "                        0.0200,  0.1653,  0.0169,  0.2216,  0.0606, -0.0044,  0.1013,  0.0608,\n",
       "                       -0.0017,  0.0582,  0.0048,  0.0482, -0.0785, -0.0290,  0.0358,  0.0719,\n",
       "                       -0.1261, -0.0424,  0.1098, -0.0308,  0.1333, -0.0210,  0.1189, -0.0209,\n",
       "                        0.1300, -0.0155,  0.0587, -0.0687, -0.0059, -0.1930,  0.0263,  0.0269,\n",
       "                        0.1165, -0.0610,  0.1815,  0.0534,  0.0142, -0.0021,  0.1121, -0.0108,\n",
       "                        0.0822, -0.1358,  0.1472,  0.0066, -0.0100, -0.1486,  0.2042,  0.0029,\n",
       "                        0.1059,  0.0376, -0.0524,  0.0087,  0.2400,  0.0040,  0.0820, -0.0424,\n",
       "                       -0.0051, -0.0012,  0.1272,  0.0442,  0.1444, -0.0185,  0.2286, -0.1883,\n",
       "                        0.2597,  0.0159,  0.0724,  0.0989,  0.1938, -0.0807,  0.0785, -0.1169,\n",
       "                        0.0713, -0.0095,  0.1743, -0.1341,  0.0248,  0.0252, -0.0414, -0.0983,\n",
       "                        0.2714, -0.0247,  0.0202,  0.0545,  0.0579, -0.0403,  0.0119, -0.0110])),\n",
       "              ('transformer_encoder.layers.3.self_attn.in_proj_weight',\n",
       "               tensor([[-0.0960,  0.0441, -0.0149,  ..., -0.0453, -0.2496, -0.0563],\n",
       "                       [ 0.0575, -0.0853,  0.0208,  ..., -0.0867,  0.2709,  0.1560],\n",
       "                       [ 0.1007,  0.1294,  0.1390,  ...,  0.1323, -0.3598, -0.0166],\n",
       "                       ...,\n",
       "                       [-0.0218,  0.1357, -0.1119,  ..., -0.1109,  0.0572, -0.0948],\n",
       "                       [ 0.0881, -0.0988, -0.0885,  ..., -0.1568, -0.0169, -0.1297],\n",
       "                       [-0.0640, -0.0326,  0.0329,  ...,  0.0213, -0.1451, -0.0047]])),\n",
       "              ('transformer_encoder.layers.3.self_attn.in_proj_bias',\n",
       "               tensor([-5.0344e-03, -1.3417e-01,  6.0625e-02,  1.1505e-01,  4.0116e-02,\n",
       "                       -3.2507e-02,  1.2003e-01, -9.2882e-02, -7.8761e-02,  1.6543e-01,\n",
       "                        1.7355e-02, -9.2238e-03,  1.2736e-01, -1.7044e-01, -3.2716e-02,\n",
       "                       -1.6302e-02,  6.9491e-02, -9.4900e-02, -3.9382e-02,  1.3637e-01,\n",
       "                        3.0141e-03, -1.7537e-01, -4.1610e-02,  2.1397e-01, -1.1225e-01,\n",
       "                        2.2212e-01, -7.2771e-02, -5.6971e-02, -5.6715e-02,  1.9518e-01,\n",
       "                        1.8551e-01,  1.2456e-01,  6.8176e-02, -9.3766e-02, -9.1282e-02,\n",
       "                       -1.2016e-03,  1.8260e-01,  2.4044e-02,  1.2111e-01,  1.5422e-01,\n",
       "                        2.3299e-03, -3.1208e-02,  1.9886e-01, -1.5903e-01, -9.2001e-02,\n",
       "                       -2.4312e-02,  7.8181e-02, -8.6296e-02,  1.8292e-01, -4.8455e-02,\n",
       "                        3.2077e-02, -1.5092e-01, -6.7894e-02, -6.1112e-02, -1.1479e-01,\n",
       "                       -5.0488e-03, -1.2199e-01, -1.5353e-02, -4.3971e-02, -2.4469e-02,\n",
       "                        1.3625e-01, -8.8688e-02,  6.4898e-02,  2.4437e-01, -1.5878e-01,\n",
       "                        3.9905e-02,  6.3528e-02,  5.9585e-02,  8.9472e-04, -9.4948e-02,\n",
       "                        8.8771e-02,  1.7069e-01, -6.6072e-02, -4.5131e-03,  5.3954e-02,\n",
       "                        1.2379e-03,  2.6398e-02, -8.5841e-02, -1.7699e-02,  6.0164e-02,\n",
       "                        1.6463e-01, -2.1218e-01,  8.4422e-02,  2.3449e-03,  1.1333e-01,\n",
       "                        4.1571e-03,  1.7879e-01, -4.7428e-02,  2.1905e-01, -4.4333e-02,\n",
       "                        1.5651e-01,  2.0419e-01,  4.4580e-02, -8.0113e-03, -2.5853e-02,\n",
       "                       -7.0838e-03, -4.0760e-03, -1.7030e-04,  5.5214e-02, -8.7763e-02,\n",
       "                        3.0799e-02,  6.0832e-02,  3.8045e-02, -1.1584e-01,  2.8235e-01,\n",
       "                       -8.5126e-02, -3.3103e-02,  6.0024e-02, -1.2850e-01, -1.4331e-01,\n",
       "                       -1.0978e-01,  9.3834e-03, -1.2000e-01, -1.9888e-01,  9.0598e-02,\n",
       "                       -4.0956e-02, -3.7533e-02, -1.9729e-01,  1.1482e-01, -1.1153e-01,\n",
       "                       -1.2516e-02, -2.6595e-02, -1.0511e-01,  2.1464e-02,  1.5754e-02,\n",
       "                        1.1721e-01,  2.2686e-02,  2.5723e-01, -1.2861e-04, -2.2160e-04,\n",
       "                        7.6588e-05,  2.0837e-05, -4.7562e-04, -3.1940e-04,  3.5255e-04,\n",
       "                        1.0285e-03, -4.3049e-04,  1.5186e-06, -4.7794e-04,  5.6931e-04,\n",
       "                        5.1097e-04, -3.6357e-04,  3.9980e-04, -3.9509e-04,  2.4211e-04,\n",
       "                       -7.3783e-04,  2.3460e-04, -2.3252e-04,  3.7900e-05, -1.1381e-03,\n",
       "                       -6.4085e-05,  1.7961e-05, -5.3684e-04,  4.7243e-04, -1.3955e-04,\n",
       "                       -6.7316e-04, -3.5543e-04,  7.6975e-05,  4.5819e-04,  1.4436e-05,\n",
       "                       -1.7408e-04,  3.2649e-04, -9.9722e-05,  1.7342e-04,  4.4569e-04,\n",
       "                        5.8969e-04,  1.4271e-04,  1.1648e-04,  1.4288e-04, -5.1595e-05,\n",
       "                       -5.4079e-05,  8.1969e-04,  5.5917e-04, -5.4992e-04,  1.5182e-04,\n",
       "                       -2.5760e-04, -3.7479e-04, -7.2677e-04,  9.8349e-04, -3.5383e-04,\n",
       "                        6.1464e-04,  6.2837e-04, -6.7222e-04,  8.7291e-04, -1.3078e-03,\n",
       "                       -1.2433e-03, -1.6656e-03,  1.9932e-04,  3.3357e-04,  5.7179e-04,\n",
       "                        1.4624e-04,  9.4921e-05,  4.3122e-04, -2.9005e-04, -4.2961e-04,\n",
       "                       -8.4301e-04, -3.2008e-04,  3.1267e-04, -4.8357e-04,  1.4314e-04,\n",
       "                        4.9126e-04,  9.8587e-07, -4.7709e-04,  4.3509e-04, -1.8182e-04,\n",
       "                       -7.8366e-04, -8.7305e-05, -7.2791e-05, -2.0577e-05,  1.9801e-04,\n",
       "                        5.0330e-05, -3.8462e-05, -2.0364e-04,  5.3389e-04, -9.1634e-04,\n",
       "                       -3.1616e-04,  4.3530e-04,  6.7203e-04,  5.2483e-04,  6.9397e-05,\n",
       "                       -2.4933e-04, -3.1181e-04, -2.6113e-04,  5.3860e-04,  1.3048e-04,\n",
       "                        1.7254e-04,  7.1710e-04,  8.4709e-04, -1.2538e-04, -5.8951e-04,\n",
       "                       -1.3963e-04, -3.2641e-04,  4.4316e-04, -5.3169e-04,  7.3278e-04,\n",
       "                       -6.7331e-04,  7.3735e-04, -3.5628e-04, -3.4641e-04,  8.1009e-05,\n",
       "                       -7.4914e-04,  1.6925e-03, -1.5853e-04,  7.2993e-06,  3.3761e-04,\n",
       "                        7.2899e-04, -6.8893e-05, -2.4751e-04, -1.4972e-04,  3.4820e-04,\n",
       "                       -1.5621e-04, -1.3353e-03, -2.0571e-04,  1.1222e-04,  3.2674e-04,\n",
       "                       -4.5311e-04, -6.4701e-02, -3.2108e-03,  7.8078e-03,  5.5856e-03,\n",
       "                       -3.7997e-02, -2.9232e-02,  7.2232e-02,  2.3051e-02,  5.0348e-02,\n",
       "                       -5.7459e-02, -9.8051e-02,  4.9806e-02,  7.6859e-02,  1.0832e-01,\n",
       "                        3.2690e-02,  5.1593e-02, -1.1931e-02,  4.6295e-02, -5.7481e-03,\n",
       "                        5.2231e-02, -7.8244e-02,  4.9662e-02,  3.1151e-02,  6.6787e-02,\n",
       "                        2.3266e-02,  3.6514e-02,  2.1522e-02,  4.2025e-02, -4.4155e-02,\n",
       "                       -3.6222e-02,  1.2955e-02,  6.4466e-03,  5.9777e-02, -9.6918e-02,\n",
       "                       -5.3023e-02, -1.2411e-02, -3.6735e-02, -5.0539e-02, -1.3722e-02,\n",
       "                       -1.1650e-02,  2.8288e-02,  1.5168e-02,  1.4685e-02,  6.8348e-02,\n",
       "                       -4.8332e-02,  3.3461e-02, -3.7471e-02,  3.1537e-03,  2.1999e-02,\n",
       "                        1.3353e-02,  3.4789e-02,  6.5521e-03,  3.6442e-02,  1.9796e-02,\n",
       "                       -4.0597e-02,  5.8854e-02, -4.7230e-02,  3.1291e-02,  3.7691e-02,\n",
       "                       -9.2766e-03, -3.2958e-02,  6.2157e-02, -3.9491e-02,  1.7105e-03,\n",
       "                        3.7622e-03,  4.5324e-02, -1.9554e-02, -1.8084e-02, -8.9467e-02,\n",
       "                        8.9892e-02,  2.0653e-02, -3.4829e-02,  1.1788e-02,  4.7946e-02,\n",
       "                       -7.2697e-02, -4.6211e-02, -4.4990e-02, -4.7770e-02,  1.8510e-02,\n",
       "                       -2.8010e-03, -6.7537e-02, -3.5463e-02, -3.3492e-03,  4.5345e-02,\n",
       "                        4.4512e-03,  1.5081e-02, -1.5754e-02,  8.5539e-03,  6.0320e-02,\n",
       "                        2.3889e-02, -5.3059e-02,  7.8432e-04,  4.8046e-02, -4.3625e-02,\n",
       "                        6.3272e-02,  5.8244e-04, -5.4605e-02, -1.7515e-02,  6.8365e-02,\n",
       "                        3.0089e-02, -3.8647e-02,  4.7334e-02,  6.1249e-02,  9.5879e-02,\n",
       "                       -4.5695e-02, -4.1341e-02,  1.1165e-01,  2.3679e-02,  4.9133e-02,\n",
       "                       -1.7345e-02,  1.4970e-02, -1.8916e-02,  5.6363e-02,  4.7321e-02,\n",
       "                       -3.4310e-02,  3.2346e-02,  3.1602e-02,  1.4267e-02,  2.0114e-02,\n",
       "                        6.0932e-02,  4.6313e-02,  8.3628e-02,  4.6546e-02, -4.4179e-02,\n",
       "                        5.1071e-02,  9.1235e-02, -8.7184e-03, -5.0699e-02])),\n",
       "              ('transformer_encoder.layers.3.self_attn.out_proj.weight',\n",
       "               tensor([[-5.6032e-02, -2.2825e-02,  1.4816e-02,  ..., -1.0247e-01,\n",
       "                         1.0773e-01,  8.3528e-02],\n",
       "                       [-2.5192e-02, -4.4393e-02,  5.3557e-02,  ...,  2.9005e-02,\n",
       "                         1.5073e-01, -1.3125e-01],\n",
       "                       [ 9.5540e-02, -1.2271e-04, -1.1933e-01,  ...,  2.4880e-02,\n",
       "                         5.6321e-02, -1.1714e-01],\n",
       "                       ...,\n",
       "                       [ 1.4064e-01,  3.6587e-03,  1.0939e-02,  ...,  1.1274e-01,\n",
       "                         1.2214e-01, -1.1635e-01],\n",
       "                       [ 6.6555e-02,  8.4600e-03, -2.6862e-02,  ..., -2.0956e-03,\n",
       "                         5.6764e-02,  1.4183e-01],\n",
       "                       [ 5.5053e-02, -2.0058e-01,  6.5428e-02,  ..., -3.9114e-02,\n",
       "                        -1.1493e-02,  1.1422e-01]])),\n",
       "              ('transformer_encoder.layers.3.self_attn.out_proj.bias',\n",
       "               tensor([-8.2032e-02, -1.0555e-01,  3.8618e-02,  9.0763e-02,  6.0417e-03,\n",
       "                       -1.9649e-01,  2.0349e-01,  5.4348e-02, -1.6678e-01,  6.2029e-02,\n",
       "                        7.1836e-02,  2.8881e-02, -7.9570e-02,  2.8214e-02, -1.6432e-01,\n",
       "                        6.7538e-02,  2.4720e-02,  1.1192e-01,  9.5820e-03,  5.6384e-03,\n",
       "                        9.9788e-02,  9.8041e-02,  1.1629e-02, -7.4749e-02, -2.4565e-01,\n",
       "                       -5.2779e-02,  4.2235e-02, -2.2837e-02,  1.5129e-01,  7.7759e-02,\n",
       "                       -9.9120e-02,  1.6391e-02, -3.4686e-02, -4.2590e-02, -1.7643e-01,\n",
       "                       -6.0025e-02,  9.1966e-02, -1.7711e-01,  3.2967e-02,  2.3337e-02,\n",
       "                        1.1998e-02, -9.1901e-02,  2.3963e-02, -1.6520e-01, -1.0439e-02,\n",
       "                        1.3661e-01, -1.6731e-01, -2.9101e-04,  9.1090e-02, -8.9364e-02,\n",
       "                       -1.5946e-02,  2.4437e-03,  5.8294e-02, -2.8591e-03,  1.6515e-02,\n",
       "                       -8.3946e-02,  1.5373e-01,  4.1053e-02, -2.1938e-02,  1.3500e-01,\n",
       "                       -5.7872e-02, -4.5342e-02, -5.9601e-02, -2.7935e-02, -1.8791e-01,\n",
       "                        3.2745e-02,  9.4163e-03,  1.1818e-02,  1.1300e-01,  1.8933e-01,\n",
       "                       -2.8632e-02, -8.0993e-03, -9.9750e-02, -8.0317e-03, -1.4792e-01,\n",
       "                       -1.1629e-01,  5.7593e-02, -1.9553e-02, -1.3140e-01,  5.1981e-03,\n",
       "                       -9.3281e-03,  1.7285e-01, -1.6939e-01, -8.5267e-02,  9.9775e-02,\n",
       "                        2.3337e-01, -1.4881e-01,  3.9951e-02, -7.2559e-02, -1.1881e-02,\n",
       "                        1.0366e-01, -2.6457e-02, -1.6591e-01,  2.6341e-02,  1.2478e-03,\n",
       "                        3.8786e-02,  8.9745e-02, -4.2846e-02, -8.9003e-02,  4.9095e-03,\n",
       "                       -3.6156e-03,  1.6889e-02, -2.1032e-01,  6.5983e-01, -2.7010e-01,\n",
       "                       -4.7866e-02,  6.2549e-02, -1.7888e-02, -1.0829e-01,  1.2963e-01,\n",
       "                        4.9369e-02,  1.0547e-01, -3.1937e-03,  5.6213e-02, -1.2530e-01,\n",
       "                        1.4233e-01, -4.1503e-03,  5.3967e-03,  9.6647e-02,  1.3425e-01,\n",
       "                       -2.6293e-01, -1.3371e-02,  4.2250e-02, -4.1982e-02,  3.9005e-03,\n",
       "                        1.1676e-02,  4.6706e-02, -8.4848e-02])),\n",
       "              ('transformer_encoder.layers.3.linear1.weight',\n",
       "               tensor([[-0.1358,  0.1540,  0.1174,  ..., -0.0915,  0.0048,  0.1806],\n",
       "                       [-0.1572,  0.4511,  0.0436,  ..., -0.0504,  0.0596, -0.1045],\n",
       "                       [ 0.0978,  0.1501, -0.0849,  ...,  0.0124,  0.0365,  0.0762],\n",
       "                       ...,\n",
       "                       [ 0.1896,  0.1006,  0.0452,  ..., -0.1751,  0.1854,  0.0444],\n",
       "                       [ 0.3386,  0.2527,  0.0367,  ..., -0.0508, -0.1800,  0.1731],\n",
       "                       [-0.0087,  0.1301, -0.4786,  ..., -0.1684, -0.0786,  0.0138]])),\n",
       "              ('transformer_encoder.layers.3.linear1.bias',\n",
       "               tensor([-0.2160, -0.2460, -0.2330, -0.3248, -0.2266, -0.2306, -0.2701, -0.2311,\n",
       "                       -0.1345, -0.2836, -0.2394, -0.3124, -0.1410, -0.2943, -0.2323, -0.2323,\n",
       "                       -0.2473, -0.2780, -0.3546, -0.2210, -0.2059, -0.2425, -0.1705, -0.3241,\n",
       "                       -0.2010, -0.3150, -0.2231, -0.1876, -0.3420, -0.2115, -0.1583, -0.1693,\n",
       "                       -0.2751, -0.2126, -0.0953, -0.1951, -0.2262, -0.2683, -0.2494, -0.2527,\n",
       "                       -0.1769, -0.2982, -0.1329, -0.2522, -0.1681, -0.1825, -0.2607, -0.2576,\n",
       "                       -0.1952, -0.2549, -0.1765, -0.1822, -0.2843, -0.3729, -0.2763, -0.2217,\n",
       "                       -0.2007, -0.3344, -0.2324, -0.2426, -0.2773, -0.2051, -0.2702, -0.1915,\n",
       "                       -0.2575, -0.2432, -0.1275, -0.1176, -0.2610, -0.1661, -0.3040, -0.3567,\n",
       "                       -0.2473, -0.1321, -0.3061, -0.1688, -0.2162, -0.3041, -0.2284, -0.2567,\n",
       "                       -0.2134, -0.1017, -0.2190, -0.2777, -0.3165, -0.1508, -0.2341, -0.1727,\n",
       "                       -0.1966, -0.0292, -0.1686, -0.2710, -0.3334, -0.2402, -0.2580, -0.1741,\n",
       "                       -0.2511, -0.2981, -0.2129, -0.1825, -0.3457, -0.2279, -0.1666, -0.2528,\n",
       "                       -0.2795, -0.1183, -0.2069, -0.2303, -0.1455, -0.1033, -0.2145, -0.1325,\n",
       "                       -0.0936, -0.1843, -0.1918, -0.1163, -0.2426, -0.2582, -0.2419, -0.2066,\n",
       "                       -0.1652, -0.2416, -0.1167, -0.1253, -0.1472, -0.2437, -0.2369, -0.0978,\n",
       "                       -0.1589, -0.2173, -0.2458, -0.2158, -0.2682, -0.3007, -0.1883, -0.1845,\n",
       "                       -0.2414, -0.2530, -0.3341, -0.3537, -0.3878, -0.2340, -0.2764, -0.1689,\n",
       "                       -0.2313, -0.3398, -0.1442, -0.1646, -0.2684, -0.1626, -0.3737, -0.2380,\n",
       "                       -0.3519, -0.1561, -0.1022, -0.3117, -0.2380, -0.2595, -0.1965, -0.1302,\n",
       "                       -0.2386, -0.1368, -0.2391, -0.1988, -0.3182, -0.3969, -0.1382, -0.2288,\n",
       "                       -0.2890, -0.2641, -0.2405, -0.2330, -0.2809, -0.2611, -0.1372, -0.0040,\n",
       "                       -0.1972, -0.2170, -0.1870, -0.2282, -0.1343, -0.3706, -0.2190, -0.1047,\n",
       "                       -0.1682, -0.2632, -0.3337, -0.1747, -0.2193, -0.2316, -0.1928, -0.2371,\n",
       "                       -0.3219, -0.2088, -0.2229, -0.3359, -0.1538, -0.1491, -0.3259, -0.2045])),\n",
       "              ('transformer_encoder.layers.3.linear2.weight',\n",
       "               tensor([[ 0.0628, -0.2769, -0.0394,  ...,  0.1102,  0.3044, -0.0349],\n",
       "                       [-0.1345,  0.0227,  0.0122,  ..., -0.1371,  0.1079, -0.0355],\n",
       "                       [-0.1252,  0.0153, -0.2776,  ...,  0.3582,  0.0734, -0.0069],\n",
       "                       ...,\n",
       "                       [-0.0864,  0.1569,  0.1187,  ...,  0.0420, -0.2053,  0.0955],\n",
       "                       [-0.1191,  0.3065, -0.0320,  ...,  0.2010, -0.1640,  0.0671],\n",
       "                       [ 0.1270, -0.1464,  0.1365,  ..., -0.0670,  0.0061, -0.2143]])),\n",
       "              ('transformer_encoder.layers.3.linear2.bias',\n",
       "               tensor([ 0.0567,  0.1204, -0.1187, -0.0553, -0.0330,  0.1553, -0.2867, -0.0959,\n",
       "                        0.1394, -0.0669, -0.1090, -0.1359,  0.0143, -0.0547,  0.3573, -0.1565,\n",
       "                       -0.0133, -0.1176, -0.0593, -0.0368, -0.2315, -0.0677, -0.1121,  0.0620,\n",
       "                        0.2387,  0.0038, -0.0862,  0.0476, -0.2935, -0.1037,  0.0188, -0.0384,\n",
       "                        0.0374,  0.1414,  0.1907, -0.0138, -0.2193,  0.1289, -0.1282, -0.0313,\n",
       "                       -0.0232,  0.1180, -0.0053,  0.2336,  0.0104, -0.2102,  0.2461, -0.0666,\n",
       "                       -0.1405,  0.0616,  0.1206,  0.0318, -0.0428,  0.0484,  0.0330,  0.0339,\n",
       "                       -0.1201, -0.0542, -0.0152, -0.0788,  0.1780,  0.0231,  0.0780,  0.0415,\n",
       "                        0.1862, -0.0158,  0.0029, -0.0215, -0.1266, -0.1029, -0.0323,  0.0364,\n",
       "                        0.1353,  0.0186,  0.1730,  0.0713, -0.0934,  0.0555,  0.2296, -0.0158,\n",
       "                        0.0281, -0.2684,  0.0983, -0.0390, -0.2388, -0.1891,  0.0362,  0.0232,\n",
       "                        0.1600, -0.0092, -0.1198, -0.0549,  0.1259,  0.0603, -0.0171, -0.0306,\n",
       "                       -0.0691,  0.1012,  0.1652, -0.0570,  0.0886, -0.0509,  0.1913,  0.1055,\n",
       "                        0.1784,  0.0753, -0.0915, -0.0138,  0.1742, -0.2087, -0.0403, -0.0912,\n",
       "                        0.0236,  0.0233,  0.1096, -0.1464,  0.0295, -0.0691, -0.0521, -0.1708,\n",
       "                        0.1038,  0.0650, -0.0269,  0.0863, -0.0015, -0.0565, -0.1101,  0.0750])),\n",
       "              ('transformer_encoder.layers.3.norm1.weight',\n",
       "               tensor([0.7356, 0.8888, 0.7265, 0.8830, 0.8734, 0.7412, 0.9604, 0.9120, 0.9323,\n",
       "                       0.9806, 0.8790, 0.8500, 0.8825, 0.8945, 0.8929, 0.8280, 0.9448, 0.7181,\n",
       "                       0.9459, 0.9668, 0.9662, 0.9885, 0.7046, 0.9932, 1.0597, 0.9068, 0.9178,\n",
       "                       0.9976, 0.8802, 0.8198, 0.9347, 0.9180, 0.9342, 0.9208, 0.8809, 0.9017,\n",
       "                       0.9325, 0.9380, 0.9686, 1.0012, 0.8965, 0.9609, 1.0215, 0.9559, 0.9661,\n",
       "                       0.9430, 1.0746, 1.0056, 0.9879, 1.0345, 0.9529, 0.9862, 0.9353, 0.9668,\n",
       "                       1.0214, 1.0271, 1.0987, 0.9505, 1.0207, 0.9611, 1.0066, 0.9728, 0.9624,\n",
       "                       0.9956, 1.0862, 0.9450, 0.9258, 1.0219, 0.9896, 1.0843, 0.9899, 1.0114,\n",
       "                       1.0012, 1.0124, 1.0797, 0.9426, 0.9914, 0.9927, 1.0055, 1.0105, 0.9838,\n",
       "                       0.9910, 1.0364, 1.0028, 0.9802, 1.1377, 0.9972, 0.9153, 0.9730, 1.0190,\n",
       "                       1.0090, 0.9856, 1.0096, 0.9861, 0.9721, 0.9868, 0.9770, 1.0133, 0.9300,\n",
       "                       1.0131, 0.9533, 0.9587, 1.0313, 2.0748, 1.1566, 0.9567, 0.9422, 0.9895,\n",
       "                       0.9523, 1.0327, 1.0165, 1.0766, 0.9780, 0.9805, 1.0817, 1.0691, 1.0061,\n",
       "                       0.9537, 0.9923, 1.0170, 1.1436, 1.0205, 0.9453, 0.9808, 0.9497, 0.9596,\n",
       "                       0.9822, 0.9701])),\n",
       "              ('transformer_encoder.layers.3.norm1.bias',\n",
       "               tensor([-0.1054, -0.1447,  0.0796,  0.1504, -0.0116, -0.2470,  0.2839,  0.0817,\n",
       "                       -0.1653,  0.0953,  0.1243,  0.0400, -0.1342,  0.0348, -0.1845,  0.1317,\n",
       "                        0.0443,  0.1400,  0.0152, -0.0008,  0.1776,  0.1321,  0.0260, -0.0891,\n",
       "                       -0.3214, -0.0805,  0.0723, -0.0183,  0.2103,  0.1007, -0.1397,  0.0054,\n",
       "                       -0.0570, -0.1027, -0.2403, -0.0783,  0.1039, -0.2459,  0.0835,  0.0405,\n",
       "                        0.0127, -0.1087,  0.0103, -0.2317, -0.0068,  0.1596, -0.2058,  0.0096,\n",
       "                        0.1407, -0.1478,  0.0040,  0.0184,  0.1209,  0.0282,  0.0691, -0.0999,\n",
       "                        0.2531,  0.0700, -0.0429,  0.1947, -0.0877, -0.0398, -0.0875, -0.0504,\n",
       "                       -0.2509,  0.0445, -0.0037,  0.0331,  0.1635,  0.2787, -0.0208,  0.0045,\n",
       "                       -0.1367, -0.0119, -0.1960, -0.1106,  0.0939, -0.0413, -0.1673,  0.0126,\n",
       "                       -0.0208,  0.2803, -0.2147, -0.0963,  0.1692,  0.3261, -0.2113,  0.0493,\n",
       "                       -0.1140,  0.0114,  0.1541, -0.0066, -0.2249,  0.0515,  0.0335,  0.0554,\n",
       "                        0.1241, -0.0488, -0.1052,  0.0050, -0.0111,  0.0593, -0.2949,  0.7496,\n",
       "                       -0.3634, -0.0704,  0.1040, -0.0305, -0.1454,  0.1874,  0.0412,  0.1525,\n",
       "                        0.0318,  0.0583, -0.2127,  0.2004,  0.0208,  0.0278,  0.1039,  0.1949,\n",
       "                       -0.3496, -0.0257,  0.0380, -0.0510,  0.0064,  0.0086,  0.0663, -0.1331])),\n",
       "              ('transformer_encoder.layers.3.norm2.weight',\n",
       "               tensor([0.9898, 0.9390, 0.9327, 1.0445, 1.0464, 0.8939, 0.9639, 0.9853, 0.9392,\n",
       "                       1.0289, 0.9557, 1.0355, 0.9487, 1.0468, 0.9766, 1.0610, 1.0819, 0.8090,\n",
       "                       0.9931, 1.0442, 1.0437, 0.9989, 0.8974, 0.9690, 0.8886, 0.9560, 0.9592,\n",
       "                       1.0378, 0.9308, 0.9843, 0.9505, 0.9999, 1.0552, 1.0005, 0.9834, 1.0361,\n",
       "                       1.0320, 0.9431, 1.0784, 1.0454, 1.0502, 1.0513, 1.0817, 0.9660, 1.0506,\n",
       "                       1.0008, 1.0195, 1.0114, 1.0206, 0.9906, 1.0276, 1.0392, 1.0000, 0.9987,\n",
       "                       1.0721, 1.0349, 0.9817, 1.0743, 1.0243, 0.9829, 1.0702, 1.0312, 0.9954,\n",
       "                       1.0612, 0.9721, 1.0652, 1.0036, 1.0346, 1.0234, 0.9288, 1.0272, 1.0807,\n",
       "                       0.9962, 0.9954, 0.9789, 0.9983, 1.0305, 0.9850, 1.0345, 1.0790, 1.0351,\n",
       "                       0.8957, 0.9685, 1.0814, 1.0357, 0.9426, 0.8943, 0.9854, 1.0131, 1.0832,\n",
       "                       0.9654, 1.0229, 0.9196, 1.0740, 1.0538, 1.0187, 1.0741, 1.0458, 0.9512,\n",
       "                       1.0260, 1.0499, 1.0124, 0.9500, 0.7510, 0.8088, 1.0755, 1.0181, 1.0629,\n",
       "                       1.0014, 1.0150, 1.0536, 1.0118, 1.0244, 0.9971, 0.9390, 1.0246, 1.0401,\n",
       "                       1.0341, 0.9594, 1.0066, 0.8626, 1.0204, 1.0467, 1.0227, 1.0057, 1.0155,\n",
       "                       1.0553, 1.0413])),\n",
       "              ('transformer_encoder.layers.3.norm2.bias',\n",
       "               tensor([ 0.1231,  0.1164,  0.0698, -0.0057,  0.0759,  0.1808, -0.0799, -0.0043,\n",
       "                        0.1698, -0.0146,  0.0063,  0.0986,  0.1431,  0.0535,  0.1090,  0.0209,\n",
       "                        0.0355,  0.0063,  0.0944,  0.0513, -0.0163, -0.0391,  0.0901,  0.1063,\n",
       "                        0.2244,  0.1177,  0.0454,  0.0505, -0.0082,  0.0146,  0.1367,  0.0768,\n",
       "                        0.0823,  0.1175,  0.1491,  0.1208,  0.0214,  0.1665,  0.0721,  0.0678,\n",
       "                        0.0554,  0.0777,  0.0627,  0.1563,  0.0631,  0.0247,  0.1710,  0.0841,\n",
       "                        0.0281,  0.1458,  0.0184,  0.0806, -0.0307,  0.0242, -0.0127,  0.1156,\n",
       "                       -0.1211,  0.0260,  0.1062, -0.0575,  0.0793,  0.0626,  0.0908,  0.0672,\n",
       "                        0.1659, -0.0019,  0.0797,  0.0167, -0.0028, -0.1322,  0.0691,  0.0428,\n",
       "                        0.1593,  0.0592,  0.1811,  0.1158,  0.0158,  0.0540,  0.1162,  0.0488,\n",
       "                        0.0531, -0.0732,  0.2353,  0.1522,  0.0187, -0.1687,  0.1935,  0.0339,\n",
       "                        0.0493,  0.0686, -0.0415,  0.0880,  0.1941, -0.0085,  0.0574,  0.0365,\n",
       "                       -0.0220,  0.0579,  0.0842,  0.0801,  0.0411,  0.0169,  0.1758, -0.3961,\n",
       "                        0.2970,  0.0415,  0.0384,  0.1056,  0.1337, -0.0071,  0.0303, -0.0721,\n",
       "                        0.0400, -0.0009,  0.1799, -0.0566,  0.0202,  0.0461, -0.0470, -0.0519,\n",
       "                        0.3178,  0.0370, -0.0199,  0.0514,  0.0389,  0.0790,  0.0467,  0.1037])),\n",
       "              ('transformer_encoder.layers.4.self_attn.in_proj_weight',\n",
       "               tensor([[ 0.0417, -0.1798,  0.1482,  ..., -0.1038, -0.0887,  0.0413],\n",
       "                       [ 0.2216, -0.0006, -0.2099,  ...,  0.1167,  0.2032, -0.0582],\n",
       "                       [-0.2117, -0.0993, -0.0020,  ...,  0.0276, -0.0703, -0.2615],\n",
       "                       ...,\n",
       "                       [-0.0817,  0.1689, -0.0065,  ..., -0.0118,  0.0766, -0.1292],\n",
       "                       [ 0.0430,  0.0293,  0.0006,  ..., -0.0942, -0.1678, -0.1272],\n",
       "                       [ 0.0303,  0.0734,  0.0350,  ...,  0.0319, -0.1058,  0.0751]])),\n",
       "              ('transformer_encoder.layers.4.self_attn.in_proj_bias',\n",
       "               tensor([ 1.1343e-01, -2.2117e-01,  3.2899e-01,  1.8077e-02, -6.7844e-02,\n",
       "                       -6.5533e-02, -2.8291e-02, -9.3853e-02, -3.3027e-02,  5.0313e-02,\n",
       "                        1.4229e-01, -5.8654e-02,  2.7668e-01, -2.7073e-02,  1.2148e-02,\n",
       "                       -8.7795e-02,  2.1139e-01, -7.4426e-02,  5.7644e-02,  1.6395e-02,\n",
       "                       -8.6709e-02, -1.8229e-01,  9.1363e-02,  1.2100e-01, -1.1828e-01,\n",
       "                        2.6662e-01, -9.7762e-02, -2.7780e-02, -3.6497e-02,  6.6051e-02,\n",
       "                       -4.6565e-03,  4.5283e-02,  1.6066e-01, -1.5805e-02, -5.3079e-02,\n",
       "                       -2.5503e-02,  1.5926e-01, -1.1241e-01,  1.0873e-01,  1.1814e-01,\n",
       "                       -8.6772e-02, -7.8550e-02,  1.6863e-01, -6.5059e-02,  2.6943e-02,\n",
       "                       -1.3716e-02,  2.9718e-02, -1.7355e-01,  1.2483e-01,  1.4568e-01,\n",
       "                       -1.2143e-02, -4.4668e-02,  5.0619e-03,  6.2637e-02, -1.1826e-01,\n",
       "                        1.0906e-01, -1.4148e-01, -7.0059e-02, -1.1235e-01,  1.1818e-01,\n",
       "                        2.3302e-02, -1.3701e-01, -1.0978e-01,  2.8071e-01, -2.6004e-01,\n",
       "                       -3.7592e-02,  5.9488e-02,  9.3291e-02,  1.5603e-02, -1.1574e-01,\n",
       "                        1.2386e-01,  1.1363e-01, -7.2375e-02, -3.1530e-02,  1.3954e-01,\n",
       "                       -6.2758e-02,  8.4971e-02, -3.7261e-02,  9.5523e-02, -5.8884e-02,\n",
       "                        2.1637e-01, -8.7493e-02,  2.3652e-01, -1.0003e-01,  1.3425e-01,\n",
       "                        4.6214e-02,  1.3683e-01,  5.9010e-03,  3.1849e-01, -3.2044e-02,\n",
       "                        6.6079e-02,  8.8599e-02,  2.8953e-02, -6.0075e-03,  9.9596e-03,\n",
       "                       -6.6562e-03,  9.8440e-02, -1.3347e-01,  5.5107e-02, -1.8305e-01,\n",
       "                        7.4822e-04,  4.2727e-02,  1.1723e-01,  3.6019e-02,  1.0258e-01,\n",
       "                       -1.4996e-03, -1.8086e-01, -3.7956e-02, -1.6737e-01, -7.7437e-02,\n",
       "                       -2.2237e-01, -1.1954e-02, -8.3513e-02, -1.7168e-01,  1.8179e-01,\n",
       "                       -7.4396e-02, -2.2164e-01, -2.0232e-01, -1.6631e-02, -4.4008e-02,\n",
       "                       -2.6640e-01, -7.7841e-02, -9.8131e-02, -1.3623e-01,  1.6857e-01,\n",
       "                        1.4349e-01,  1.8040e-01,  2.2660e-01, -3.8758e-04, -5.6824e-04,\n",
       "                        8.0019e-04,  5.9640e-05,  3.6151e-04, -6.4381e-04,  9.9382e-05,\n",
       "                       -2.1825e-04,  9.5562e-04, -3.9681e-04, -1.7185e-04, -8.2466e-04,\n",
       "                       -1.3795e-06, -6.5729e-04,  3.6425e-04,  4.0464e-04,  6.3272e-04,\n",
       "                       -3.0656e-04, -1.4994e-03,  4.0279e-04,  4.9298e-04,  2.8687e-04,\n",
       "                        1.3815e-03,  1.0615e-03,  3.0700e-04,  7.9657e-04,  3.2272e-04,\n",
       "                       -2.1341e-04, -1.3184e-03,  1.0695e-04,  1.3163e-03,  9.8938e-04,\n",
       "                        5.0113e-04, -8.2343e-05,  1.9431e-04,  3.4836e-04, -7.9623e-04,\n",
       "                        2.0202e-04, -4.1867e-05,  8.6571e-05, -4.1996e-04, -2.7268e-04,\n",
       "                        7.3866e-04,  2.3948e-04,  6.6778e-04,  2.9231e-04,  2.4063e-05,\n",
       "                       -4.3189e-04, -2.3218e-04,  2.1846e-04,  2.9156e-04, -3.5407e-05,\n",
       "                        1.3911e-03, -5.1518e-04,  8.5730e-05,  1.9129e-04, -6.5251e-05,\n",
       "                       -2.8215e-04, -3.7007e-04, -5.2189e-05,  9.1343e-04, -5.6034e-04,\n",
       "                       -1.6011e-03,  6.4299e-04, -1.0139e-03, -5.5785e-04, -6.1559e-05,\n",
       "                        5.6969e-04,  1.1325e-05,  6.9782e-04,  3.6910e-04,  1.0707e-03,\n",
       "                       -5.8225e-04,  3.9791e-04,  2.0557e-04, -6.1059e-04,  4.5316e-04,\n",
       "                       -1.2120e-03,  4.0287e-04, -8.4655e-04,  1.5961e-03, -1.1283e-03,\n",
       "                        5.4098e-04,  9.3097e-05,  1.7341e-04,  1.1685e-03,  1.1910e-03,\n",
       "                        5.7145e-04,  1.6937e-03, -2.5589e-04,  3.1617e-04,  8.7093e-04,\n",
       "                        7.7568e-04,  3.4750e-04, -7.0799e-05,  4.0359e-04,  1.2394e-05,\n",
       "                        4.2996e-04,  2.9156e-04, -3.4366e-04,  6.1908e-05, -5.4537e-04,\n",
       "                        6.9633e-04,  1.2687e-03, -2.7514e-04,  2.3765e-04, -6.7695e-04,\n",
       "                       -7.2127e-06, -4.9861e-04, -6.1038e-04, -1.2398e-04, -1.1007e-03,\n",
       "                        2.8748e-04, -7.2176e-05,  7.5635e-04, -1.5832e-04, -1.7448e-03,\n",
       "                        3.6452e-04, -6.8153e-04, -9.8592e-04,  3.4172e-04, -6.5140e-04,\n",
       "                        1.8162e-04, -4.6506e-04,  4.3431e-04,  4.3132e-04,  3.2037e-04,\n",
       "                       -2.4505e-04, -7.2837e-02, -1.5064e-02,  9.4456e-03,  3.1490e-02,\n",
       "                       -5.6704e-02, -4.6720e-02,  6.1910e-02,  5.0234e-02,  4.6333e-02,\n",
       "                       -4.5884e-02, -8.9347e-02,  5.8806e-02,  2.0452e-02,  1.1375e-01,\n",
       "                        2.1161e-02,  6.6542e-02, -5.0288e-04,  6.7479e-02, -6.5765e-03,\n",
       "                        5.1307e-02, -5.3805e-02,  4.0447e-02,  1.0140e-01,  5.7755e-02,\n",
       "                        3.8806e-03,  3.5376e-02,  5.5437e-02,  6.1556e-02, -3.9497e-02,\n",
       "                       -3.4793e-02,  8.7035e-03, -2.7661e-04,  7.4476e-02, -3.2525e-02,\n",
       "                       -5.5990e-02, -4.0936e-03, -2.5434e-03,  2.5509e-02,  4.1925e-03,\n",
       "                       -1.8281e-03,  1.3139e-02, -1.4239e-02, -1.8761e-02,  1.0052e-01,\n",
       "                       -3.7285e-02, -8.1666e-03, -2.8517e-02, -1.4081e-02,  9.0331e-03,\n",
       "                        4.9943e-03,  1.8733e-02, -1.2638e-02,  2.9461e-02, -1.8759e-02,\n",
       "                       -6.4334e-02,  6.5701e-02, -4.7574e-02,  5.8881e-03,  3.7155e-02,\n",
       "                       -1.1145e-02, -3.0712e-02,  6.0392e-02, -1.6034e-02, -2.8642e-03,\n",
       "                       -5.5274e-02,  6.5469e-02, -3.1451e-02,  1.5895e-02, -1.1276e-01,\n",
       "                        9.0679e-02,  9.1151e-03,  5.6958e-03,  8.6767e-03,  2.5220e-02,\n",
       "                       -5.7329e-02, -6.7315e-02, -2.2781e-02, -5.2656e-03,  1.3927e-02,\n",
       "                       -6.2803e-03, -8.4562e-02, -4.7132e-03,  5.2138e-02,  1.3862e-02,\n",
       "                       -8.8224e-03, -1.1248e-02, -1.5008e-02,  2.3302e-02,  3.7452e-02,\n",
       "                        7.8594e-02, -4.1573e-02, -4.9836e-03,  8.2074e-02, -4.4251e-02,\n",
       "                        5.0449e-02, -5.4847e-03, -7.4398e-02, -2.7626e-02,  5.7884e-02,\n",
       "                        4.3825e-02,  5.6827e-03,  1.7427e-02,  7.0012e-02,  7.3706e-02,\n",
       "                        1.2938e-02, -3.0952e-02,  6.1981e-02,  1.5312e-02,  6.1266e-02,\n",
       "                       -2.9262e-02,  5.2300e-02, -3.1821e-02,  2.8015e-02,  6.7898e-02,\n",
       "                       -1.9622e-02,  6.6480e-02,  7.4777e-02,  8.0096e-02, -1.6033e-03,\n",
       "                        3.6253e-02,  1.6064e-02,  1.0896e-01,  3.6509e-02, -2.5959e-02,\n",
       "                        2.1889e-02,  5.9492e-02, -2.3604e-02,  1.5793e-02])),\n",
       "              ('transformer_encoder.layers.4.self_attn.out_proj.weight',\n",
       "               tensor([[-2.2262e-02,  3.7393e-02, -1.7495e-02,  ...,  1.2939e-01,\n",
       "                         7.9217e-05,  4.2702e-02],\n",
       "                       [ 3.0783e-02, -1.2524e-02, -3.0772e-02,  ..., -9.3320e-03,\n",
       "                         2.7052e-02, -6.7200e-02],\n",
       "                       [ 1.0547e-01, -5.3379e-02, -5.9895e-02,  ...,  1.7090e-03,\n",
       "                         6.3407e-02,  4.5686e-04],\n",
       "                       ...,\n",
       "                       [ 5.6799e-02, -5.6672e-02, -3.7948e-02,  ...,  4.3963e-02,\n",
       "                        -1.9020e-02, -1.2011e-01],\n",
       "                       [ 1.4125e-01, -6.8586e-02,  4.4857e-02,  ..., -4.1779e-02,\n",
       "                         1.4123e-01,  1.1587e-01],\n",
       "                       [ 1.0620e-01, -1.0410e-01, -2.7862e-02,  ...,  4.5547e-03,\n",
       "                         7.5957e-02, -4.7538e-02]])),\n",
       "              ('transformer_encoder.layers.4.self_attn.out_proj.bias',\n",
       "               tensor([-5.4836e-02, -1.1705e-01,  1.2011e-01,  1.3291e-01,  3.2949e-02,\n",
       "                       -1.4316e-01,  1.9326e-01,  8.7979e-03, -7.3172e-02,  3.5277e-02,\n",
       "                        3.2646e-02, -1.3317e-02, -1.6535e-01,  1.4278e-02, -5.7889e-02,\n",
       "                        2.5302e-02, -9.7246e-03, -5.5391e-02, -3.1809e-02, -1.3941e-02,\n",
       "                        9.8968e-02,  7.0624e-02, -1.8892e-02, -6.5320e-02, -2.0141e-01,\n",
       "                       -1.0938e-02, -6.7646e-02,  2.5728e-02,  1.0056e-01,  2.4237e-02,\n",
       "                       -4.5138e-03, -3.7541e-02, -2.2821e-02,  1.0387e-03, -2.3978e-01,\n",
       "                       -5.2041e-02, -5.0023e-02, -1.4089e-01,  6.7177e-02,  2.2001e-02,\n",
       "                        1.2444e-02, -1.2496e-01,  1.7882e-02, -9.6342e-02,  4.6208e-02,\n",
       "                        5.7713e-02, -9.3304e-02, -1.4899e-03,  6.4413e-02, -7.3170e-02,\n",
       "                        7.0027e-02,  2.9907e-02,  5.3387e-02,  9.2474e-02,  1.9850e-02,\n",
       "                       -4.3082e-02,  1.3678e-01,  5.4054e-02, -1.5626e-02,  9.9467e-02,\n",
       "                       -6.1532e-02, -5.1235e-02, -8.7573e-02,  1.6878e-02, -1.4955e-01,\n",
       "                       -1.1803e-02,  1.5832e-02,  4.6683e-02,  1.0262e-01,  2.1368e-01,\n",
       "                       -2.6271e-02, -6.0243e-04, -7.3046e-03,  3.4648e-02, -7.0604e-02,\n",
       "                       -7.8159e-02,  6.4545e-02,  1.9937e-03, -2.3054e-02,  1.7154e-02,\n",
       "                       -4.1553e-03,  1.2583e-01, -1.1198e-01, -1.2363e-01,  8.3330e-02,\n",
       "                        2.2093e-01, -2.2382e-01,  4.0667e-02, -9.3271e-02,  2.1070e-02,\n",
       "                        8.2345e-02,  1.8353e-02, -1.9748e-01,  6.0129e-03,  7.4939e-03,\n",
       "                        1.1507e-01,  6.2871e-02, -2.1067e-02, -6.1541e-02, -2.3051e-02,\n",
       "                        1.9267e-02, -3.2336e-02, -2.3203e-01,  6.7403e-01, -1.8136e-01,\n",
       "                       -1.2237e-01,  2.0853e-02, -5.0941e-02, -1.7286e-02,  1.2225e-01,\n",
       "                       -2.6759e-03,  9.5491e-02,  6.5385e-02,  4.6865e-02, -1.2813e-01,\n",
       "                        1.6425e-01,  4.7678e-02,  1.9642e-02,  1.1074e-02,  4.9304e-02,\n",
       "                       -2.8957e-01, -1.0336e-02, -4.3482e-02, -6.1726e-02,  3.6571e-02,\n",
       "                       -8.6288e-02,  2.5995e-02, -1.5295e-01])),\n",
       "              ('transformer_encoder.layers.4.linear1.weight',\n",
       "               tensor([[-0.0213,  0.1850,  0.1189,  ..., -0.2114,  0.1675,  0.0635],\n",
       "                       [-0.2146,  0.2134, -0.0005,  ...,  0.1266, -0.0448, -0.0602],\n",
       "                       [-0.0031,  0.1495, -0.3565,  ...,  0.0493, -0.0391, -0.1123],\n",
       "                       ...,\n",
       "                       [-0.1026,  0.0147, -0.0405,  ..., -0.1401, -0.1454, -0.1213],\n",
       "                       [-0.0225,  0.1601,  0.0863,  ..., -0.0137,  0.0088,  0.1255],\n",
       "                       [ 0.3779, -0.0202, -0.0749,  ...,  0.1170,  0.1021, -0.1224]])),\n",
       "              ('transformer_encoder.layers.4.linear1.bias',\n",
       "               tensor([-0.2641, -0.2396, -0.2203, -0.2410, -0.2070, -0.1347, -0.2497, -0.1900,\n",
       "                       -0.2511, -0.2837, -0.1495, -0.2596, -0.2053, -0.2728, -0.2242, -0.1419,\n",
       "                       -0.2420, -0.2910, -0.4416, -0.2337, -0.2407, -0.2778, -0.2494, -0.2633,\n",
       "                       -0.2687, -0.2460, -0.2080, -0.2291, -0.3132, -0.2469, -0.3165, -0.1191,\n",
       "                       -0.2503, -0.2020, -0.1775, -0.2236, -0.2136, -0.2927, -0.2697, -0.2499,\n",
       "                       -0.0400, -0.2579, -0.2060, -0.3373, -0.1755, -0.1556, -0.3191, -0.2122,\n",
       "                       -0.2284, -0.2697, -0.2937, -0.0811, -0.3129, -0.3083, -0.2995, -0.2867,\n",
       "                       -0.1083, -0.2549, -0.2310, -0.2725, -0.2686, -0.2620, -0.2732, -0.2931,\n",
       "                       -0.2083, -0.2246, -0.1561, -0.1374, -0.1953, -0.1838, -0.3153, -0.3355,\n",
       "                       -0.3430, -0.1577, -0.2901, -0.1791, -0.2327, -0.1649, -0.2175, -0.2112,\n",
       "                       -0.2152, -0.1584, -0.1489, -0.2295, -0.3440, -0.2214, -0.1567, -0.1428,\n",
       "                       -0.1778, -0.0975, -0.1786, -0.2928, -0.3013, -0.2296, -0.2410, -0.1819,\n",
       "                       -0.2398, -0.3428, -0.1204, -0.1476, -0.2428, -0.2689, -0.1200, -0.1973,\n",
       "                       -0.2484, -0.1382, -0.1474, -0.1094, -0.1493, -0.2449, -0.2753, -0.1532,\n",
       "                       -0.2119, -0.2281, -0.3065, -0.1941, -0.2096, -0.1753, -0.2630, -0.2396,\n",
       "                       -0.1329, -0.1921, -0.1129, -0.1611, -0.1336, -0.2409, -0.2431, -0.1430,\n",
       "                       -0.1821, -0.1915, -0.3163, -0.2462, -0.2255, -0.2525, -0.1917, -0.1424,\n",
       "                       -0.2967, -0.1783, -0.2999, -0.3164, -0.2410, -0.2192, -0.2722, -0.2696,\n",
       "                       -0.2578, -0.2890, -0.1513, -0.1412, -0.3026, -0.2105, -0.3522, -0.2720,\n",
       "                       -0.3178, -0.2757, -0.1396, -0.2868, -0.2980, -0.2931, -0.2301, -0.2801,\n",
       "                       -0.2978, -0.1720, -0.2581, -0.1568, -0.2801, -0.3256, -0.1129, -0.0594,\n",
       "                       -0.2348, -0.2855, -0.3017, -0.2734, -0.2400, -0.2418, -0.1797, -0.0802,\n",
       "                       -0.3055, -0.2668, -0.1177, -0.2363, -0.1724, -0.3911, -0.2623, -0.1344,\n",
       "                       -0.2772, -0.2303, -0.2570, -0.1988, -0.2065, -0.2656, -0.2005, -0.0952,\n",
       "                       -0.2669, -0.1768, -0.2312, -0.2977, -0.1618, -0.2792, -0.3155, -0.2785])),\n",
       "              ('transformer_encoder.layers.4.linear2.weight',\n",
       "               tensor([[-2.5106e-01,  7.5258e-02,  7.4438e-02,  ...,  1.7593e-01,\n",
       "                        -1.2569e-04,  2.0470e-01],\n",
       "                       [ 1.0932e-01,  1.5606e-01, -1.7631e-01,  ..., -7.4266e-02,\n",
       "                         1.0793e-01, -2.8075e-01],\n",
       "                       [-3.7163e-02,  1.2986e-01, -2.1608e-01,  ..., -1.0362e-01,\n",
       "                         3.5808e-01, -1.1363e-01],\n",
       "                       ...,\n",
       "                       [-2.2561e-01,  6.1200e-02,  1.2738e-01,  ...,  6.8428e-02,\n",
       "                         7.0644e-02,  1.1468e-01],\n",
       "                       [ 3.0181e-01,  3.9085e-02, -4.6145e-02,  ..., -5.3795e-03,\n",
       "                         1.1810e-01,  1.8825e-01],\n",
       "                       [ 2.9089e-01,  1.4705e-01,  9.2262e-02,  ..., -1.8372e-03,\n",
       "                        -2.3493e-01, -5.5793e-02]])),\n",
       "              ('transformer_encoder.layers.4.linear2.bias',\n",
       "               tensor([ 0.0791,  0.1414, -0.1721, -0.1466, -0.0521,  0.0658, -0.3118, -0.0663,\n",
       "                        0.0813, -0.0327, -0.0635, -0.1407,  0.0469, -0.0512,  0.2818, -0.1506,\n",
       "                        0.0194, -0.0191, -0.0534, -0.0303, -0.2292, -0.1257, -0.0778,  0.0275,\n",
       "                        0.2757, -0.0195, -0.0295,  0.0170, -0.2646, -0.0573, -0.0492, -0.0040,\n",
       "                        0.0145,  0.1108,  0.2568, -0.0265, -0.1869,  0.0477, -0.1475, -0.0630,\n",
       "                        0.0063,  0.1717, -0.0120,  0.2124,  0.0306, -0.2235,  0.1774, -0.0842,\n",
       "                       -0.1539,  0.0473,  0.0855,  0.0011, -0.0010,  0.0104, -0.0051,  0.0433,\n",
       "                       -0.1388, -0.0476, -0.0113, -0.0521,  0.1917,  0.0957,  0.0921,  0.0620,\n",
       "                        0.2335,  0.0098, -0.0129, -0.0172, -0.1584, -0.1022, -0.0270,  0.0383,\n",
       "                        0.0916, -0.0082,  0.0887,  0.1014, -0.0848,  0.0942,  0.2099,  0.0036,\n",
       "                        0.0643, -0.2793,  0.0575,  0.0209, -0.2800, -0.1882,  0.0762,  0.0554,\n",
       "                        0.1496, -0.0248, -0.0945, -0.0353,  0.1560,  0.0777, -0.0747, -0.0583,\n",
       "                       -0.0496,  0.1457,  0.1735, -0.0807,  0.0291, -0.0177,  0.2027,  0.3812,\n",
       "                        0.1312,  0.1659, -0.0918,  0.0160,  0.0846, -0.2424, -0.0378, -0.0733,\n",
       "                       -0.0423,  0.0344,  0.1342, -0.1693,  0.0131, -0.0724, -0.0060, -0.1391,\n",
       "                        0.1107,  0.1032,  0.0277,  0.1219,  0.0077, -0.0197, -0.1422,  0.1480])),\n",
       "              ('transformer_encoder.layers.4.norm1.weight',\n",
       "               tensor([0.7997, 0.8844, 0.8174, 0.9845, 0.8938, 0.8665, 1.0069, 0.8612, 0.8906,\n",
       "                       1.0027, 0.8920, 0.9347, 0.9179, 0.9647, 0.9082, 0.9307, 0.9779, 0.6650,\n",
       "                       0.9280, 0.9706, 0.9992, 0.9695, 0.7765, 0.9807, 1.0141, 0.8770, 0.8674,\n",
       "                       1.0054, 0.8780, 0.8462, 0.8537, 0.9049, 0.9909, 0.9373, 0.9254, 1.0031,\n",
       "                       0.9252, 0.8990, 0.9678, 0.9883, 0.9495, 0.9942, 1.0055, 0.9282, 0.9967,\n",
       "                       0.9394, 1.0313, 0.9925, 1.0178, 1.0032, 0.9462, 0.9883, 0.8892, 0.8849,\n",
       "                       1.0225, 1.0705, 1.1080, 0.9926, 1.0411, 0.9448, 0.9904, 0.9453, 1.0091,\n",
       "                       0.9972, 1.0701, 0.9736, 0.9648, 1.0277, 0.9817, 1.1254, 0.9966, 1.0078,\n",
       "                       0.9532, 0.9819, 1.0638, 0.9501, 0.9742, 0.9393, 0.9538, 1.0563, 0.9559,\n",
       "                       0.8599, 1.0067, 1.0357, 0.9934, 1.1494, 1.0716, 0.8648, 0.9699, 1.0499,\n",
       "                       0.9294, 0.9713, 1.0607, 1.0338, 0.9516, 0.9426, 0.9810, 0.9751, 0.9160,\n",
       "                       0.9896, 0.9388, 0.8875, 1.0632, 2.2597, 1.0960, 1.0115, 0.9203, 0.9882,\n",
       "                       0.9670, 1.0242, 1.0280, 1.0699, 0.9418, 0.9530, 1.0931, 1.1031, 1.0450,\n",
       "                       0.9333, 0.9229, 0.9867, 1.1815, 1.0000, 0.9921, 0.9593, 0.8840, 0.9019,\n",
       "                       0.9924, 1.0164])),\n",
       "              ('transformer_encoder.layers.4.norm1.bias',\n",
       "               tensor([-0.0541, -0.1474,  0.1479,  0.1738,  0.0154, -0.1640,  0.2681,  0.0057,\n",
       "                       -0.0786,  0.0609,  0.0533,  0.0077, -0.1600,  0.0133, -0.0978,  0.0428,\n",
       "                        0.0032, -0.0519, -0.0065, -0.0136,  0.1233,  0.1181,  0.0040, -0.0576,\n",
       "                       -0.2480, -0.0096, -0.0562,  0.0215,  0.1475,  0.0225, -0.0104, -0.0281,\n",
       "                       -0.0163, -0.0278, -0.2886, -0.0596, -0.0418, -0.1694,  0.0907,  0.0315,\n",
       "                        0.0106, -0.1590,  0.0364, -0.1517,  0.0402,  0.0874, -0.1056,  0.0267,\n",
       "                        0.1042, -0.1102,  0.0737,  0.0566,  0.0633,  0.0966,  0.0472, -0.0537,\n",
       "                        0.2196,  0.0487, -0.0213,  0.1340, -0.0634, -0.0667, -0.1219,  0.0146,\n",
       "                       -0.1859, -0.0209, -0.0041,  0.0491,  0.1383,  0.2549, -0.0185, -0.0036,\n",
       "                       -0.0416,  0.0297, -0.0892, -0.0958,  0.0765, -0.0338, -0.0547,  0.0135,\n",
       "                       -0.0138,  0.1929, -0.1221, -0.1284,  0.1307,  0.2865, -0.2558,  0.0457,\n",
       "                       -0.1234,  0.0325,  0.1122,  0.0380, -0.2333,  0.0186,  0.0348,  0.1262,\n",
       "                        0.0761, -0.0295, -0.0571, -0.0151,  0.0220, -0.0159, -0.2798,  0.7185,\n",
       "                       -0.2228, -0.1406,  0.0505, -0.0655, -0.0157,  0.1544,  0.0192,  0.1224,\n",
       "                        0.0849,  0.0578, -0.1715,  0.2121,  0.0667,  0.0203,  0.0026,  0.0916,\n",
       "                       -0.3399, -0.0367, -0.0589, -0.0724,  0.0370, -0.1024,  0.0310, -0.1953])),\n",
       "              ('transformer_encoder.layers.4.norm2.weight',\n",
       "               tensor([1.1305, 1.0154, 0.9887, 1.1020, 1.1277, 0.9453, 1.0194, 1.1161, 1.0736,\n",
       "                       1.0836, 1.0992, 1.0777, 1.0146, 1.1302, 1.1656, 1.1820, 1.1174, 1.0973,\n",
       "                       1.0579, 1.1384, 1.0804, 1.0434, 1.0828, 1.0644, 1.0271, 1.1275, 1.1050,\n",
       "                       1.1379, 1.1096, 1.1660, 1.0938, 1.1482, 1.1605, 1.1643, 1.0227, 1.0824,\n",
       "                       1.0942, 1.0217, 1.1348, 1.0874, 1.0888, 1.0532, 1.1159, 1.0443, 1.1197,\n",
       "                       1.0498, 1.1493, 1.0280, 1.0797, 1.0520, 1.1356, 1.0443, 0.9994, 1.0360,\n",
       "                       1.1130, 1.1590, 1.0566, 1.0839, 1.1172, 1.0949, 1.1396, 1.1408, 1.1098,\n",
       "                       1.1291, 1.0633, 1.1734, 1.0543, 1.0821, 1.1301, 0.8877, 1.0886, 1.1292,\n",
       "                       1.1384, 1.1342, 1.0256, 1.0297, 1.0426, 1.0571, 1.1009, 1.1111, 1.0735,\n",
       "                       1.0651, 1.0740, 1.1531, 1.1549, 0.9725, 0.9065, 1.1122, 1.0701, 1.1189,\n",
       "                       1.0885, 1.0895, 0.9272, 1.0498, 1.1246, 1.0923, 1.0922, 1.1390, 1.0680,\n",
       "                       1.1059, 1.1204, 1.1173, 0.9353, 0.1317, 0.8828, 1.0967, 1.1436, 1.1183,\n",
       "                       1.1717, 1.1109, 1.1193, 1.0842, 1.0780, 1.0591, 0.9798, 0.9750, 1.1473,\n",
       "                       1.1281, 1.0926, 1.1430, 0.8242, 1.0898, 1.1262, 1.1300, 1.1389, 0.9822,\n",
       "                       1.1108, 1.0792])),\n",
       "              ('transformer_encoder.layers.4.norm2.bias',\n",
       "               tensor([ 0.1050,  0.1218,  0.0367, -0.0168,  0.0708,  0.1631, -0.0143,  0.0872,\n",
       "                        0.1268,  0.0077,  0.0736,  0.1449,  0.2160,  0.0982,  0.0198,  0.1198,\n",
       "                        0.0618,  0.1241,  0.1324,  0.0957,  0.0514,  0.0317,  0.1225,  0.1473,\n",
       "                        0.2030,  0.1064,  0.1482,  0.0424,  0.0855,  0.0897,  0.0993,  0.0822,\n",
       "                        0.0984,  0.0460,  0.1977,  0.1569,  0.2068,  0.2052,  0.0857,  0.0759,\n",
       "                        0.0577,  0.1532,  0.0524,  0.1240,  0.0444,  0.0939,  0.1125,  0.0992,\n",
       "                        0.0594,  0.1523, -0.0430,  0.0420,  0.0205, -0.0336,  0.0556,  0.1553,\n",
       "                       -0.0778,  0.0445,  0.1409, -0.0387,  0.0481,  0.1253,  0.1770,  0.0476,\n",
       "                        0.2171,  0.0720,  0.1048,  0.0660,  0.0101, -0.1513,  0.1337,  0.0714,\n",
       "                        0.0489,  0.0218,  0.1379,  0.1218,  0.0418,  0.0364,  0.0388,  0.0756,\n",
       "                        0.0645,  0.0478,  0.2361,  0.2390,  0.1048, -0.1847,  0.2822, -0.0186,\n",
       "                        0.1154,  0.0674,  0.0016,  0.0795,  0.2453,  0.0105,  0.0853, -0.0505,\n",
       "                        0.0155,  0.0345,  0.0716,  0.1257,  0.0349,  0.1275,  0.2626, -0.7804,\n",
       "                        0.2916,  0.1326,  0.1126,  0.1549,  0.0446,  0.0493,  0.0780, -0.0554,\n",
       "                        0.0212, -0.0241,  0.2001, -0.0788, -0.0014,  0.0806,  0.0623,  0.0530,\n",
       "                        0.3548,  0.0616,  0.1093,  0.0891,  0.0536,  0.1749,  0.1073,  0.1922])),\n",
       "              ('transformer_encoder.layers.5.self_attn.in_proj_weight',\n",
       "               tensor([[-0.0457, -0.2061, -0.0258,  ..., -0.2762, -0.0776,  0.0065],\n",
       "                       [ 0.1057,  0.0270, -0.1396,  ...,  0.1617,  0.1205,  0.0687],\n",
       "                       [-0.0947, -0.3350, -0.2176,  ..., -0.1719, -0.2493,  0.2897],\n",
       "                       ...,\n",
       "                       [-0.0605, -0.0246, -0.0728,  ..., -0.0178,  0.1914, -0.1137],\n",
       "                       [ 0.0722, -0.0234,  0.0768,  ...,  0.0394, -0.0605, -0.0751],\n",
       "                       [-0.0374, -0.0368, -0.0144,  ..., -0.0620, -0.2359, -0.0304]])),\n",
       "              ('transformer_encoder.layers.5.self_attn.in_proj_bias',\n",
       "               tensor([ 2.9064e-01, -1.4598e-01,  7.9552e-02,  1.5910e-02,  3.4711e-02,\n",
       "                        3.2147e-01,  8.5720e-03, -3.9312e-01, -1.0083e-03, -3.7465e-02,\n",
       "                        2.9651e-01, -3.0802e-01,  2.6201e-01,  4.7398e-02,  6.2269e-02,\n",
       "                       -3.3573e-01,  3.3324e-01, -3.2645e-02,  1.4015e-01,  2.9797e-01,\n",
       "                        1.6611e-01, -2.6736e-01,  1.3655e-01, -1.3556e-01, -1.7470e-01,\n",
       "                        5.3744e-01, -1.1048e-01, -2.9946e-02, -3.6783e-01,  3.2317e-01,\n",
       "                       -2.7872e-01,  2.8856e-02, -8.1572e-02,  1.4816e-01,  5.5792e-02,\n",
       "                       -1.6098e-01,  3.8153e-01, -1.6715e-01,  2.8692e-01,  5.7799e-01,\n",
       "                        9.2962e-02, -3.1959e-01,  9.2515e-02, -4.1855e-01, -1.1195e-01,\n",
       "                       -4.2827e-01,  9.5448e-02, -9.4357e-02,  2.3510e-01,  3.4956e-01,\n",
       "                       -2.2447e-01, -1.4140e-01,  2.7540e-01, -2.7634e-01,  1.4492e-01,\n",
       "                        3.7067e-02,  4.2167e-02, -3.0676e-01, -2.9928e-01, -3.1834e-01,\n",
       "                       -3.4672e-02, -3.0377e-01,  4.6929e-02,  4.1307e-01, -4.8963e-01,\n",
       "                       -1.1169e-01,  1.7833e-01,  1.3851e-01,  5.7978e-03,  1.2202e-02,\n",
       "                        2.0323e-01,  7.2764e-02, -3.7185e-01, -1.0460e-01,  1.4253e-01,\n",
       "                       -1.0655e-01,  3.2019e-01, -2.1165e-01,  4.8875e-02, -1.4397e-01,\n",
       "                        5.5153e-01, -3.4282e-01,  4.0768e-02, -2.8737e-01,  3.7429e-01,\n",
       "                        2.2230e-01,  3.7876e-01,  3.4167e-01,  5.3478e-01, -1.0892e-01,\n",
       "                        2.7160e-01,  1.4746e-01,  2.0821e-01,  1.9374e-01,  2.3490e-01,\n",
       "                        1.9564e-01, -1.0021e-01, -8.2741e-02,  2.3533e-01, -5.2519e-01,\n",
       "                        2.5227e-01,  1.2237e-01,  2.7739e-01, -6.2071e-02,  1.1505e-01,\n",
       "                        6.6974e-02, -1.7973e-01, -8.7769e-02,  2.9972e-01, -2.3778e-01,\n",
       "                       -4.5809e-01, -2.3200e-01, -6.7212e-02, -1.1806e-01,  9.2961e-02,\n",
       "                       -2.6511e-01, -3.0259e-01, -3.3930e-01, -2.2300e-01, -2.7993e-01,\n",
       "                        2.1716e-02, -1.8518e-01, -3.7065e-01, -3.7303e-01,  1.5778e-01,\n",
       "                        1.4384e-01,  1.6227e-01,  2.1534e-01,  2.9672e-04, -4.6817e-04,\n",
       "                        4.7314e-04, -2.5379e-04,  4.4272e-04,  8.8757e-04, -2.3341e-04,\n",
       "                        3.7408e-04,  1.5822e-04,  4.2674e-06,  6.3107e-04, -1.0704e-03,\n",
       "                        2.6462e-06,  2.0291e-04, -3.3932e-04, -5.4640e-05, -1.0397e-03,\n",
       "                        1.5614e-04,  5.7957e-04,  1.1162e-03,  6.8513e-04,  1.4041e-04,\n",
       "                       -5.4864e-04, -9.7658e-05,  1.4479e-05, -2.0571e-04, -1.4065e-03,\n",
       "                        9.1403e-05,  1.4001e-04,  5.8662e-04, -1.6559e-04,  1.2826e-04,\n",
       "                        1.0886e-04,  3.3059e-04, -1.6061e-03,  3.7821e-04, -4.5273e-04,\n",
       "                        1.0434e-03,  1.7459e-04,  1.3788e-03,  4.0970e-04, -1.6991e-03,\n",
       "                        1.5887e-03, -1.4610e-03,  3.7254e-04, -4.7299e-04, -4.1277e-04,\n",
       "                       -1.1776e-03,  1.0152e-03,  7.6111e-04, -8.7372e-04, -1.4265e-04,\n",
       "                        9.3217e-04,  7.5986e-04,  7.9333e-04,  2.2365e-04,  2.2213e-04,\n",
       "                       -1.3780e-03, -8.9533e-04,  4.5630e-04, -8.8653e-04, -1.1529e-03,\n",
       "                        5.6025e-04,  1.2279e-03, -4.2873e-04, -8.3653e-04,  9.2471e-05,\n",
       "                        2.1706e-04, -6.8412e-04,  1.7769e-04, -8.2740e-04, -1.0935e-04,\n",
       "                       -1.5466e-03, -1.2652e-03, -2.8534e-05, -6.3150e-04,  2.9656e-04,\n",
       "                       -9.4627e-04, -1.8351e-03,  4.5159e-04,  2.2980e-03, -1.7518e-03,\n",
       "                        1.3962e-03, -6.3918e-04,  2.2207e-03,  1.6225e-04,  8.1471e-04,\n",
       "                        1.9372e-03,  1.7831e-03, -8.2304e-04, -3.9152e-04, -1.5210e-04,\n",
       "                        1.1832e-03,  3.3771e-04,  8.2825e-04,  7.5380e-04,  1.2668e-03,\n",
       "                        6.5449e-05,  2.4228e-04,  5.1528e-04, -1.1050e-03,  6.2900e-04,\n",
       "                        6.2536e-04,  4.4738e-04,  6.6228e-04, -1.9223e-04,  1.3576e-04,\n",
       "                       -3.8992e-04,  9.1346e-05,  1.3284e-03,  7.8798e-04,  7.3938e-04,\n",
       "                        1.3123e-03, -1.1057e-04,  4.5908e-04, -1.9712e-04,  4.6149e-04,\n",
       "                        1.2598e-03,  5.3463e-04,  1.3865e-03,  1.2675e-03,  3.0436e-06,\n",
       "                        7.3618e-04,  6.5340e-04,  4.5998e-05, -1.9430e-03, -7.3652e-04,\n",
       "                       -7.2884e-04, -4.3656e-02,  1.6270e-02,  1.6212e-02,  4.9503e-02,\n",
       "                       -3.4087e-02, -3.4251e-03,  4.4806e-02,  4.0919e-02,  1.1644e-02,\n",
       "                       -2.4649e-02, -8.7261e-02,  6.0461e-03,  1.2491e-02,  4.6572e-02,\n",
       "                       -1.6338e-02,  5.5992e-02, -3.2713e-03,  1.3896e-02, -8.3123e-03,\n",
       "                        4.4345e-02, -1.2154e-02,  5.4677e-02,  5.4900e-02,  2.7495e-02,\n",
       "                        1.0439e-02, -1.7263e-02, -1.4246e-02,  2.5430e-02, -7.5053e-03,\n",
       "                       -2.5568e-02, -3.0871e-03,  3.2890e-02,  4.6272e-02, -4.5018e-02,\n",
       "                       -4.1803e-02,  1.1446e-02, -4.8157e-03,  1.9394e-02,  2.1643e-03,\n",
       "                       -9.6512e-03, -1.4537e-02, -9.3730e-03,  6.0623e-04,  3.1812e-02,\n",
       "                       -5.4290e-02, -2.4102e-02, -1.4055e-02, -2.8040e-03, -3.1460e-03,\n",
       "                        1.1946e-02,  2.2679e-02,  1.3993e-02,  1.2036e-02,  2.7403e-02,\n",
       "                       -5.8874e-02,  3.5670e-02, -4.5373e-02, -1.1691e-02, -2.9328e-03,\n",
       "                        8.2865e-03,  6.4765e-03,  5.7770e-02, -2.3306e-02,  3.3283e-02,\n",
       "                        1.6975e-03,  5.8234e-02, -6.3838e-02, -3.6564e-02, -8.8848e-02,\n",
       "                        4.9207e-02, -3.2027e-02, -3.0566e-02,  2.8044e-02, -9.1771e-03,\n",
       "                       -2.0279e-02, -4.8891e-02,  4.1396e-03, -8.4108e-03,  1.0548e-02,\n",
       "                       -3.1495e-03, -4.9918e-02, -1.0602e-02, -1.2600e-02,  1.2930e-02,\n",
       "                       -7.1997e-03, -2.2429e-02, -2.1755e-02,  6.1804e-02,  4.1360e-02,\n",
       "                        2.9765e-02, -2.8427e-02,  1.9124e-03,  3.1258e-02, -1.8496e-02,\n",
       "                        2.6722e-02,  1.6513e-02, -1.8491e-03, -2.5848e-02,  2.3274e-02,\n",
       "                        3.2832e-02, -9.0731e-03,  1.8225e-02,  2.1957e-02,  7.9264e-02,\n",
       "                        3.4491e-03, -2.6357e-02,  4.2641e-02, -1.2564e-02,  2.6804e-02,\n",
       "                       -1.6734e-03,  1.5940e-02, -4.3260e-02,  1.4167e-02,  6.6582e-02,\n",
       "                       -2.3610e-02,  3.4291e-02,  5.6576e-02,  3.4642e-02,  3.4369e-02,\n",
       "                        4.8626e-02,  4.1594e-03,  6.5067e-02,  1.2996e-02, -3.0032e-02,\n",
       "                        2.9862e-02,  5.9688e-02, -9.2466e-03, -2.8636e-02])),\n",
       "              ('transformer_encoder.layers.5.self_attn.out_proj.weight',\n",
       "               tensor([[-0.0840, -0.0203,  0.0287,  ..., -0.0140,  0.0550,  0.1325],\n",
       "                       [ 0.0269, -0.0592, -0.0476,  ...,  0.0580,  0.1025, -0.0138],\n",
       "                       [-0.1064,  0.0637, -0.0130,  ...,  0.0523,  0.0404,  0.0614],\n",
       "                       ...,\n",
       "                       [-0.0021,  0.0826, -0.0406,  ...,  0.1154,  0.0781,  0.0328],\n",
       "                       [ 0.1005, -0.0815, -0.0263,  ..., -0.0346,  0.1155,  0.0757],\n",
       "                       [-0.0017, -0.0274, -0.0632,  ...,  0.1609,  0.0732, -0.0143]])),\n",
       "              ('transformer_encoder.layers.5.self_attn.out_proj.bias',\n",
       "               tensor([-0.0865, -0.1058,  0.0498,  0.1864, -0.0404, -0.0226,  0.2785, -0.0841,\n",
       "                        0.0335,  0.0183,  0.0951,  0.0222,  0.0636,  0.1377, -0.1708,  0.0950,\n",
       "                       -0.0283, -0.0580,  0.0750, -0.0112,  0.1456,  0.0679,  0.0485,  0.0584,\n",
       "                       -0.1574,  0.0129, -0.0352,  0.0652,  0.1678, -0.1194, -0.0326, -0.0338,\n",
       "                        0.0063, -0.1170, -0.0840,  0.0534,  0.0581,  0.0682,  0.0354,  0.0081,\n",
       "                       -0.0619, -0.1414,  0.0453, -0.1614, -0.0521,  0.0543,  0.0502, -0.0017,\n",
       "                        0.0475, -0.1152, -0.0229,  0.0047, -0.0282, -0.0269,  0.1043, -0.0504,\n",
       "                        0.4281, -0.0266,  0.0060,  0.0644, -0.1140, -0.1296, -0.0127, -0.0140,\n",
       "                       -0.1053, -0.0821,  0.0598,  0.0008,  0.1281,  0.0113,  0.0363, -0.0674,\n",
       "                       -0.0937, -0.0628, -0.0580, -0.0841,  0.0251, -0.2200, -0.0908, -0.0270,\n",
       "                       -0.1538,  0.1903,  0.0419, -0.0418,  0.2286,  0.1846, -0.0878, -0.1431,\n",
       "                       -0.0234, -0.0236,  0.0755,  0.0611, -0.1282,  0.0138,  0.1164, -0.1007,\n",
       "                       -0.0085, -0.1039, -0.1190, -0.0159,  0.0582,  0.0909, -0.0781,  0.3373,\n",
       "                        0.0193, -0.1195,  0.1006, -0.0609, -0.0277,  0.0611,  0.0237,  0.0243,\n",
       "                        0.0798, -0.0959, -0.1537,  0.2047, -0.0505, -0.0215, -0.0842,  0.0780,\n",
       "                       -0.1183, -0.1221, -0.0416, -0.0595,  0.0010, -0.1165,  0.0368, -0.1488])),\n",
       "              ('transformer_encoder.layers.5.linear1.weight',\n",
       "               tensor([[-1.8530e-01,  1.0148e-01,  3.5940e-04,  ...,  1.2067e-01,\n",
       "                         4.5533e-02,  1.8870e-01],\n",
       "                       [ 1.2918e-01,  5.6284e-01,  9.5986e-02,  ...,  8.9532e-02,\n",
       "                         1.3342e-01,  2.2606e-01],\n",
       "                       [ 1.1339e-01,  2.6683e-03,  1.0899e-01,  ...,  9.2466e-03,\n",
       "                         1.1432e-01, -4.3490e-02],\n",
       "                       ...,\n",
       "                       [ 1.4026e-01,  1.4049e-01, -1.8622e-01,  ...,  1.3705e-01,\n",
       "                        -1.0831e-01, -6.0146e-02],\n",
       "                       [ 3.1501e-02, -1.3133e-01,  8.7203e-02,  ...,  1.8748e-01,\n",
       "                         8.4794e-02,  6.7986e-02],\n",
       "                       [-1.7504e-01,  1.5630e-01, -5.1728e-02,  ...,  6.8217e-02,\n",
       "                        -3.9521e-02, -1.7285e-01]])),\n",
       "              ('transformer_encoder.layers.5.linear1.bias',\n",
       "               tensor([-0.3036, -0.3065, -0.2103, -0.2942, -0.1794, -0.2212, -0.2921, -0.2717,\n",
       "                       -0.1954, -0.2402, -0.2400, -0.2681, -0.3086, -0.3268, -0.2771, -0.2030,\n",
       "                       -0.3018, -0.2013, -0.3322, -0.2026, -0.2636, -0.2643, -0.2588, -0.2359,\n",
       "                       -0.2592, -0.2670, -0.2546, -0.1824, -0.3024, -0.2719, -0.3149, -0.1737,\n",
       "                       -0.2610, -0.1885, -0.2106, -0.1999, -0.1425, -0.3648, -0.2928, -0.2382,\n",
       "                       -0.2146, -0.2472, -0.2336, -0.3173, -0.1760, -0.1702, -0.3456, -0.2504,\n",
       "                       -0.2260, -0.2212, -0.2326, -0.1832, -0.3448, -0.3125, -0.2944, -0.2344,\n",
       "                       -0.1339, -0.3437, -0.2641, -0.2335, -0.3560, -0.2945, -0.3276, -0.3026,\n",
       "                       -0.2532, -0.3296, -0.1745, -0.2040, -0.1463, -0.1583, -0.3538, -0.3106,\n",
       "                       -0.2780, -0.1696, -0.2540, -0.2325, -0.2732, -0.2492, -0.1844, -0.2676,\n",
       "                       -0.1992, -0.1580, -0.1985, -0.2705, -0.3185, -0.2161, -0.2675, -0.1967,\n",
       "                       -0.2750, -0.1826, -0.2138, -0.2807, -0.3273, -0.3405, -0.2478, -0.2094,\n",
       "                       -0.2829, -0.2723, -0.2492, -0.1830, -0.2261, -0.2413, -0.1782, -0.3504,\n",
       "                       -0.2249, -0.2338, -0.2571, -0.1646, -0.2241, -0.1758, -0.2619, -0.2194,\n",
       "                       -0.1613, -0.0557, -0.2900, -0.1219, -0.2951, -0.1579, -0.2512, -0.2888,\n",
       "                       -0.1449, -0.2226, -0.2628, -0.1421, -0.1049, -0.2816, -0.3324, -0.1870,\n",
       "                       -0.1304, -0.2663, -0.2893, -0.2995, -0.2181, -0.2967, -0.1960, -0.1569,\n",
       "                       -0.3101, -0.2267, -0.3345, -0.2882, -0.3438, -0.1563, -0.2560, -0.1457,\n",
       "                       -0.3134, -0.3461, -0.1645, -0.2018, -0.2168, -0.2032, -0.3423, -0.3384,\n",
       "                       -0.3441, -0.2128, -0.2155, -0.3865, -0.2491, -0.2527, -0.1701, -0.2514,\n",
       "                       -0.1636, -0.2617, -0.2495, -0.2598, -0.3232, -0.3558, -0.1858, -0.2348,\n",
       "                       -0.2895, -0.2092, -0.3002, -0.2853, -0.1960, -0.3485, -0.2208, -0.1588,\n",
       "                       -0.2527, -0.2868, -0.2434, -0.2000, -0.1585, -0.3049, -0.1671, -0.1593,\n",
       "                       -0.2645, -0.3646, -0.2850, -0.2195, -0.2529, -0.3064, -0.3173, -0.1492,\n",
       "                       -0.2941, -0.1941, -0.2762, -0.2535, -0.2386, -0.2921, -0.2830, -0.4072])),\n",
       "              ('transformer_encoder.layers.5.linear2.weight',\n",
       "               tensor([[-0.1282, -0.1866,  0.1569,  ..., -0.0553,  0.2501,  0.1024],\n",
       "                       [-0.0346,  0.2589,  0.1106,  ..., -0.1814,  0.2370,  0.0668],\n",
       "                       [ 0.0983,  0.0410, -0.0985,  ...,  0.0825,  0.1607, -0.0202],\n",
       "                       ...,\n",
       "                       [ 0.1332,  0.1217,  0.0429,  ..., -0.1055,  0.1399,  0.2699],\n",
       "                       [ 0.2040,  0.0118, -0.0564,  ...,  0.0056, -0.0763,  0.0314],\n",
       "                       [ 0.0727,  0.2291, -0.0065,  ..., -0.2099, -0.1269,  0.0862]])),\n",
       "              ('transformer_encoder.layers.5.linear2.bias',\n",
       "               tensor([-0.0241,  0.0967, -0.0192, -0.1080, -0.1162, -0.0688, -0.1263, -0.0933,\n",
       "                        0.0332,  0.0009,  0.0153, -0.1081,  0.0952, -0.0335,  0.2644, -0.0821,\n",
       "                        0.0675,  0.0037,  0.0229, -0.0038, -0.2005, -0.1165, -0.0185,  0.0297,\n",
       "                        0.1979, -0.0666, -0.0410,  0.0837, -0.2474,  0.0145, -0.0915, -0.0101,\n",
       "                        0.0223,  0.0809,  0.1266, -0.0673, -0.2229,  0.0524, -0.1720,  0.0031,\n",
       "                       -0.0646,  0.0288,  0.0701,  0.1227, -0.0317, -0.1662,  0.1678, -0.0450,\n",
       "                       -0.1851, -0.0291,  0.0909,  0.0700,  0.1084,  0.0008,  0.0620,  0.0381,\n",
       "                        0.0298,  0.0246, -0.0042, -0.0302,  0.1899,  0.0508,  0.0370,  0.0393,\n",
       "                        0.0477,  0.0263, -0.0111, -0.0037, -0.1024, -0.0969,  0.0107, -0.0091,\n",
       "                        0.0351,  0.0351,  0.0194,  0.0743, -0.0876,  0.1261,  0.2320,  0.0399,\n",
       "                        0.0008, -0.2603, -0.0961, -0.0439, -0.2365, -0.0819,  0.0279,  0.0501,\n",
       "                        0.1353, -0.0230, -0.0257,  0.0241,  0.0297,  0.0923, -0.0106, -0.0875,\n",
       "                        0.0595,  0.1580,  0.0805,  0.0206,  0.0894,  0.0298,  0.1356,  0.0752,\n",
       "                        0.0847,  0.1598, -0.0568,  0.0259,  0.0883, -0.2455, -0.1135, -0.0116,\n",
       "                        0.0420,  0.0387,  0.0533, -0.1273, -0.0868, -0.0751, -0.0268, -0.1467,\n",
       "                        0.0212,  0.0163,  0.0832,  0.1124, -0.0096,  0.0043, -0.0772, -0.0328])),\n",
       "              ('transformer_encoder.layers.5.norm1.weight',\n",
       "               tensor([0.8491, 0.9809, 0.7629, 1.1009, 1.0175, 0.8835, 1.1306, 1.0364, 0.9998,\n",
       "                       1.0400, 0.9827, 1.0064, 0.9542, 1.0853, 1.0256, 1.0639, 1.0790, 0.7920,\n",
       "                       1.0023, 1.1450, 1.0796, 1.0043, 0.8447, 1.0677, 1.0924, 1.0326, 0.9164,\n",
       "                       1.1379, 1.0123, 0.9543, 0.8333, 1.0007, 1.1369, 1.0543, 0.9490, 0.9985,\n",
       "                       0.9872, 0.8846, 1.0434, 1.0576, 0.8869, 0.9918, 1.0136, 0.9676, 1.0238,\n",
       "                       0.9605, 1.0837, 0.9945, 1.0361, 0.9860, 1.0323, 0.9219, 0.9031, 0.8719,\n",
       "                       1.0657, 1.1538, 1.2643, 1.0143, 1.0664, 0.9168, 1.0549, 0.9507, 0.9688,\n",
       "                       1.0563, 1.0904, 1.1199, 0.9832, 0.8618, 1.0940, 0.9765, 1.0106, 0.9993,\n",
       "                       1.0269, 1.0922, 1.0182, 0.9448, 1.0052, 0.9870, 1.0154, 1.0305, 1.0300,\n",
       "                       0.9671, 1.0613, 1.0884, 1.1130, 1.0951, 0.9357, 0.8499, 0.9756, 1.0888,\n",
       "                       0.9849, 0.9990, 1.1058, 1.0004, 0.9987, 0.9281, 1.0067, 0.9792, 0.8984,\n",
       "                       0.9937, 1.0129, 0.9654, 0.9579, 1.0863, 0.8717, 1.0643, 0.9866, 1.0414,\n",
       "                       1.0984, 1.1046, 1.0831, 1.0788, 1.0295, 0.9580, 1.0541, 1.0634, 1.0763,\n",
       "                       1.0408, 0.9029, 1.0190, 1.0525, 0.9883, 1.1135, 1.0207, 0.8679, 0.9368,\n",
       "                       1.0223, 1.0270])),\n",
       "              ('transformer_encoder.layers.5.norm1.bias',\n",
       "               tensor([-0.0743, -0.1601,  0.0583,  0.2419, -0.0700, -0.0458,  0.3577, -0.0555,\n",
       "                        0.0387, -0.0135,  0.1009,  0.0225,  0.0706,  0.1495, -0.2313,  0.1378,\n",
       "                       -0.0577, -0.0569,  0.1199, -0.0031,  0.1997,  0.1125,  0.0752,  0.0677,\n",
       "                       -0.2026,  0.0354, -0.0012,  0.0636,  0.2030, -0.1187, -0.0241, -0.0360,\n",
       "                       -0.0196, -0.1547, -0.1180,  0.0701,  0.1045,  0.0585,  0.0586,  0.0301,\n",
       "                       -0.0692, -0.1668,  0.0608, -0.2124, -0.0084,  0.1173,  0.0257,  0.0160,\n",
       "                        0.0684, -0.1092, -0.0667,  0.0177, -0.0380, -0.0412,  0.1013, -0.0532,\n",
       "                        0.5324, -0.0233, -0.0017,  0.0988, -0.1653, -0.1871, -0.0543,  0.0201,\n",
       "                       -0.1134, -0.1101,  0.0708,  0.0418,  0.1997,  0.0550,  0.0779, -0.0924,\n",
       "                       -0.1261, -0.1030, -0.0811, -0.1130,  0.0364, -0.2907, -0.1283, -0.0300,\n",
       "                       -0.2106,  0.2423,  0.0418, -0.0337,  0.2980,  0.2381, -0.1118, -0.1853,\n",
       "                       -0.0601, -0.0281,  0.1142,  0.0706, -0.1718, -0.0055,  0.1314, -0.0971,\n",
       "                       -0.0078, -0.1259, -0.1330,  0.0179,  0.0601,  0.1483, -0.0945,  0.3676,\n",
       "                       -0.0285, -0.1611,  0.1263, -0.0498, -0.0500,  0.1286,  0.0027,  0.0554,\n",
       "                        0.1064, -0.1281, -0.1463,  0.2824, -0.0187,  0.0329, -0.0940,  0.1074,\n",
       "                       -0.1480, -0.1464, -0.0289, -0.0642,  0.0141, -0.1133,  0.0716, -0.1857])),\n",
       "              ('transformer_encoder.layers.5.norm2.weight',\n",
       "               tensor([1.3364, 1.0835, 1.2517, 1.3078, 1.3840, 1.1196, 1.1536, 1.1072, 1.2991,\n",
       "                       1.2298, 1.2064, 1.3758, 1.2832, 1.2914, 1.0344, 1.2209, 1.4025, 1.2255,\n",
       "                       1.1227, 1.5071, 1.3433, 1.2412, 1.3938, 1.1789, 1.1120, 1.1180, 1.2028,\n",
       "                       1.3226, 1.1075, 1.0089, 1.0360, 1.3259, 1.2722, 1.1196, 1.2077, 1.2761,\n",
       "                       1.1969, 1.2601, 1.1249, 1.2128, 1.2559, 0.9583, 1.4051, 1.2059, 1.0556,\n",
       "                       1.1732, 1.0967, 1.2790, 1.0439, 1.1718, 1.2117, 1.1118, 0.9260, 1.1441,\n",
       "                       1.1002, 1.2560, 1.1603, 1.1721, 1.3017, 1.1314, 1.2110, 1.3047, 1.0133,\n",
       "                       1.1724, 1.0367, 1.3358, 1.3620, 1.0181, 1.3486, 1.2086, 1.2253, 1.3189,\n",
       "                       1.1202, 1.1501, 0.9718, 1.2518, 1.3006, 0.8969, 1.0703, 1.1113, 1.0144,\n",
       "                       1.0128, 1.2752, 1.1129, 1.0777, 1.1186, 1.2091, 1.0797, 1.1906, 1.2594,\n",
       "                       1.1787, 1.0361, 0.8161, 1.2810, 1.0635, 1.3079, 1.1247, 1.1431, 1.1838,\n",
       "                       1.1470, 1.1876, 1.2131, 1.0545, 0.9908, 1.2696, 1.2807, 1.3339, 1.3471,\n",
       "                       1.1756, 1.2132, 1.3577, 1.1058, 1.2180, 1.1914, 1.1280, 1.0869, 1.0561,\n",
       "                       1.3931, 1.2195, 1.1494, 1.0188, 1.0849, 1.3969, 1.1470, 1.2145, 1.1865,\n",
       "                       1.2198, 1.1469])),\n",
       "              ('transformer_encoder.layers.5.norm2.bias',\n",
       "               tensor([-0.0856,  0.1169,  0.0054, -0.1878,  0.0755,  0.0647, -0.3619,  0.0248,\n",
       "                        0.1597, -0.3322, -0.0941, -0.0393,  0.0216, -0.2505,  0.2181, -0.0577,\n",
       "                        0.0602,  0.1721,  0.0295,  0.0668, -0.2620, -0.1396, -0.0805,  0.1084,\n",
       "                        0.2230, -0.0464, -0.1239,  0.0789, -0.4617,  0.1661,  0.1777,  0.0781,\n",
       "                        0.0022,  0.1711,  0.0398, -0.0322, -0.1031,  0.1123, -0.2015, -0.1453,\n",
       "                        0.0590,  0.1833, -0.0955,  0.0859, -0.0223, -0.2143,  0.2510, -0.1752,\n",
       "                       -0.2905,  0.0102, -0.0820,  0.0482, -0.0019, -0.0595,  0.0143,  0.1811,\n",
       "                       -0.5094, -0.2136, -0.1494, -0.0428,  0.1590,  0.0213,  0.1730,  0.1754,\n",
       "                        0.3722, -0.0423,  0.0093,  0.0141, -0.1235, -0.1824, -0.0771,  0.0085,\n",
       "                        0.1007, -0.1043,  0.1285,  0.0143, -0.2604,  0.1022,  0.2396,  0.0719,\n",
       "                        0.1253, -0.4136,  0.0119,  0.1885, -0.1739, -0.1879,  0.0676,  0.0433,\n",
       "                        0.1514,  0.0619, -0.0009,  0.1035,  0.1309,  0.0173, -0.1131,  0.0660,\n",
       "                        0.0155,  0.2880,  0.0942,  0.0180, -0.0334, -0.0683,  0.2367, -0.2222,\n",
       "                        0.0769,  0.3629, -0.0820,  0.0865,  0.0033, -0.1873,  0.0258,  0.0010,\n",
       "                       -0.0550,  0.0791,  0.3321, -0.0645, -0.0385,  0.1244, -0.0640, -0.2651,\n",
       "                        0.0714,  0.0366,  0.2018,  0.0455, -0.1122,  0.1982,  0.0232,  0.2317])),\n",
       "              ('encoder.weight',\n",
       "               tensor([[-0.0412, -0.0355,  0.0068,  ..., -0.0078, -0.0506,  0.0821],\n",
       "                       [ 0.0075, -0.0055, -0.0043,  ..., -0.0879,  0.0009, -0.0854],\n",
       "                       [-0.0669, -0.0025,  0.0926,  ...,  0.0532, -0.0380, -0.0375],\n",
       "                       ...,\n",
       "                       [-0.0020,  0.0008, -0.0267,  ..., -0.0683,  0.0252, -0.0269],\n",
       "                       [-0.0028, -0.0403, -0.0314,  ..., -0.0354,  0.0222, -0.0148],\n",
       "                       [ 0.0087,  0.0027,  0.0622,  ..., -0.0408, -0.0751,  0.0681]])),\n",
       "              ('decoder.weight',\n",
       "               tensor([[ 0.1800,  0.1080,  0.0189,  ...,  0.3265, -0.0347,  0.1587],\n",
       "                       [ 0.1695,  0.1108, -0.0162,  ...,  0.2982, -0.0389,  0.1864],\n",
       "                       [ 0.1836,  0.1308, -0.0152,  ...,  0.3070, -0.0265,  0.1671],\n",
       "                       ...,\n",
       "                       [ 0.0163,  0.0955,  0.0240,  ..., -0.0615,  0.0530,  0.2588],\n",
       "                       [ 0.0409,  0.1645,  0.0804,  ..., -0.0296, -0.0250,  0.1480],\n",
       "                       [-0.0654,  0.2863,  0.0357,  ..., -0.0936,  0.0552,  0.1553]])),\n",
       "              ('decoder.bias',\n",
       "               tensor([-5.9447, -5.9534, -5.9439,  ..., -0.2648, -0.1437, -0.1953]))]),\n",
       " 'networks': [Data(edge_index=[2, 6420], num_nodes=1432, edge_weight=[6420], node_index=[1432], node_sequence=[1], node_tokens=[1432]),\n",
       "  Data(edge_index=[2, 12916], num_nodes=2941, edge_weight=[12916], node_index=[2941], node_sequence=[1], node_tokens=[2941]),\n",
       "  Data(edge_index=[2, 11982], num_nodes=2796, edge_weight=[11982], node_index=[2796], node_sequence=[1], node_tokens=[2796]),\n",
       "  Data(edge_index=[2, 15648], num_nodes=3529, edge_weight=[15648], node_index=[3529], node_sequence=[1], node_tokens=[3529]),\n",
       "  Data(edge_index=[2, 2454], num_nodes=545, edge_weight=[2454], node_index=[545], node_sequence=[1], node_tokens=[545]),\n",
       "  Data(edge_index=[2, 3410], num_nodes=732, edge_weight=[3410], node_index=[732], node_sequence=[1], node_tokens=[732]),\n",
       "  Data(edge_index=[2, 4464], num_nodes=964, edge_weight=[4464], node_index=[964], node_sequence=[1], node_tokens=[964]),\n",
       "  Data(edge_index=[2, 6898], num_nodes=1540, edge_weight=[6898], node_index=[1540], node_sequence=[1], node_tokens=[1540]),\n",
       "  Data(edge_index=[2, 3064], num_nodes=684, edge_weight=[3064], node_index=[684], node_sequence=[1], node_tokens=[684])],\n",
       " 'tokenizer': <tokenizers.Tokenizer at 0xb1a5670>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint['model_params']['epochs'] = 20\n",
    "checkpoint['model_params']['ntokens'] = pyg_graphs[0].num_nodes\n",
    "\n",
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e299376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.pre_tokenizers import WhitespaceSplit\n",
    "from tokenizers import Tokenizer, models, trainers\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def bert_walk_tokenizer(data, model_params):\n",
    "    tokenizer = Tokenizer(models.WordLevel(unk_token=\"[UNK]\"))\n",
    "    #my_tokens = Path(\"tokenizer_test_.pt\")\n",
    "    \n",
    "    print(\"training tokenizer!\")\n",
    "    tokenizer.pre_tokenizer = WhitespaceSplit()\n",
    "    trainer = trainers.WordLevelTrainer(special_tokens=[\"[UNK]\", \"[MASK]\", \"[CLS]\", \"[PAD]\"])\n",
    "    tokenizer.enable_padding()\n",
    "    tokenizer.train_from_iterator(map(lambda x: x.split(), data), trainer=trainer)\n",
    "    tokenizer.save('tokenizer_test_.pt')\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3de9341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training tokenizer!\n"
     ]
    }
   ],
   "source": [
    "tokenizer = bert_walk_tokenizer(data, checkpoint['model_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c848864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Data(edge_index=[2, 6014], num_nodes=1304, edge_weight=[6014], node_index=[1304], node_sequence=[1])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyg_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff991d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2945, 1304)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab_size(), len(torch.tensor(tokenizer.encode(pyg_graphs[0][\"node_sequence\"][0]).ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84eab78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for net in pyg_graphs:\n",
    "        net[\"node_tokens\"] = torch.tensor(tokenizer.encode(net[\"node_sequence\"][0]).ids).to(device)\n",
    "        net.edge_index = net.edge_index.to(device)\n",
    "        net.edge_weight = net.edge_weight.to(device)\n",
    "checkpoint[\"model_params\"][\"ntokens\"] = tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bae39b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 64,\n",
       " 'emsize': 128,\n",
       " 'nhid': 200,\n",
       " 'nlayers': 6,\n",
       " 'nhead': 4,\n",
       " 'dropout': 0.0,\n",
       " 'learning_rate': 0.0005,\n",
       " 'epochs': 20,\n",
       " 'K': 1,\n",
       " 'alpha': 0.1,\n",
       " 'mask_rate': 0.2,\n",
       " 'q': 1,\n",
       " 'p': 1,\n",
       " 'walk_length': 10,\n",
       " 'num_walks': 10,\n",
       " 'weighted': 1,\n",
       " 'directed': 0,\n",
       " 'organism': 'FIRSTMM_DB',\n",
       " 'ntokens': 2945}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint[\"model_params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35991e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerModel(checkpoint['model_params'], pyg_graphs).to(device)\n",
    "dataset = BertWalkDataset(data, tokenizer)\n",
    "dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=checkpoint['model_params'][\"batch_size\"],\n",
    "        collate_fn=partial(bert_walk_collate, tokenizer=tokenizer),\n",
    "        shuffle=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edcf4e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=200, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=200, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=200, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=200, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=200, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=200, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (3): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=200, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=200, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (4): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=200, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=200, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (5): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=200, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=200, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder): Embedding(2945, 128)\n",
       "  (decoder): Linear(in_features=128, out_features=2945, bias=True)\n",
       "  (appnp): ModuleList(\n",
       "    (0): APPNP(K=1, alpha=0.1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71a1eb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bert_walk(model, dataloader, model_params, tokenizer):\n",
    "    lr = model_params[\"learning_rate\"]\n",
    "    mask_token_id = tokenizer.get_vocab()[\"[MASK]\"]\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    best_loss = float(\"inf\")\n",
    "    best_model = None\n",
    "    for epoch in range(model_params[\"epochs\"]):\n",
    "        total_loss = 0\n",
    "        epoch_start_time = time.time()\n",
    "        model.all_prop_emb()\n",
    "        for b, batch in enumerate(dataloader):\n",
    "            optim.zero_grad()\n",
    "            input = batch[\"input\"].clone()\n",
    "            labels = batch[\"input\"].clone()\n",
    "            src_mask = batch[\"src_mask\"]\n",
    "            src_key_padding_mask = batch[\"src_key_padding_mask\"]\n",
    "\n",
    "            rand_mask = ~batch[\"input\"].bool()\n",
    "            for i, row in enumerate(\n",
    "                torch.randint(\n",
    "                    1,\n",
    "                    batch[\"input\"].shape[1],\n",
    "                    (batch[\"input\"].shape[0], int(batch[\"input\"].shape[1] * model_params[\"mask_rate\"])),\n",
    "                )\n",
    "            ):\n",
    "                rand_mask[i, row] = True\n",
    "\n",
    "            mask_idx = (rand_mask.flatten() == True).nonzero().view(-1)\n",
    "            input = input.flatten()\n",
    "            input[mask_idx] = mask_token_id\n",
    "            input = input.view(batch[\"input\"].size())\n",
    "            labels[input != mask_token_id] = -100\n",
    "\n",
    "            out = model(input.to(device), src_mask.to(device), src_key_padding_mask.to(device))\n",
    "            loss = criterion(out.view(-1, model_params[\"ntokens\"]), labels.view(-1).to(device))\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            optim.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        elapsed = time.time() - epoch_start_time\n",
    "        loss_dict = {}\n",
    "        val_loss = total_loss / (len(dataloader))\n",
    "        loss_dict[\"total\"] = val_loss\n",
    "        \n",
    "        print(\"-\" * 89)\n",
    "        print(f\"| epoch {1+epoch:3d} | time: {elapsed:5.2f}s | \" f\"loss {val_loss:5.2f} | lr {lr:02.5f}\")\n",
    "        print(\"-\" * 89)\n",
    "\n",
    "\n",
    "        \n",
    "        if total_loss < best_loss:\n",
    "            best_loss = total_loss\n",
    "            best_model = model.state_dict()\n",
    "        \n",
    "\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2435ac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = train_bert_walk(model, dataloader, checkpoint['model_params'], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0678ab11",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "        {\n",
    "            \"model_params\": checkpoint['model_params'],\n",
    "            \"model_state_dict\": mdl,\n",
    "            \"networks\": pyg_graphs,\n",
    "            \"tokenizer\": tokenizer,\n",
    "        },\n",
    "        \"test_model.pt\",\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
